{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ijsbqc7Ipl2"
   },
   "source": [
    "## Full PATEGAN rewrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5293,
     "status": "ok",
     "timestamp": 1623408956873,
     "user": {
      "displayName": "Tee Yee Yang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgKFrQtw-OyvubwOe5xvtv9JOTRkaAVybEHvmq9ag=s64",
      "userId": "07106232567566268752"
     },
     "user_tz": -480
    },
    "id": "QifCHxjTI5Ql"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from models import dp_wgan, pate_gan\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1623408956876,
     "user": {
      "displayName": "Tee Yee Yang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgKFrQtw-OyvubwOe5xvtv9JOTRkaAVybEHvmq9ag=s64",
      "userId": "07106232567566268752"
     },
     "user_tz": -480
    },
    "id": "KcDKmo_aisiA"
   },
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "MODEL_NAME = 'PATEGAN' # Don't change this\n",
    "DATASET_NAME = 'churn' # Choose either 'churn' or 'marketing' exactly!\n",
    "TARGET_VARIABLE = 'Exited' # either 'Exited' or 'Response'\n",
    "TRAIN_TEST_RATIO = 0.25\n",
    "LEAKY = False # Put False for normal relu. The number indicates the amount of negative slope. Default is 0.01\n",
    "\n",
    "# These seem to be good to tune from what I can tell from the github.\n",
    "NUM_TEACHERS = 8\n",
    "TARGET_EPSILON = 10\n",
    "TARGET_DELTA = 1e-4\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# Following defaults in the toolbox. Might not be crucial to tune these\n",
    "BATCH_SIZE = 64\n",
    "TEACHER_ITER = 5\n",
    "STUDENT_ITER = 5\n",
    "NUM_MOMENTS= 100\n",
    "LAP_SCALE = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1623408956876,
     "user": {
      "displayName": "Tee Yee Yang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgKFrQtw-OyvubwOe5xvtv9JOTRkaAVybEHvmq9ag=s64",
      "userId": "07106232567566268752"
     },
     "user_tz": -480
    },
    "id": "6LXKHydGhhEF"
   },
   "outputs": [],
   "source": [
    "# Read in data and do train test split\n",
    "df = pd.read_csv(f'{DATASET_NAME}_processed.csv')\n",
    "df_train, df_test = train_test_split(df, test_size=TRAIN_TEST_RATIO, random_state=42, stratify = df[TARGET_VARIABLE])\n",
    "\n",
    "# Initialise logfile path\n",
    "timestamp = int(time.time())\n",
    "logfile = f'log_{DATASET_NAME}_{MODEL_NAME}_{timestamp}_{TARGET_EPSILON}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1623408956877,
     "user": {
      "displayName": "Tee Yee Yang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgKFrQtw-OyvubwOe5xvtv9JOTRkaAVybEHvmq9ag=s64",
      "userId": "07106232567566268752"
     },
     "user_tz": -480
    },
    "id": "0rmYtc28ZXk4"
   },
   "outputs": [],
   "source": [
    "# Grab x and y from the respective dataframes and convert to numpy arrays.\n",
    "train_x = df_train.drop(columns=TARGET_VARIABLE).values\n",
    "train_y = df_train[TARGET_VARIABLE].values\n",
    "test_x = df_test.drop(columns=TARGET_VARIABLE).values\n",
    "test_y = df_test[TARGET_VARIABLE].values\n",
    "\n",
    "# Initialise scaler and use this to normalize the inputs.\n",
    "scaler = StandardScaler()\n",
    "train_x = scaler.fit_transform(train_x)\n",
    "test_x = scaler.transform(test_x)\n",
    "\n",
    "\n",
    "# Some misc variables for pategan \n",
    "data_columns = [col for col in df_train.columns if col != TARGET_VARIABLE]\n",
    "class_ratios = df_train[TARGET_VARIABLE].sort_values().groupby(df_train[TARGET_VARIABLE]).size().values/train_x.shape[0]\n",
    "input_dim = train_x.shape[1]\n",
    "z_dim = int(input_dim / 4 + 1) if input_dim % 4 == 0 else int(input_dim / 4)\n",
    "conditional = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Roc of 0 found, saving....\n",
      "Step :  0 Loss SD :  0.7008012136281578 Loss G :  0.7809650556559247 Epsilon :  0.09274980371976183 ROC_SCORE:  0.6363626496049511\n",
      "Step :  10 Loss SD :  0.6942692695665338 Loss G :  0.7576940767680684 Epsilon :  0.09921380371976182 ROC_SCORE:  0.6348711638522665\n",
      "Step :  20 Loss SD :  0.6975757592078511 Loss G :  0.7567712985485595 Epsilon :  0.10567780371976183 ROC_SCORE:  0.6324708733505094\n",
      "Best Roc of 0.6363626496049511 found, saving....\n",
      "Step :  30 Loss SD :  0.6866581249919952 Loss G :  0.7591672490062915 Epsilon :  0.11214180371976187 ROC_SCORE:  0.6371757387615586\n",
      "Best Roc of 0.6371757387615586 found, saving....\n",
      "Step :  40 Loss SD :  0.7160411002772764 Loss G :  0.770765299156676 Epsilon :  0.11860580371976191 ROC_SCORE:  0.6400185905336292\n",
      "Step :  50 Loss SD :  0.7052686038294211 Loss G :  0.7504189439479136 Epsilon :  0.12506980371976192 ROC_SCORE:  0.6355288385159544\n",
      "Step :  60 Loss SD :  0.692065210979011 Loss G :  0.7364775056998085 Epsilon :  0.13153380371976195 ROC_SCORE:  0.6296502236488559\n",
      "Step :  70 Loss SD :  0.6901961625397592 Loss G :  0.7271587005611682 Epsilon :  0.13799780371976175 ROC_SCORE:  0.6396801323046046\n",
      "Step :  80 Loss SD :  0.7026841032456428 Loss G :  0.7292062229380117 Epsilon :  0.14446180371976158 ROC_SCORE:  0.6342593734674404\n",
      "Step :  90 Loss SD :  0.6909835636788371 Loss G :  0.7079831153898684 Epsilon :  0.15092580371976136 ROC_SCORE:  0.6336821196365965\n",
      "Best Roc of 0.6400185905336292 found, saving....\n",
      "Step :  100 Loss SD :  0.7017436589698284 Loss G :  0.7047383088357213 Epsilon :  0.1573898037197612 ROC_SCORE:  0.6406999474057621\n",
      "Step :  110 Loss SD :  0.7004112146055969 Loss G :  0.7097571823177307 Epsilon :  0.16385380371976097 ROC_SCORE:  0.632846828409572\n",
      "Step :  120 Loss SD :  0.6978353133779145 Loss G :  0.714140623073201 Epsilon :  0.1703178037197608 ROC_SCORE:  0.6373824647061087\n",
      "Step :  130 Loss SD :  0.6906380049396825 Loss G :  0.7095059672174072 Epsilon :  0.1767818037197609 ROC_SCORE:  0.6306991481312271\n",
      "Step :  140 Loss SD :  0.6924222439718237 Loss G :  0.7034298856946519 Epsilon :  0.18324580371976118 ROC_SCORE:  0.6350334856559824\n",
      "Step :  150 Loss SD :  0.6940759927428013 Loss G :  0.7117747569029453 Epsilon :  0.18965666502016681 ROC_SCORE:  0.6317396851647739\n",
      "Step :  160 Loss SD :  0.6949833865561574 Loss G :  0.7042864732259794 Epsilon :  0.19586935128395944 ROC_SCORE:  0.6373074710460332\n",
      "Step :  170 Loss SD :  0.6904830642184232 Loss G :  0.7016704335639548 Epsilon :  0.20189159534756576 ROC_SCORE:  0.6371910335211792\n",
      "Step :  180 Loss SD :  0.6926196137401448 Loss G :  0.6916167313300476 Epsilon :  0.207742970471642 ROC_SCORE:  0.6289634396039546\n",
      "Step :  190 Loss SD :  0.6933086830183063 Loss G :  0.7007985846906606 Epsilon :  0.2134371812870851 ROC_SCORE:  0.6352402116005325\n",
      "Step :  200 Loss SD :  0.6902848182210038 Loss G :  0.696675433778597 Epsilon :  0.21898734555266197 ROC_SCORE:  0.6309946823574455\n",
      "Step :  210 Loss SD :  0.696293368802925 Loss G :  0.691172433845253 Epsilon :  0.22440155628886976 ROC_SCORE:  0.6377806218355881\n",
      "Step :  220 Loss SD :  0.68892207472501 Loss G :  0.6911409413258166 Epsilon :  0.22968870582686435 ROC_SCORE:  0.6252630945344424\n",
      "Step :  230 Loss SD :  0.6888888247321092 Loss G :  0.6888752431438805 Epsilon :  0.23485858698703926 ROC_SCORE:  0.6359866945458887\n",
      "Step :  240 Loss SD :  0.6917406310130759 Loss G :  0.6870613586052886 Epsilon :  0.23992201002566588 ROC_SCORE:  0.6402337039270036\n",
      "Step :  250 Loss SD :  0.6923565461998121 Loss G :  0.6883820791780344 Epsilon :  0.24488148910495086 ROC_SCORE:  0.6373089511840611\n",
      "Step :  260 Loss SD :  0.6922164292480546 Loss G :  0.6865069459946992 Epsilon :  0.24974405908075925 ROC_SCORE:  0.6349821742043518\n",
      "Step :  270 Loss SD :  0.6911096333783577 Loss G :  0.6918262266826937 Epsilon :  0.2545146461914563 ROC_SCORE:  0.6398562687299133\n",
      "Best Roc of 0.6406999474057621 found, saving....\n",
      "Step :  280 Loss SD :  0.6916677811373856 Loss G :  0.6867979836257784 Epsilon :  0.25920459405522234 ROC_SCORE:  0.6414755397323317\n",
      "Step :  290 Loss SD :  0.6986894593591556 Loss G :  0.6891223581086663 Epsilon :  0.26380669102823057 ROC_SCORE:  0.627249933147099\n",
      "Step :  300 Loss SD :  0.6894579276058439 Loss G :  0.6824427247992797 Epsilon :  0.2683311937967585 ROC_SCORE:  0.630041473467539\n",
      "Step :  310 Loss SD :  0.6953970252240721 Loss G :  0.687406529493217 Epsilon :  0.27278378194082675 ROC_SCORE:  0.6297612340009413\n",
      "Step :  320 Loss SD :  0.6882422670968178 Loss G :  0.6850264855716734 Epsilon :  0.2771669667459133 ROC_SCORE:  0.6297750486225342\n",
      "Step :  330 Loss SD :  0.691425263226067 Loss G :  0.6876724223870655 Epsilon :  0.28148341169660496 ROC_SCORE:  0.636526451546695\n",
      "Step :  340 Loss SD :  0.6957599073185357 Loss G :  0.684944981963683 Epsilon :  0.2857359441842451 ROC_SCORE:  0.6384328693265077\n",
      "Step :  350 Loss SD :  0.6952572251754805 Loss G :  0.686027779761411 Epsilon :  0.28992756831213257 ROC_SCORE:  0.6393845980783863\n",
      "Best Roc of 0.6414755397323317 found, saving....\n",
      "Step :  360 Loss SD :  0.6922314231462143 Loss G :  0.6928667077551963 Epsilon :  0.2940614789202603 ROC_SCORE:  0.6433942919957095\n",
      "Best Roc of 0.6433942919957095 found, saving....\n",
      "Step :  370 Loss SD :  0.6937105599531135 Loss G :  0.6905195618944449 Epsilon :  0.29814107696735576 ROC_SCORE:  0.648994147534238\n",
      "Step :  380 Loss SD :  0.6910085999544151 Loss G :  0.6842306409818826 Epsilon :  0.30216998642583787 ROC_SCORE:  0.6355288385159544\n",
      "Step :  390 Loss SD :  0.6925443313682725 Loss G :  0.6869478871089725 Epsilon :  0.3061379864258372 ROC_SCORE:  0.6269391041612601\n",
      "Step :  400 Loss SD :  0.6927998828762488 Loss G :  0.6918838489363512 Epsilon :  0.31005607286626513 ROC_SCORE:  0.6301080796787903\n",
      "Step :  410 Loss SD :  0.6910557661315979 Loss G :  0.6944138013828944 Epsilon :  0.31393146393179994 ROC_SCORE:  0.6329524115888887\n",
      "Step :  420 Loss SD :  0.6898431008250678 Loss G :  0.6836576562183738 Epsilon :  0.31776857193062896 ROC_SCORE:  0.6324264692096754\n",
      "Step :  430 Loss SD :  0.696919034178292 Loss G :  0.6853363404440952 Epsilon :  0.32154457193062913 ROC_SCORE:  0.6450717817605551\n",
      "Step :  440 Loss SD :  0.6939048860922208 Loss G :  0.683152761961392 Epsilon :  0.325284118806605 ROC_SCORE:  0.6359659726134995\n",
      "Step :  450 Loss SD :  0.696018668492032 Loss G :  0.684530982397672 Epsilon :  0.3289951637852884 ROC_SCORE:  0.6421026248767785\n",
      "Step :  460 Loss SD :  0.6910953727879496 Loss G :  0.6891910134924938 Epsilon :  0.33264316378528896 ROC_SCORE:  0.6374283489849707\n",
      "Step :  470 Loss SD :  0.6919771678259917 Loss G :  0.6848687015342194 Epsilon :  0.33626713403592356 ROC_SCORE:  0.6414671522835076\n",
      "Step :  480 Loss SD :  0.6960480644858451 Loss G :  0.6833318637813711 Epsilon :  0.33985113403592326 ROC_SCORE:  0.635728657149708\n",
      "Step :  490 Loss SD :  0.6955152510640932 Loss G :  0.6846769324923553 Epsilon :  0.3433938587402967 ROC_SCORE:  0.6393179918671348\n",
      "Step :  500 Loss SD :  0.6834658040519053 Loss G :  0.6855013677822747 Epsilon :  0.34691385874029596 ROC_SCORE:  0.637146629380345\n",
      "Step :  510 Loss SD :  0.6948781606928977 Loss G :  0.6866715506806206 Epsilon :  0.35038160701841253 ROC_SCORE:  0.6368802045353403\n",
      "Step :  520 Loss SD :  0.6937445373434219 Loss G :  0.686693449283327 Epsilon :  0.3538376070184116 ROC_SCORE:  0.6380554341294173\n",
      "Step :  530 Loss SD :  0.6943730111075989 Loss G :  0.6877218230944312 Epsilon :  0.35723713023031406 ROC_SCORE:  0.6307588470316818\n",
      "Step :  540 Loss SD :  0.6909121715168378 Loss G :  0.6872610123365591 Epsilon :  0.3606291302303136 ROC_SCORE:  0.6340526475228903\n",
      "Step :  550 Loss SD :  0.6946393323734676 Loss G :  0.6879210845692987 Epsilon :  0.36396770925444155 ROC_SCORE:  0.6380569142674452\n",
      "Step :  560 Loss SD :  0.6961527946638715 Loss G :  0.6877518335079676 Epsilon :  0.36729570925444177 ROC_SCORE:  0.6264230293688988\n",
      "Step :  570 Loss SD :  0.6927997740444733 Loss G :  0.6874428858038455 Epsilon :  0.3705812074395159 ROC_SCORE:  0.6329524115888887\n",
      "Step :  580 Loss SD :  0.6940163948969138 Loss G :  0.6880369039605649 Epsilon :  0.37384520743951555 ROC_SCORE:  0.6410176837023974\n",
      "Step :  590 Loss SD :  0.6925875778102941 Loss G :  0.686818235382145 Epsilon :  0.37708613004031666 ROC_SCORE:  0.6369482908846194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step :  600 Loss SD :  0.6919909928260499 Loss G :  0.6856637889549123 Epsilon :  0.38028613004031625 ROC_SCORE:  0.6377529925924026\n",
      "Step :  610 Loss SD :  0.691941400692252 Loss G :  0.6866570701573937 Epsilon :  0.3834861300403158 ROC_SCORE:  0.6345549076936589\n",
      "Step :  620 Loss SD :  0.6916346721749135 Loss G :  0.6860165335644124 Epsilon :  0.38662769108283196 ROC_SCORE:  0.6327747950255521\n",
      "Step :  630 Loss SD :  0.6939897343680764 Loss G :  0.6856709948626836 Epsilon :  0.3897636910828319 ROC_SCORE:  0.6430489264558884\n",
      "Step :  640 Loss SD :  0.6960126662661179 Loss G :  0.6853662000682204 Epsilon :  0.3928798887654502 ROC_SCORE:  0.6358771643318312\n",
      "Step :  650 Loss SD :  0.6920122504296028 Loss G :  0.6860489244896205 Epsilon :  0.39595188876545084 ROC_SCORE:  0.6360325788247506\n",
      "Step :  660 Loss SD :  0.6937926435501568 Loss G :  0.6857886216279561 Epsilon :  0.3990238887654515 ROC_SCORE:  0.6321699119515225\n",
      "Step :  670 Loss SD :  0.6931624397901379 Loss G :  0.6874407011914018 Epsilon :  0.4020615906951342 ROC_SCORE:  0.6297252173089315\n",
      "Step :  680 Loss SD :  0.6933108068091731 Loss G :  0.6864444445397154 Epsilon :  0.40506959069513415 ROC_SCORE:  0.6325236649401678\n",
      "Step :  690 Loss SD :  0.6948183018480523 Loss G :  0.6861020615011315 Epsilon :  0.40807759069513416 ROC_SCORE:  0.6429601181742202\n",
      "Step :  700 Loss SD :  0.6932815205155719 Loss G :  0.6877166592808429 Epsilon :  0.41104863048834817 ROC_SCORE:  0.6327678877147558\n",
      "Step :  710 Loss SD :  0.6941945582803377 Loss G :  0.688090264312853 Epsilon :  0.41399263048834795 ROC_SCORE:  0.6300789702975769\n",
      "Step :  720 Loss SD :  0.693700406297612 Loss G :  0.6890802692119282 Epsilon :  0.4169366304883477 ROC_SCORE:  0.6295989121972254\n",
      "Step :  730 Loss SD :  0.694178009524682 Loss G :  0.6875443635598522 Epsilon :  0.41985391754491697 ROC_SCORE:  0.6312611072024503\n",
      "Step :  740 Loss SD :  0.6909018747422295 Loss G :  0.6872321187478654 Epsilon :  0.422733917544917 ROC_SCORE:  0.6323766378960727\n",
      "Step :  750 Loss SD :  0.6941253999844569 Loss G :  0.6852151353931762 Epsilon :  0.42561391754491706 ROC_SCORE:  0.6290009364339924\n",
      "Step :  760 Loss SD :  0.6936981424118838 Loss G :  0.6862873439971002 Epsilon :  0.42849156213898015 ROC_SCORE:  0.6301317618872352\n",
      "Step :  770 Loss SD :  0.6939456741572381 Loss G :  0.6858297236823505 Epsilon :  0.43130756213898097 ROC_SCORE:  0.6342968702974782\n",
      "Step :  780 Loss SD :  0.6933929481944181 Loss G :  0.6858136407122117 Epsilon :  0.43412356213898184 ROC_SCORE:  0.6294879018451401\n",
      "Step :  790 Loss SD :  0.6916381670468043 Loss G :  0.6865593831373245 Epsilon :  0.43693956213898266 ROC_SCORE:  0.6347103221865782\n",
      "Step :  800 Loss SD :  0.6924157523603642 Loss G :  0.6873171690406336 Epsilon :  0.4397290183803887 ROC_SCORE:  0.6340235381416768\n",
      "Step :  810 Loss SD :  0.6914434168478167 Loss G :  0.6879799756957881 Epsilon :  0.4424810183803887 ROC_SCORE:  0.6364169213326374\n",
      "Step :  820 Loss SD :  0.6927363826475752 Loss G :  0.6859233618638509 Epsilon :  0.44523301838038876 ROC_SCORE:  0.6358411476398212\n",
      "Step :  830 Loss SD :  0.6954963603528924 Loss G :  0.688288195100756 Epsilon :  0.4479850183803888 ROC_SCORE:  0.6293630768714619\n",
      "Step :  840 Loss SD :  0.6926030993922934 Loss G :  0.6885874407604002 Epsilon :  0.45070324809696327 ROC_SCORE:  0.6312833092728674\n",
      "Step :  850 Loss SD :  0.6906928697204455 Loss G :  0.6866550446985982 Epsilon :  0.45339124809696296 ROC_SCORE:  0.6356260342464469\n",
      "Step :  860 Loss SD :  0.6931730995656052 Loss G :  0.6864730713940429 Epsilon :  0.45607924809696276 ROC_SCORE:  0.635256986498181\n",
      "Step :  870 Loss SD :  0.69350298940239 Loss G :  0.6870639477060076 Epsilon :  0.45876724809696245 ROC_SCORE:  0.6299013537342402\n",
      "Step :  880 Loss SD :  0.693042412157546 Loss G :  0.6893401779815111 Epsilon :  0.46143290929940123 ROC_SCORE:  0.6331744322930594\n",
      "Step :  890 Loss SD :  0.6935758171138648 Loss G :  0.6873915562631779 Epsilon :  0.4640569092994012 ROC_SCORE:  0.6332701478855242\n",
      "Step :  900 Loss SD :  0.6937264713046833 Loss G :  0.6872180313971847 Epsilon :  0.46668090929940115 ROC_SCORE:  0.6315788434990858\n",
      "Step :  910 Loss SD :  0.6926065530763943 Loss G :  0.688817317889298 Epsilon :  0.4693049092994011 ROC_SCORE:  0.6367346576292727\n",
      "Step :  920 Loss SD :  0.6942964003753818 Loss G :  0.6889932376567457 Epsilon :  0.47192890929940107 ROC_SCORE:  0.6341123464233451\n",
      "Step :  930 Loss SD :  0.6951299819741109 Loss G :  0.6890175674441738 Epsilon :  0.4744985736404109 ROC_SCORE:  0.6297543266901449\n",
      "Step :  940 Loss SD :  0.6938908744131433 Loss G :  0.687830208910711 Epsilon :  0.47705857364041165 ROC_SCORE:  0.6316745590915506\n",
      "Step :  950 Loss SD :  0.6921305806232776 Loss G :  0.6877593535408213 Epsilon :  0.4796185736404124 ROC_SCORE:  0.6312764019620709\n",
      "Step :  960 Loss SD :  0.6927546956375517 Loss G :  0.6891925771249159 Epsilon :  0.4821785736404131 ROC_SCORE:  0.6324792607993337\n",
      "Step :  970 Loss SD :  0.6931543434549666 Loss G :  0.6877535784396434 Epsilon :  0.4847385736404139 ROC_SCORE:  0.6315719361882892\n",
      "Step :  980 Loss SD :  0.6933064220830959 Loss G :  0.6897268049673249 Epsilon :  0.48723497820988343 ROC_SCORE:  0.6364460307138509\n",
      "Step :  990 Loss SD :  0.6917444005158226 Loss G :  0.6888540651090795 Epsilon :  0.4897309782098832 ROC_SCORE:  0.6297543266901449\n",
      "Step :  1000 Loss SD :  0.6935280013672847 Loss G :  0.6892343230715783 Epsilon :  0.492226978209883 ROC_SCORE:  0.6344813941716111\n",
      "Step :  1010 Loss SD :  0.6935543826834948 Loss G :  0.6886207231568471 Epsilon :  0.49472297820988276 ROC_SCORE:  0.634968359582759\n",
      "Step :  1020 Loss SD :  0.6933351218427165 Loss G :  0.6889457551583313 Epsilon :  0.4972189782098826 ROC_SCORE:  0.63301901780014\n",
      "Step :  1030 Loss SD :  0.6937710954071356 Loss G :  0.6896095439335954 Epsilon :  0.49966731816153276 ROC_SCORE:  0.6386839994118917\n",
      "Step :  1040 Loss SD :  0.6932942339995145 Loss G :  0.6893446496907453 Epsilon :  0.5020993181615321 ROC_SCORE:  0.6338681236487573\n",
      "Step :  1050 Loss SD :  0.6941960860719218 Loss G :  0.6905086862650043 Epsilon :  0.5045313181615315 ROC_SCORE:  0.6325833638406226\n",
      "Step :  1060 Loss SD :  0.6927815679150353 Loss G :  0.6910792942310401 Epsilon :  0.5069633181615308 ROC_SCORE:  0.6336835997746243\n",
      "Step :  1070 Loss SD :  0.6925688761138912 Loss G :  0.6913424962228918 Epsilon :  0.5093953181615302 ROC_SCORE:  0.633388065548406\n",
      "Step :  1080 Loss SD :  0.6932121158141022 Loss G :  0.6901371246073374 Epsilon :  0.5118235881104234 ROC_SCORE:  0.6311945009911991\n",
      "Step :  1090 Loss SD :  0.6935172080679022 Loss G :  0.6898449977877907 Epsilon :  0.5141915881104229 ROC_SCORE:  0.6329011001372582\n",
      "Step :  1100 Loss SD :  0.6940214072515811 Loss G :  0.6899412933840792 Epsilon :  0.5165595881104224 ROC_SCORE:  0.6303231930721647\n",
      "Step :  1110 Loss SD :  0.6925132268557381 Loss G :  0.6906372109564023 Epsilon :  0.5189275881104218 ROC_SCORE:  0.6343856785791465\n",
      "Step :  1120 Loss SD :  0.6928927453640111 Loss G :  0.691718465286112 Epsilon :  0.5212955881104214 ROC_SCORE:  0.6303967065942122\n",
      "Step :  1130 Loss SD :  0.6925016295027389 Loss G :  0.6923136951685265 Epsilon :  0.5236635881104209 ROC_SCORE:  0.6381082257190758\n",
      "Step :  1140 Loss SD :  0.6931284856218827 Loss G :  0.6913603116990564 Epsilon :  0.5260315881104204 ROC_SCORE:  0.6304120013538328\n",
      "Step :  1150 Loss SD :  0.693140757916092 Loss G :  0.6905094213903036 Epsilon :  0.5283429820564864 ROC_SCORE:  0.6340457402120939\n",
      "Step :  1160 Loss SD :  0.6930726248348675 Loss G :  0.6925685753748896 Epsilon :  0.5306469820564867 ROC_SCORE:  0.6292742685897936\n",
      "Step :  1170 Loss SD :  0.6931575857996832 Loss G :  0.6908768492778238 Epsilon :  0.5329509820564869 ROC_SCORE:  0.6323697305852761\n",
      "Step :  1180 Loss SD :  0.6933766926196233 Loss G :  0.6908011507157772 Epsilon :  0.5352549820564872 ROC_SCORE:  0.6300567682271597\n",
      "Step :  1190 Loss SD :  0.6938730729811188 Loss G :  0.6910815330352662 Epsilon :  0.5375589820564876 ROC_SCORE:  0.6362545995289215\n",
      "Step :  1200 Loss SD :  0.6930972827735894 Loss G :  0.6912614224632949 Epsilon :  0.5398629820564878 ROC_SCORE:  0.6291410561672911\n",
      "Step :  1210 Loss SD :  0.6936315889426059 Loss G :  0.6909632141044342 Epsilon :  0.5421563638816539 ROC_SCORE:  0.635279188568598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step :  1220 Loss SD :  0.6936674411152786 Loss G :  0.6910925314308535 Epsilon :  0.5443963638816531 ROC_SCORE:  0.6355456134136028\n",
      "Step :  1230 Loss SD :  0.6919798485106798 Loss G :  0.6922861065015107 Epsilon :  0.5466363638816522 ROC_SCORE:  0.6403461944171167\n",
      "Step :  1240 Loss SD :  0.6930061822480059 Loss G :  0.6912151423768931 Epsilon :  0.5488763638816513 ROC_SCORE:  0.6359812673731201\n",
      "Step :  1250 Loss SD :  0.6935439210520908 Loss G :  0.690620763874079 Epsilon :  0.5511163638816503 ROC_SCORE:  0.6282406388670432\n",
      "Step :  1260 Loss SD :  0.6938112391261565 Loss G :  0.6902322519113901 Epsilon :  0.5533563638816495 ROC_SCORE:  0.6309433709058149\n",
      "Step :  1270 Loss SD :  0.693143515782545 Loss G :  0.6899772279675375 Epsilon :  0.5555963638816486 ROC_SCORE:  0.6334546717596571\n",
      "Step :  1280 Loss SD :  0.6928536611176918 Loss G :  0.6913951369277943 Epsilon :  0.5578363638816477 ROC_SCORE:  0.6379903080561939\n",
      "Step :  1290 Loss SD :  0.692696304123508 Loss G :  0.6912989636425064 Epsilon :  0.5600228233932258 ROC_SCORE:  0.6338987131679987\n",
      "Step :  1300 Loss SD :  0.6933731162917305 Loss G :  0.6914415439604131 Epsilon :  0.562198823393227 ROC_SCORE:  0.6290078437447886\n",
      "Step :  1310 Loss SD :  0.6932421144300177 Loss G :  0.6915447878578196 Epsilon :  0.5643748233932282 ROC_SCORE:  0.6281518305853747\n",
      "Step :  1320 Loss SD :  0.6925807655777858 Loss G :  0.6915358703787376 Epsilon :  0.5665508233932295 ROC_SCORE:  0.6308698573837672\n",
      "Step :  1330 Loss SD :  0.6929725792206078 Loss G :  0.6912952226483083 Epsilon :  0.5687268233932307 ROC_SCORE:  0.6371328147587523\n",
      "Step :  1340 Loss SD :  0.6931666578304075 Loss G :  0.6916128074575258 Epsilon :  0.5709028233932318 ROC_SCORE:  0.6368969794329888\n",
      "Step :  1350 Loss SD :  0.6935329491288479 Loss G :  0.6922255182302065 Epsilon :  0.5730788233932331 ROC_SCORE:  0.6284986762632238\n",
      "Step :  1360 Loss SD :  0.6929910245300543 Loss G :  0.6929496355597086 Epsilon :  0.5752548233932343 ROC_SCORE:  0.6338612163379609\n",
      "Step :  1370 Loss SD :  0.6931378211226205 Loss G :  0.6921561306096495 Epsilon :  0.577378336624275 ROC_SCORE:  0.6175155587175689\n",
      "Step :  1380 Loss SD :  0.6927297433509246 Loss G :  0.6925877807563601 Epsilon :  0.5794903366242763 ROC_SCORE:  0.6291119467860776\n",
      "Step :  1390 Loss SD :  0.6937260625301547 Loss G :  0.6916472073825674 Epsilon :  0.5816023366242776 ROC_SCORE:  0.6280630223037066\n",
      "Step :  1400 Loss SD :  0.692611471453119 Loss G :  0.6924695153467969 Epsilon :  0.583714336624279 ROC_SCORE:  0.6332410385043108\n",
      "Step :  1410 Loss SD :  0.692872668291006 Loss G :  0.6919195290980871 Epsilon :  0.5858263366242803 ROC_SCORE:  0.6280783170633272\n",
      "Step :  1420 Loss SD :  0.6933458496396401 Loss G :  0.6923756498212945 Epsilon :  0.5879383366242816 ROC_SCORE:  0.630663131439217\n",
      "Step :  1430 Loss SD :  0.6937183203076825 Loss G :  0.6928371324243061 Epsilon :  0.590050336624283 ROC_SCORE:  0.6336031789417803\n",
      "Step :  1440 Loss SD :  0.6932214989698051 Loss G :  0.6924160606973253 Epsilon :  0.5921623366242843 ROC_SCORE:  0.6301539639576523\n",
      "Step :  1450 Loss SD :  0.6933097674821693 Loss G :  0.6920259930970272 Epsilon :  0.5942725539346587 ROC_SCORE:  0.6323544358256555\n",
      "Step :  1460 Loss SD :  0.6936262428250204 Loss G :  0.6924047118310972 Epsilon :  0.596320553934658 ROC_SCORE:  0.6359437705430824\n",
      "Step :  1470 Loss SD :  0.6931354537727197 Loss G :  0.6929759307856936 Epsilon :  0.5983685539346574 ROC_SCORE:  0.6334990759004913\n",
      "Step :  1480 Loss SD :  0.6930301455667689 Loss G :  0.6924488434680336 Epsilon :  0.6004165539346566 ROC_SCORE:  0.6268517760176195\n",
      "Step :  1490 Loss SD :  0.6928158696361919 Loss G :  0.6923703191323509 Epsilon :  0.6024645539346559 ROC_SCORE:  0.6356788258361052\n",
      "Step :  1500 Loss SD :  0.6932743179358629 Loss G :  0.6925848044629503 Epsilon :  0.6045125539346552 ROC_SCORE:  0.626142789902301\n",
      "Step :  1510 Loss SD :  0.6933793471494143 Loss G :  0.6926306347891437 Epsilon :  0.6065605539346545 ROC_SCORE:  0.6313499154841186\n",
      "Step :  1520 Loss SD :  0.6929449624109241 Loss G :  0.6929986591397138 Epsilon :  0.6086085539346539 ROC_SCORE:  0.6288386146302765\n",
      "Step :  1530 Loss SD :  0.6931854873179102 Loss G :  0.6925508938152163 Epsilon :  0.6106565539346531 ROC_SCORE:  0.6244583928266592\n",
      "Step :  1540 Loss SD :  0.6931355546756578 Loss G :  0.6932834721006796 Epsilon :  0.6127045539346524 ROC_SCORE:  0.6153096596767971\n",
      "Step :  1550 Loss SD :  0.6934464131050948 Loss G :  0.6939201056581137 Epsilon :  0.6147297457325135 ROC_SCORE:  0.6355969248652336\n",
      "Step :  1560 Loss SD :  0.6929252238130582 Loss G :  0.6945224256910016 Epsilon :  0.6167137457325145 ROC_SCORE:  0.6283141523890907\n",
      "Step :  1570 Loss SD :  0.6932305372473794 Loss G :  0.6929695261529794 Epsilon :  0.6186977457325151 ROC_SCORE:  0.6302052754092827\n",
      "Step :  1580 Loss SD :  0.6930247456593184 Loss G :  0.6931359722144849 Epsilon :  0.6206817457325161 ROC_SCORE:  0.6339653193792498\n",
      "Step :  1590 Loss SD :  0.6930522427840191 Loss G :  0.6927912578474453 Epsilon :  0.6226657457325168 ROC_SCORE:  0.6286762928265605\n",
      "Step :  1600 Loss SD :  0.6933941280789759 Loss G :  0.6923193923490303 Epsilon :  0.6246497457325176 ROC_SCORE:  0.6406639307137522\n",
      "Step :  1610 Loss SD :  0.6933168616021501 Loss G :  0.692415808573909 Epsilon :  0.6266337457325183 ROC_SCORE:  0.6212756026875359\n",
      "Step :  1620 Loss SD :  0.6932991428020667 Loss G :  0.6920005243263871 Epsilon :  0.6286177457325193 ROC_SCORE:  0.6280408202332894\n",
      "Step :  1630 Loss SD :  0.6932845867905449 Loss G :  0.692353881815395 Epsilon :  0.6306017457325199 ROC_SCORE:  0.628402960670759\n",
      "Step :  1640 Loss SD :  0.6925999381709327 Loss G :  0.6916380261728909 Epsilon :  0.6325857457325209 ROC_SCORE:  0.6272805226663403\n",
      "Step :  1650 Loss SD :  0.6935046376575509 Loss G :  0.6925513546291477 Epsilon :  0.6345697457325216 ROC_SCORE:  0.6235801775968282\n",
      "Step :  1660 Loss SD :  0.6934050370975506 Loss G :  0.6918512988993388 Epsilon :  0.6365099438612605 ROC_SCORE:  0.6293339674902484\n",
      "Step :  1670 Loss SD :  0.6935222427741463 Loss G :  0.6919027548081014 Epsilon :  0.6384299438612605 ROC_SCORE:  0.6277467661450989\n",
      "Step :  1680 Loss SD :  0.6936304930032704 Loss G :  0.6920403518277649 Epsilon :  0.6403499438612607 ROC_SCORE:  0.6285208783336409\n",
      "Step :  1690 Loss SD :  0.6936399494807809 Loss G :  0.6922137212948373 Epsilon :  0.6422699438612607 ROC_SCORE:  0.6334990759004913\n",
      "Step :  1700 Loss SD :  0.6929893183772957 Loss G :  0.6924370906295257 Epsilon :  0.6441899438612608 ROC_SCORE:  0.6304633128054634\n",
      "Step :  1710 Loss SD :  0.6936371926607894 Loss G :  0.6914796637821209 Epsilon :  0.6461099438612609 ROC_SCORE:  0.6318605631037113\n",
      "Step :  1720 Loss SD :  0.6926912188532115 Loss G :  0.6911407019905753 Epsilon :  0.6480299438612609 ROC_SCORE:  0.6343856785791465\n",
      "Step :  1730 Loss SD :  0.6930332371470044 Loss G :  0.6915560529200757 Epsilon :  0.649949943861261 ROC_SCORE:  0.6257362453239972\n",
      "Step :  1740 Loss SD :  0.6935687590394846 Loss G :  0.6910884183525795 Epsilon :  0.6518699438612611 ROC_SCORE:  0.6283876659111385\n",
      "Step :  1750 Loss SD :  0.6934427855022669 Loss G :  0.6921810149834463 Epsilon :  0.6537899438612612 ROC_SCORE:  0.6332410385043108\n",
      "Step :  1760 Loss SD :  0.6932841089068446 Loss G :  0.6930089870725635 Epsilon :  0.6557099438612612 ROC_SCORE:  0.6305161043951218\n",
      "Step :  1770 Loss SD :  0.692753047695241 Loss G :  0.6937085643766787 Epsilon :  0.6576299438612614 ROC_SCORE:  0.6322143160923567\n",
      "Step :  1780 Loss SD :  0.6931973304449989 Loss G :  0.6930274656526132 Epsilon :  0.6594943275705912 ROC_SCORE:  0.6304786075650841\n",
      "Step :  1790 Loss SD :  0.6930442215566486 Loss G :  0.6931123333255363 Epsilon :  0.6613503275705913 ROC_SCORE:  0.6264161220581024\n",
      "Step :  1800 Loss SD :  0.6931493021350463 Loss G :  0.6939111029058351 Epsilon :  0.6632063275705914 ROC_SCORE:  0.6254116017165654\n",
      "Step :  1810 Loss SD :  0.6930610427329577 Loss G :  0.6930815646792796 Epsilon :  0.6650623275705915 ROC_SCORE:  0.6269918957509184\n",
      "Step :  1820 Loss SD :  0.6931025595126832 Loss G :  0.6938245934015549 Epsilon :  0.6669183275705916 ROC_SCORE:  0.6318674704145076\n",
      "Step :  1830 Loss SD :  0.693216359757155 Loss G :  0.6932110225363516 Epsilon :  0.6687743275705916 ROC_SCORE:  0.6360034694435373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step :  1840 Loss SD :  0.6932099539960238 Loss G :  0.6932786193338609 Epsilon :  0.6706303275705917 ROC_SCORE:  0.6269780811293255\n",
      "Step :  1850 Loss SD :  0.6935359952545368 Loss G :  0.6926771048852605 Epsilon :  0.6724863275705918 ROC_SCORE:  0.6299694400835193\n",
      "Step :  1860 Loss SD :  0.6932919475304926 Loss G :  0.6927356666074668 Epsilon :  0.6743423275705919 ROC_SCORE:  0.6305230117059183\n",
      "Step :  1870 Loss SD :  0.6932891793408535 Loss G :  0.6928281071071407 Epsilon :  0.676198327570592 ROC_SCORE:  0.6251091601795506\n",
      "Step :  1880 Loss SD :  0.6930374281525629 Loss G :  0.6932131969520305 Epsilon :  0.678054327570592 ROC_SCORE:  0.6335878841821596\n",
      "Step :  1890 Loss SD :  0.6933260395127183 Loss G :  0.6923352208990898 Epsilon :  0.6799103275705921 ROC_SCORE:  0.6317342579920052\n",
      "Step :  1900 Loss SD :  0.6930749178001437 Loss G :  0.6921698763457014 Epsilon :  0.6817663275705922 ROC_SCORE:  0.6284473648115932\n",
      "Step :  1910 Loss SD :  0.6934739518462869 Loss G :  0.6920345633155587 Epsilon :  0.6835749174805614 ROC_SCORE:  0.6326346752922533\n",
      "Step :  1920 Loss SD :  0.6931276319141404 Loss G :  0.6919522117927045 Epsilon :  0.6853669174805624 ROC_SCORE:  0.6251091601795506\n",
      "Step :  1930 Loss SD :  0.693271543707477 Loss G :  0.6919756680901992 Epsilon :  0.6871589174805632 ROC_SCORE:  0.6273027247367574\n",
      "Step :  1940 Loss SD :  0.6929198649316198 Loss G :  0.6922451268233878 Epsilon :  0.6889509174805641 ROC_SCORE:  0.6267935572551925\n",
      "Step :  1950 Loss SD :  0.6929791754215391 Loss G :  0.6915979582552791 Epsilon :  0.6907429174805649 ROC_SCORE:  0.6251604716311813\n",
      "Step :  1960 Loss SD :  0.693246258908369 Loss G :  0.6910863587192383 Epsilon :  0.692534917480566 ROC_SCORE:  0.630456405494667\n",
      "Step :  1970 Loss SD :  0.6929521199280362 Loss G :  0.6914394813231262 Epsilon :  0.6943269174805666 ROC_SCORE:  0.6265715365510218\n",
      "Step :  1980 Loss SD :  0.693078163245014 Loss G :  0.6911206511238515 Epsilon :  0.6961189174805676 ROC_SCORE:  0.624377971993815\n",
      "Step :  1990 Loss SD :  0.6927574575437203 Loss G :  0.6906941227206264 Epsilon :  0.6979109174805684 ROC_SCORE:  0.6288455219410727\n",
      "Step :  2000 Loss SD :  0.6933992070059609 Loss G :  0.6907254703191992 Epsilon :  0.6997029174805695 ROC_SCORE:  0.6296142069568461\n",
      "Step :  2010 Loss SD :  0.693456740823394 Loss G :  0.690392097743499 Epsilon :  0.7014949174805701 ROC_SCORE:  0.6331078260818082\n",
      "Step :  2020 Loss SD :  0.6929264202710359 Loss G :  0.6908169349290063 Epsilon :  0.7032869174805711 ROC_SCORE:  0.6346812128053647\n",
      "Step :  2030 Loss SD :  0.6929329116770974 Loss G :  0.690729848810808 Epsilon :  0.7050789174805719 ROC_SCORE:  0.6258181462948692\n",
      "Step :  2040 Loss SD :  0.6930759236132595 Loss G :  0.690900671876153 Epsilon :  0.7068709174805728 ROC_SCORE:  0.6192527473828693\n",
      "Step :  2050 Loss SD :  0.6934600602225889 Loss G :  0.6906674174114088 Epsilon :  0.7086566604606725 ROC_SCORE:  0.623742499400544\n",
      "Step :  2060 Loss SD :  0.6929336022352308 Loss G :  0.6908574052518179 Epsilon :  0.7103846604606717 ROC_SCORE:  0.6247761291232945\n",
      "Step :  2070 Loss SD :  0.6934410410857588 Loss G :  0.6913170265724117 Epsilon :  0.7121126604606709 ROC_SCORE:  0.6309364635950185\n",
      "Step :  2080 Loss SD :  0.6930603168510197 Loss G :  0.6910453951415428 Epsilon :  0.71384066046067 ROC_SCORE:  0.6350280584832138\n",
      "Step :  2090 Loss SD :  0.693342866396532 Loss G :  0.6909683364242676 Epsilon :  0.7155686604606691 ROC_SCORE:  0.63162324763992\n",
      "Step :  2100 Loss SD :  0.6932103230261856 Loss G :  0.6906388795263502 Epsilon :  0.7172966604606683 ROC_SCORE:  0.6276495704146065\n",
      "Step :  2110 Loss SD :  0.6936265249501531 Loss G :  0.6901865433355914 Epsilon :  0.7190246604606674 ROC_SCORE:  0.623535773455994\n",
      "Step :  2120 Loss SD :  0.6931567291224476 Loss G :  0.6907610778511766 Epsilon :  0.7207526604606665 ROC_SCORE:  0.6271251081734209\n",
      "Step :  2130 Loss SD :  0.692599006787303 Loss G :  0.6903578980656976 Epsilon :  0.7224806604606656 ROC_SCORE:  0.6267269510439414\n",
      "Step :  2140 Loss SD :  0.6928506024998721 Loss G :  0.6903625234991888 Epsilon :  0.7242086604606648 ROC_SCORE:  0.6292298644489595\n",
      "Step :  2150 Loss SD :  0.6929954952046271 Loss G :  0.6904177656101377 Epsilon :  0.725936660460664 ROC_SCORE:  0.6286318886857263\n",
      "Step :  2160 Loss SD :  0.6930468155707752 Loss G :  0.6902868667933931 Epsilon :  0.727664660460663 ROC_SCORE:  0.6257293380132009\n",
      "Step :  2170 Loss SD :  0.6930479815504216 Loss G :  0.6901779485613578 Epsilon :  0.7293926604606622 ROC_SCORE:  0.6257362453239972\n",
      "Step :  2180 Loss SD :  0.6933549091687291 Loss G :  0.6897567118553862 Epsilon :  0.7311206604606613 ROC_SCORE:  0.6234247631039086\n",
      "Step :  2190 Loss SD :  0.6936907213856905 Loss G :  0.689585220398813 Epsilon :  0.7328486604606604 ROC_SCORE:  0.626305111706017\n",
      "Step :  2200 Loss SD :  0.6930344279159513 Loss G :  0.6895261530976016 Epsilon :  0.7345766604606596 ROC_SCORE:  0.6245249990379103\n",
      "Step :  2210 Loss SD :  0.6940505095602342 Loss G :  0.6893094607978669 Epsilon :  0.7363046604606587 ROC_SCORE:  0.6352500791873845\n",
      "Step :  2220 Loss SD :  0.6924222014702854 Loss G :  0.6894444086250957 Epsilon :  0.7379880148790793 ROC_SCORE:  0.6256183276611155\n",
      "Step :  2230 Loss SD :  0.6932318957270065 Loss G :  0.689983238058254 Epsilon :  0.739652014879081 ROC_SCORE:  0.6292298644489595\n",
      "Step :  2240 Loss SD :  0.6926122926246063 Loss G :  0.6906804375779092 Epsilon :  0.7413160148790826 ROC_SCORE:  0.622162205366191\n",
      "Step :  2250 Loss SD :  0.6930511070400756 Loss G :  0.6908615018575592 Epsilon :  0.7429800148790844 ROC_SCORE:  0.6293048581090349\n",
      "Step :  2260 Loss SD :  0.6931571026227048 Loss G :  0.6911191788814915 Epsilon :  0.7446440148790859 ROC_SCORE:  0.6320366995290202\n",
      "Step :  2270 Loss SD :  0.6932810840744985 Loss G :  0.6911470923863243 Epsilon :  0.7463080148790877 ROC_SCORE:  0.6219623867324374\n",
      "Step :  2280 Loss SD :  0.69342194322711 Loss G :  0.6909381011241964 Epsilon :  0.7479720148790893 ROC_SCORE:  0.624909341545797\n",
      "Step :  2290 Loss SD :  0.6933538947827704 Loss G :  0.6912887781007861 Epsilon :  0.749636014879091 ROC_SCORE:  0.6235426807667904\n",
      "Step :  2300 Loss SD :  0.692973299128398 Loss G :  0.691799284760689 Epsilon :  0.7513000148790926 ROC_SCORE:  0.6327900897851727\n",
      "Step :  2310 Loss SD :  0.6931269519994248 Loss G :  0.6917165509744119 Epsilon :  0.7529640148790944 ROC_SCORE:  0.6249981498274653\n",
      "Step :  2320 Loss SD :  0.6930853346159032 Loss G :  0.6922986247728475 Epsilon :  0.7546280148790959 ROC_SCORE:  0.6313499154841186\n",
      "Step :  2330 Loss SD :  0.6931234184998369 Loss G :  0.6920072276292929 Epsilon :  0.7562920148790977 ROC_SCORE:  0.6307519397208854\n",
      "Step :  2340 Loss SD :  0.6930630997258308 Loss G :  0.6925729975300601 Epsilon :  0.7579560148790992 ROC_SCORE:  0.6299319432534816\n",
      "Step :  2350 Loss SD :  0.6931711614072893 Loss G :  0.6925780823886931 Epsilon :  0.759620014879101 ROC_SCORE:  0.624909341545797\n",
      "Step :  2360 Loss SD :  0.6931245751041054 Loss G :  0.6923704352640065 Epsilon :  0.7612840148791026 ROC_SCORE:  0.6324210420369067\n",
      "Step :  2370 Loss SD :  0.692959454452559 Loss G :  0.6925970167622382 Epsilon :  0.7629480148791044 ROC_SCORE:  0.6294740872235474\n",
      "Step :  2380 Loss SD :  0.6931641294817181 Loss G :  0.6926281153937671 Epsilon :  0.7646120148791059 ROC_SCORE:  0.6288761114603141\n",
      "Step :  2390 Loss SD :  0.6930850777297466 Loss G :  0.6929812548591838 Epsilon :  0.7662760148791077 ROC_SCORE:  0.626926769677695\n",
      "Step :  2400 Loss SD :  0.693056057314931 Loss G :  0.6925095404222847 Epsilon :  0.7679241821656911 ROC_SCORE:  0.6242072627412749\n",
      "Step :  2410 Loss SD :  0.69317631971895 Loss G :  0.6924875902556533 Epsilon :  0.7695241821656927 ROC_SCORE:  0.6228045852702584\n",
      "Step :  2420 Loss SD :  0.6931040350675443 Loss G :  0.6924447996454494 Epsilon :  0.7711241821656943 ROC_SCORE:  0.6178791792930663\n",
      "Step :  2430 Loss SD :  0.6929645096169568 Loss G :  0.691890002349586 Epsilon :  0.7727241821656959 ROC_SCORE:  0.6323031243740249\n",
      "Step :  2440 Loss SD :  0.6925834343865154 Loss G :  0.691737194946992 Epsilon :  0.7743241821656975 ROC_SCORE:  0.6385591744382136\n",
      "Step :  2450 Loss SD :  0.6931932121089794 Loss G :  0.691390450499508 Epsilon :  0.7759241821656991 ROC_SCORE:  0.6282628409374602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step :  2460 Loss SD :  0.6931655043884364 Loss G :  0.6911153986029208 Epsilon :  0.7775241821657007 ROC_SCORE:  0.6285361730932615\n",
      "Step :  2470 Loss SD :  0.6934415283644164 Loss G :  0.6912900422760895 Epsilon :  0.7791241821657023 ROC_SCORE:  0.6249759477570481\n",
      "Step :  2480 Loss SD :  0.6931232740679483 Loss G :  0.691259401800715 Epsilon :  0.7807241821657039 ROC_SCORE:  0.6240977325272172\n",
      "Step :  2490 Loss SD :  0.6932041592137168 Loss G :  0.6909326584261255 Epsilon :  0.7823241821657055 ROC_SCORE:  0.6313277134137015\n",
      "Step :  2500 Loss SD :  0.6932986687229493 Loss G :  0.6907635402850797 Epsilon :  0.7839241821657071 ROC_SCORE:  0.6242003554304785\n",
      "Step :  2510 Loss SD :  0.6928479311695384 Loss G :  0.6906822732834943 Epsilon :  0.7855241821657087 ROC_SCORE:  0.6305674158467525\n",
      "Step :  2520 Loss SD :  0.6932965496592894 Loss G :  0.6908930626437275 Epsilon :  0.7871241821657103 ROC_SCORE:  0.6286832001373568\n",
      "Step :  2530 Loss SD :  0.6929242837148921 Loss G :  0.6912674587422749 Epsilon :  0.7887241821657119 ROC_SCORE:  0.634703414875782\n",
      "Step :  2540 Loss SD :  0.6931772797333101 Loss G :  0.6915373300404082 Epsilon :  0.7903241821657135 ROC_SCORE:  0.6247623145017018\n",
      "Step :  2550 Loss SD :  0.6929517350636848 Loss G :  0.6915595950231649 Epsilon :  0.7919241821657151 ROC_SCORE:  0.6215267327729201\n",
      "Step :  2560 Loss SD :  0.6931200775016759 Loss G :  0.6908338816645581 Epsilon :  0.7935241821657167 ROC_SCORE:  0.6209218496988905\n",
      "Step :  2570 Loss SD :  0.6932216212288926 Loss G :  0.6909251673089818 Epsilon :  0.7951241821657183 ROC_SCORE:  0.6313583029329429\n",
      "Step :  2580 Loss SD :  0.6933181057622618 Loss G :  0.6905827256955461 Epsilon :  0.7967241821657199 ROC_SCORE:  0.6288164125598592\n",
      "Step :  2590 Loss SD :  0.6932527259278358 Loss G :  0.6904694261745186 Epsilon :  0.7983241821657215 ROC_SCORE:  0.6301608712684487\n",
      "Step :  2600 Loss SD :  0.6930828965867271 Loss G :  0.690445276843736 Epsilon :  0.7999241821657231 ROC_SCORE:  0.6206110207130515\n",
      "Step :  2610 Loss SD :  0.6932539772236908 Loss G :  0.6908805413666513 Epsilon :  0.8014991813902583 ROC_SCORE:  0.6293339674902484\n",
      "Step :  2620 Loss SD :  0.6929557224591246 Loss G :  0.6911666919215262 Epsilon :  0.803035181390257 ROC_SCORE:  0.6312097957508197\n",
      "Step :  2630 Loss SD :  0.6933736488969315 Loss G :  0.6912753212656308 Epsilon :  0.8045711813902556 ROC_SCORE:  0.60481350754229\n",
      "Step :  2640 Loss SD :  0.6932725606001768 Loss G :  0.6911385861835009 Epsilon :  0.8061071813902542 ROC_SCORE:  0.6265424271698082\n",
      "Step :  2650 Loss SD :  0.6931488175255662 Loss G :  0.6915626514586071 Epsilon :  0.8076431813902528 ROC_SCORE:  0.6220220856328921\n",
      "Step :  2660 Loss SD :  0.6927569947092316 Loss G :  0.6911718317509674 Epsilon :  0.8091791813902514 ROC_SCORE:  0.6252936840536836\n",
      "Step :  2670 Loss SD :  0.6927799729961084 Loss G :  0.6907171151695597 Epsilon :  0.81071518139025 ROC_SCORE:  0.633374250926813\n",
      "Step :  2680 Loss SD :  0.6928767378216867 Loss G :  0.6901968117241712 Epsilon :  0.8122511813902485 ROC_SCORE:  0.6251091601795506\n",
      "Step :  2690 Loss SD :  0.6940180342173569 Loss G :  0.6890330452993395 Epsilon :  0.8137871813902472 ROC_SCORE:  0.6220067908732716\n",
      "Step :  2700 Loss SD :  0.693155420942775 Loss G :  0.689086931154774 Epsilon :  0.8153231813902458 ROC_SCORE:  0.6275982589629757\n",
      "Step :  2710 Loss SD :  0.6935906189297849 Loss G :  0.6888821541322709 Epsilon :  0.8168591813902444 ROC_SCORE:  0.6276939745554405\n",
      "Step :  2720 Loss SD :  0.693824849257164 Loss G :  0.6886289434799192 Epsilon :  0.818395181390243 ROC_SCORE:  0.6227088696777937\n",
      "Step :  2730 Loss SD :  0.6927590286100103 Loss G :  0.6890628467962132 Epsilon :  0.8199311813902416 ROC_SCORE:  0.6273027247367574\n",
      "Step :  2740 Loss SD :  0.6942053373413375 Loss G :  0.6889762597481685 Epsilon :  0.8214671813902402 ROC_SCORE:  0.6302427722393207\n",
      "Step :  2750 Loss SD :  0.6930770565434653 Loss G :  0.6889390547012608 Epsilon :  0.8230031813902388 ROC_SCORE:  0.626800464565989\n",
      "Step :  2760 Loss SD :  0.6938203016411016 Loss G :  0.6890443545915266 Epsilon :  0.8245391813902374 ROC_SCORE:  0.6234913693151598\n",
      "Step :  2770 Loss SD :  0.693567250640384 Loss G :  0.6892501871094395 Epsilon :  0.826075181390236 ROC_SCORE:  0.6269183822288709\n",
      "Step :  2780 Loss SD :  0.6935041320776285 Loss G :  0.6895263356868414 Epsilon :  0.8276111813902346 ROC_SCORE:  0.6241712460492649\n",
      "Step :  2790 Loss SD :  0.6926262569234992 Loss G :  0.6893628465199179 Epsilon :  0.8291471813902332 ROC_SCORE:  0.6254490985466031\n",
      "Step :  2800 Loss SD :  0.6932762152621764 Loss G :  0.6890267971032707 Epsilon :  0.8306831813902318 ROC_SCORE:  0.6203598906276673\n",
      "Step :  2810 Loss SD :  0.6940070747199049 Loss G :  0.6888208942173376 Epsilon :  0.8322191813902304 ROC_SCORE:  0.6252936840536836\n",
      "Step :  2820 Loss SD :  0.6935649795568285 Loss G :  0.6888003799638915 Epsilon :  0.833755181390229 ROC_SCORE:  0.6342455588458477\n",
      "Step :  2830 Loss SD :  0.6931576735594018 Loss G :  0.6885742007806177 Epsilon :  0.8352911813902276 ROC_SCORE:  0.6170729974472553\n",
      "Step :  2840 Loss SD :  0.6930725593046896 Loss G :  0.6889104186940314 Epsilon :  0.8368271813902262 ROC_SCORE:  0.6245180917271139\n",
      "Step :  2850 Loss SD :  0.6935311130777393 Loss G :  0.6892333914376602 Epsilon :  0.8383190350898989 ROC_SCORE:  0.6265715365510218\n",
      "Step :  2860 Loss SD :  0.6931533935381642 Loss G :  0.6896379958250141 Epsilon :  0.8397910350898993 ROC_SCORE:  0.6199908428794013\n",
      "Step :  2870 Loss SD :  0.6933437847398984 Loss G :  0.6898276315953575 Epsilon :  0.8412630350898996 ROC_SCORE:  0.6239201159638806\n",
      "Step :  2880 Loss SD :  0.6934760639691212 Loss G :  0.6899113950952749 Epsilon :  0.8427350350899 ROC_SCORE:  0.6233221402006475\n",
      "Step :  2890 Loss SD :  0.6933987802643572 Loss G :  0.690061790892911 Epsilon :  0.8442070350899002 ROC_SCORE:  0.6207511404463505\n",
      "Step :  2900 Loss SD :  0.6924715958897285 Loss G :  0.6900525393000785 Epsilon :  0.8456790350899006 ROC_SCORE:  0.6209953632209383\n",
      "Step :  2910 Loss SD :  0.6926299516721524 Loss G :  0.689638122622113 Epsilon :  0.847151035089901 ROC_SCORE:  0.6233956537226952\n",
      "Step :  2920 Loss SD :  0.6933382486213291 Loss G :  0.6896300019183943 Epsilon :  0.8486230350899013 ROC_SCORE:  0.6277536734558954\n",
      "Step :  2930 Loss SD :  0.6932654636476245 Loss G :  0.6895624819650873 Epsilon :  0.8500950350899017 ROC_SCORE:  0.6251091601795506\n",
      "Step :  2940 Loss SD :  0.692482908947227 Loss G :  0.6893740712764782 Epsilon :  0.851567035089902 ROC_SCORE:  0.6219998835624752\n",
      "Step :  2950 Loss SD :  0.692721369402272 Loss G :  0.6884879529622874 Epsilon :  0.8530390350899023 ROC_SCORE:  0.620455606220132\n",
      "Step :  2960 Loss SD :  0.6930151160239766 Loss G :  0.6886153729979141 Epsilon :  0.8545110350899027 ROC_SCORE:  0.6307741417913025\n",
      "Step :  2970 Loss SD :  0.6932841124474836 Loss G :  0.689033523224566 Epsilon :  0.855983035089903 ROC_SCORE:  0.626142789902301\n",
      "Step :  2980 Loss SD :  0.692278514438178 Loss G :  0.6890799657555442 Epsilon :  0.8574550350899034 ROC_SCORE:  0.617930490744697\n",
      "Step :  2990 Loss SD :  0.6926597354416801 Loss G :  0.6892078409273537 Epsilon :  0.8589270350899038 ROC_SCORE:  0.6221330959849776\n",
      "Step :  3000 Loss SD :  0.6937520518976402 Loss G :  0.6894957588338678 Epsilon :  0.860399035089904 ROC_SCORE:  0.6202863771056197\n",
      "Step :  3010 Loss SD :  0.6932424402893429 Loss G :  0.6902450887144236 Epsilon :  0.8618710350899044 ROC_SCORE:  0.6224424448327888\n",
      "Step :  3020 Loss SD :  0.6926134349866009 Loss G :  0.6899747856826508 Epsilon :  0.8633430350899047 ROC_SCORE:  0.6279229025704076\n",
      "Step :  3030 Loss SD :  0.6921786858635472 Loss G :  0.6900061715716018 Epsilon :  0.8648150350899051 ROC_SCORE:  0.6149460391012996\n",
      "Step :  3040 Loss SD :  0.6933518956333194 Loss G :  0.6899799622012288 Epsilon :  0.8662870350899055 ROC_SCORE:  0.6276204610333929\n",
      "Step :  3050 Loss SD :  0.6935027243263167 Loss G :  0.689468969956758 Epsilon :  0.8677590350899057 ROC_SCORE:  0.6266450500730695\n",
      "Step :  3060 Loss SD :  0.6932945132739461 Loss G :  0.6893464695193027 Epsilon :  0.8692310350899061 ROC_SCORE:  0.6172353192509712\n",
      "Step :  3070 Loss SD :  0.6924579112709413 Loss G :  0.6894401623576336 Epsilon :  0.8707030350899064 ROC_SCORE:  0.6257071359427838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step :  3080 Loss SD :  0.6932627694148632 Loss G :  0.6896460804439136 Epsilon :  0.8721750350899068 ROC_SCORE:  0.6271029061030038\n",
      "Step :  3090 Loss SD :  0.693763810165163 Loss G :  0.6895654447783292 Epsilon :  0.8736470350899072 ROC_SCORE:  0.6271848070738757\n",
      "Step :  3100 Loss SD :  0.6931069339456573 Loss G :  0.6894531340915678 Epsilon :  0.8751190350899075 ROC_SCORE:  0.6123099132737791\n",
      "Step :  3110 Loss SD :  0.6927565488296603 Loss G :  0.6888865396691609 Epsilon :  0.8765910350899078 ROC_SCORE:  0.6294365903935095\n",
      "Step :  3120 Loss SD :  0.6926226002398312 Loss G :  0.6888921382951054 Epsilon :  0.8780244367606121 ROC_SCORE:  0.6282850430078772\n",
      "Step :  3130 Loss SD :  0.6935144217559803 Loss G :  0.6893153768910577 Epsilon :  0.8794324367606111 ROC_SCORE:  0.6243044584717674\n",
      "Step :  3140 Loss SD :  0.6932808072139883 Loss G :  0.6891336707322996 Epsilon :  0.8808404367606102 ROC_SCORE:  0.6211798870950712\n",
      "Step :  3150 Loss SD :  0.6936390369809774 Loss G :  0.68929246334853 Epsilon :  0.8822484367606093 ROC_SCORE:  0.6083584381188827\n",
      "Step :  3160 Loss SD :  0.6934965351887521 Loss G :  0.6894957824232272 Epsilon :  0.8836564367606082 ROC_SCORE:  0.6266159406918559\n",
      "Step :  3170 Loss SD :  0.6928365886448411 Loss G :  0.6897901262555828 Epsilon :  0.8850644367606073 ROC_SCORE:  0.6245333864867344\n",
      "Step :  3180 Loss SD :  0.6932548980019407 Loss G :  0.68987464998663 Epsilon :  0.8864724367606064 ROC_SCORE:  0.6278937931891941\n",
      "Step :  3190 Loss SD :  0.6930376221144412 Loss G :  0.6894182758199664 Epsilon :  0.8878804367606054 ROC_SCORE:  0.6282115294858297\n",
      "Step :  3200 Loss SD :  0.6926832600746989 Loss G :  0.6893900547077434 Epsilon :  0.8892884367606044 ROC_SCORE:  0.6266381427622731\n",
      "Step :  3210 Loss SD :  0.6936252416752979 Loss G :  0.6893864162969637 Epsilon :  0.8906964367606035 ROC_SCORE:  0.6301761660280694\n",
      "Step :  3220 Loss SD :  0.6930318451701261 Loss G :  0.6893245661403375 Epsilon :  0.8921044367606025 ROC_SCORE:  0.6247845165721186\n",
      "Step :  3230 Loss SD :  0.6929079724370525 Loss G :  0.6892099532675907 Epsilon :  0.8935124367606015 ROC_SCORE:  0.6225756572552912\n",
      "Step :  3240 Loss SD :  0.6930316288094405 Loss G :  0.6894394855082445 Epsilon :  0.8949204367606006 ROC_SCORE:  0.6280783170633272\n",
      "Step :  3250 Loss SD :  0.6936652675103342 Loss G :  0.689431181915186 Epsilon :  0.8963284367605996 ROC_SCORE:  0.6303897992834159\n",
      "Step :  3260 Loss SD :  0.6924595216669849 Loss G :  0.6893923479903817 Epsilon :  0.8977364367605987 ROC_SCORE:  0.6252714819832665\n",
      "Step :  3270 Loss SD :  0.6931691223219147 Loss G :  0.6892674162667657 Epsilon :  0.8991444367605977 ROC_SCORE:  0.6266159406918559\n",
      "Step :  3280 Loss SD :  0.6935292997142133 Loss G :  0.6891731526197614 Epsilon :  0.9005524367605967 ROC_SCORE:  0.6242156501900991\n",
      "Step :  3290 Loss SD :  0.6931071775286645 Loss G :  0.6895396093929865 Epsilon :  0.9019604367605958 ROC_SCORE:  0.6276579578634306\n",
      "Step :  3300 Loss SD :  0.6927678844587739 Loss G :  0.6890130440818161 Epsilon :  0.9033684367605949 ROC_SCORE:  0.6271182008626244\n",
      "Step :  3310 Loss SD :  0.69327190342928 Loss G :  0.6893946299666199 Epsilon :  0.9047764367605938 ROC_SCORE:  0.6274359371592598\n",
      "Step :  3320 Loss SD :  0.6930747842828795 Loss G :  0.6892672031819931 Epsilon :  0.9061844367605929 ROC_SCORE:  0.6299916421539362\n",
      "Step :  3330 Loss SD :  0.693534418199368 Loss G :  0.6891134997072388 Epsilon :  0.907592436760592 ROC_SCORE:  0.6253380881945176\n",
      "Step :  3340 Loss SD :  0.6932796659373118 Loss G :  0.6892076560225973 Epsilon :  0.909000436760591 ROC_SCORE:  0.6292895633494142\n",
      "Step :  3350 Loss SD :  0.6931633427262744 Loss G :  0.6891131196031437 Epsilon :  0.91040843676059 ROC_SCORE:  0.6215267327729201\n",
      "Step :  3360 Loss SD :  0.6924850120649247 Loss G :  0.6888476685925458 Epsilon :  0.9118164367605891 ROC_SCORE:  0.6153081795387694\n",
      "Step :  3370 Loss SD :  0.6941498097177881 Loss G :  0.6886218962849369 Epsilon :  0.9132244367605881 ROC_SCORE:  0.6249024342350006\n",
      "Step :  3380 Loss SD :  0.6930432339848721 Loss G :  0.6884229691962704 Epsilon :  0.9146324367605871 ROC_SCORE:  0.6221844074366082\n",
      "Step :  3390 Loss SD :  0.6925550547090016 Loss G :  0.6883461346628509 Epsilon :  0.9160404367605862 ROC_SCORE:  0.6305008096355011\n",
      "Step :  3400 Loss SD :  0.6930439976743343 Loss G :  0.6883110401843371 Epsilon :  0.9174484367605852 ROC_SCORE:  0.622982201833595\n",
      "Step :  3410 Loss SD :  0.6926788203165096 Loss G :  0.6880446774622956 Epsilon :  0.9188564367605843 ROC_SCORE:  0.6316454497103369\n",
      "Step :  3420 Loss SD :  0.6934518095635627 Loss G :  0.688467721652406 Epsilon :  0.9202644367605833 ROC_SCORE:  0.6111652731989433\n",
      "Step :  3430 Loss SD :  0.6928796910601569 Loss G :  0.6887623696737324 Epsilon :  0.9216434185988615 ROC_SCORE:  0.6163349019507233\n",
      "Step :  3440 Loss SD :  0.693668749570201 Loss G :  0.6890202051477649 Epsilon :  0.9229874185988599 ROC_SCORE:  0.6244514855158627\n",
      "Step :  3450 Loss SD :  0.6932891296595439 Loss G :  0.6888963183015622 Epsilon :  0.9243314185988588 ROC_SCORE:  0.6149682411717168\n",
      "Step :  3460 Loss SD :  0.6933819668546866 Loss G :  0.6895201366079574 Epsilon :  0.9256754185988573 ROC_SCORE:  0.6261802867323387\n",
      "Step :  3470 Loss SD :  0.6937521675197443 Loss G :  0.6899671799731429 Epsilon :  0.9270194185988562 ROC_SCORE:  0.6233290475114438\n",
      "Step :  3480 Loss SD :  0.6936856692819997 Loss G :  0.6897447378938404 Epsilon :  0.9283634185988546 ROC_SCORE:  0.623188927778145\n",
      "Step :  3490 Loss SD :  0.6932608339934668 Loss G :  0.6897475202483082 Epsilon :  0.9297074185988535 ROC_SCORE:  0.6244001740642321\n",
      "Step :  3500 Loss SD :  0.6937113325365685 Loss G :  0.6901910392101568 Epsilon :  0.931051418598852 ROC_SCORE:  0.6174351378847249\n",
      "Step :  3510 Loss SD :  0.6929812337017163 Loss G :  0.6904705342019956 Epsilon :  0.9323954185988509 ROC_SCORE:  0.6336391956337902\n",
      "Step :  3520 Loss SD :  0.6934379957956696 Loss G :  0.6908693464860207 Epsilon :  0.9337394185988493 ROC_SCORE:  0.631934076625759\n",
      "Step :  3530 Loss SD :  0.6932682843429387 Loss G :  0.6918861547066882 Epsilon :  0.9350834185988482 ROC_SCORE:  0.6265271324101876\n",
      "Step :  3540 Loss SD :  0.6930191862204484 Loss G :  0.6920080581969741 Epsilon :  0.9364274185988467 ROC_SCORE:  0.6257224307024044\n",
      "Step :  3550 Loss SD :  0.6933879696686996 Loss G :  0.692213915302442 Epsilon :  0.9377714185988456 ROC_SCORE:  0.6326874668819117\n",
      "Step :  3560 Loss SD :  0.6930396277246553 Loss G :  0.6927228637708915 Epsilon :  0.9391154185988441 ROC_SCORE:  0.6204264968389186\n",
      "Step :  3570 Loss SD :  0.6931342722376926 Loss G :  0.6928695586880363 Epsilon :  0.940459418598843 ROC_SCORE:  0.6255892182799019\n",
      "Step :  3580 Loss SD :  0.6931493832604139 Loss G :  0.6930995282032978 Epsilon :  0.9418034185988414 ROC_SCORE:  0.6289496249823616\n",
      "Step :  3590 Loss SD :  0.6931302860360076 Loss G :  0.6933309337730575 Epsilon :  0.9431474185988403 ROC_SCORE:  0.6256627318019496\n",
      "Step :  3600 Loss SD :  0.6931367164250954 Loss G :  0.6935681295464579 Epsilon :  0.9444914185988388 ROC_SCORE:  0.6302871763801547\n",
      "Step :  3610 Loss SD :  0.6931500129399839 Loss G :  0.6932215427160769 Epsilon :  0.9458354185988377 ROC_SCORE:  0.622450832281613\n",
      "Step :  3620 Loss SD :  0.6931472250879419 Loss G :  0.6928237644951543 Epsilon :  0.9471794185988361 ROC_SCORE:  0.6238535097526295\n",
      "Step :  3630 Loss SD :  0.6931473704063961 Loss G :  0.6925260046790259 Epsilon :  0.948523418598835 ROC_SCORE:  0.6217931576179251\n",
      "Step :  3640 Loss SD :  0.6931472453742922 Loss G :  0.6927969938350854 Epsilon :  0.9498674185988335 ROC_SCORE:  0.6229377976927608\n",
      "Step :  3650 Loss SD :  0.6931730310155098 Loss G :  0.6929304161383467 Epsilon :  0.9512114185988324 ROC_SCORE:  0.6219041679700104\n",
      "Step :  3660 Loss SD :  0.6930282292914913 Loss G :  0.6924151725228127 Epsilon :  0.9525554185988309 ROC_SCORE:  0.6267782624955719\n",
      "Step :  3670 Loss SD :  0.6931146112924016 Loss G :  0.6920929243967912 Epsilon :  0.9538994185988298 ROC_SCORE:  0.6297627141389691\n",
      "Step :  3680 Loss SD :  0.6931120793309964 Loss G :  0.6925750419895735 Epsilon :  0.9552434185988282 ROC_SCORE:  0.6210022705317346\n",
      "Step :  3690 Loss SD :  0.6931392889333017 Loss G :  0.6928950272556732 Epsilon :  0.9565874185988271 ROC_SCORE:  0.628484861641631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step :  3700 Loss SD :  0.6931359032688365 Loss G :  0.693092364755208 Epsilon :  0.9579314185988256 ROC_SCORE:  0.6236245817376622\n",
      "Step :  3710 Loss SD :  0.6931472562064864 Loss G :  0.6935645413928212 Epsilon :  0.9592754185988245 ROC_SCORE:  0.6239201159638806\n",
      "Step :  3720 Loss SD :  0.6929008175463716 Loss G :  0.6940494077056717 Epsilon :  0.9606194185988229 ROC_SCORE:  0.6327096689523287\n",
      "Step :  3730 Loss SD :  0.6929374755965719 Loss G :  0.6945108233772513 Epsilon :  0.9619634185988218 ROC_SCORE:  0.622982201833595\n",
      "Step :  3740 Loss SD :  0.6928976880640286 Loss G :  0.6944749111149772 Epsilon :  0.9633074185988203 ROC_SCORE:  0.6213353015879908\n",
      "Step :  3750 Loss SD :  0.6931732486861002 Loss G :  0.6939837796343624 Epsilon :  0.9646514185988192 ROC_SCORE:  0.6277314713854782\n",
      "Step :  3760 Loss SD :  0.6930598861565199 Loss G :  0.6945760928125668 Epsilon :  0.9659954185988177 ROC_SCORE:  0.620455606220132\n",
      "Step :  3770 Loss SD :  0.6932880106495279 Loss G :  0.6942373499959501 Epsilon :  0.9673394185988166 ROC_SCORE:  0.6246957082904504\n",
      "Step :  3780 Loss SD :  0.6932401236877086 Loss G :  0.6935459425663428 Epsilon :  0.968683418598815 ROC_SCORE:  0.6244667802754833\n",
      "Step :  3790 Loss SD :  0.6931505646895293 Loss G :  0.6932541002943139 Epsilon :  0.9700027564197198 ROC_SCORE:  0.6286762928265605\n",
      "Step :  3800 Loss SD :  0.6931727866568816 Loss G :  0.6933172335446616 Epsilon :  0.9712827564197192 ROC_SCORE:  0.6187435799013044\n",
      "Step :  3810 Loss SD :  0.6931472467319887 Loss G :  0.6935263340501759 Epsilon :  0.9725627564197186 ROC_SCORE:  0.6333520488563961\n",
      "Step :  3820 Loss SD :  0.6931617906464009 Loss G :  0.693029094680116 Epsilon :  0.973842756419718 ROC_SCORE:  0.6268448687068231\n",
      "Step :  3830 Loss SD :  0.693134491305197 Loss G :  0.6932569955861125 Epsilon :  0.9751227564197174 ROC_SCORE:  0.6294740872235474\n",
      "Step :  3840 Loss SD :  0.6931356024912418 Loss G :  0.6933285121777795 Epsilon :  0.9764027564197167 ROC_SCORE:  0.6203529833168709\n",
      "Step :  3850 Loss SD :  0.6931368362450927 Loss G :  0.6929736987978721 Epsilon :  0.9776827564197162 ROC_SCORE:  0.6196217951311352\n",
      "Step :  3860 Loss SD :  0.6931429292561336 Loss G :  0.6930307386037199 Epsilon :  0.9789627564197156 ROC_SCORE:  0.6299541453238986\n",
      "Step :  3870 Loss SD :  0.692990510575652 Loss G :  0.6940011695718409 Epsilon :  0.980242756419715 ROC_SCORE:  0.6292382518977836\n",
      "Step :  3880 Loss SD :  0.6931900219934818 Loss G :  0.6938297591886603 Epsilon :  0.9815227564197144 ROC_SCORE:  0.6316829465403748\n",
      "Step :  3890 Loss SD :  0.693116030819351 Loss G :  0.6936465195653451 Epsilon :  0.9828027564197138 ROC_SCORE:  0.6298362276610169\n",
      "Step :  3900 Loss SD :  0.6931836508525067 Loss G :  0.6943061279722736 Epsilon :  0.9840827564197132 ROC_SCORE:  0.620455606220132\n",
      "Step :  3910 Loss SD :  0.6931477350751944 Loss G :  0.6942115019525683 Epsilon :  0.9853627564197126 ROC_SCORE:  0.6270585019621696\n",
      "Step :  3920 Loss SD :  0.6932383038545962 Loss G :  0.6941060311564784 Epsilon :  0.9866427564197121 ROC_SCORE:  0.6282406388670432\n",
      "Step :  3930 Loss SD :  0.693186077326751 Loss G :  0.6943735622878361 Epsilon :  0.9879227564197115 ROC_SCORE:  0.6292229571381631\n",
      "Step :  3940 Loss SD :  0.692919365030199 Loss G :  0.6946268307775522 Epsilon :  0.9892027564197109 ROC_SCORE:  0.6276495704146065\n",
      "Step :  3950 Loss SD :  0.6932456148142505 Loss G :  0.6947014561310326 Epsilon :  0.9904827564197103 ROC_SCORE:  0.6217556607878874\n",
      "Step :  3960 Loss SD :  0.6931486958673823 Loss G :  0.6948904479826365 Epsilon :  0.9917627564197097 ROC_SCORE:  0.6258625504357034\n",
      "Step :  3970 Loss SD :  0.6930459382348813 Loss G :  0.694787437198137 Epsilon :  0.9930427564197091 ROC_SCORE:  0.6277161766258575\n",
      "Step :  3980 Loss SD :  0.6927795851586581 Loss G :  0.6948437974453537 Epsilon :  0.9943227564197086 ROC_SCORE:  0.6183217405633801\n",
      "Step :  3990 Loss SD :  0.6933375283811793 Loss G :  0.694659400389441 Epsilon :  0.995602756419708 ROC_SCORE:  0.6229017810007509\n",
      "Step :  4000 Loss SD :  0.6934445707126354 Loss G :  0.6950632582239767 Epsilon :  0.9968827564197074 ROC_SCORE:  0.624702615601247\n",
      "Step :  4010 Loss SD :  0.6929578946216459 Loss G :  0.6952172788500727 Epsilon :  0.9981627564197068 ROC_SCORE:  0.6227976779594621\n",
      "Step :  4020 Loss SD :  0.6926949525511743 Loss G :  0.6956007336798364 Epsilon :  0.9994427564197061 ROC_SCORE:  0.6226131540853289\n",
      "Step :  4030 Loss SD :  0.6934694948729112 Loss G :  0.6951626335512902 Epsilon :  1.0007227564197057 ROC_SCORE:  0.6283294471487114\n",
      "Step :  4040 Loss SD :  0.6932609093861901 Loss G :  0.6949628709507742 Epsilon :  1.002002756419705 ROC_SCORE:  0.6087871847676035\n",
      "Step :  4050 Loss SD :  0.6933383191553035 Loss G :  0.6954069748638219 Epsilon :  1.0032827564197044 ROC_SCORE:  0.6300429536055668\n",
      "Step :  4060 Loss SD :  0.6930415895002114 Loss G :  0.6947117167864334 Epsilon :  1.0045627564197037 ROC_SCORE:  0.6241934481196819\n",
      "Step :  4070 Loss SD :  0.6933874409317392 Loss G :  0.6947074431267724 Epsilon :  1.0058427564197032 ROC_SCORE:  0.6172437066997953\n",
      "Step :  4080 Loss SD :  0.6929933168065798 Loss G :  0.6948190246572219 Epsilon :  1.0071227564197027 ROC_SCORE:  0.6248358280237493\n",
      "Step :  4090 Loss SD :  0.693465084349674 Loss G :  0.6951561006576623 Epsilon :  1.008402756419702 ROC_SCORE:  0.6188309080449448\n",
      "Step :  4100 Loss SD :  0.6930974110862734 Loss G :  0.6947994609655437 Epsilon :  1.0096827564197015 ROC_SCORE:  0.6261871940431352\n",
      "Step :  4110 Loss SD :  0.6932088920784392 Loss G :  0.6950573255180655 Epsilon :  1.0109627564197008 ROC_SCORE:  0.6223689313107411\n",
      "Step :  4120 Loss SD :  0.6930978224494803 Loss G :  0.694760197703542 Epsilon :  1.0122427564197003 ROC_SCORE:  0.621297804757953\n",
      "Step :  4130 Loss SD :  0.6932181568439232 Loss G :  0.6942685786469747 Epsilon :  1.0135227564196996 ROC_SCORE:  0.623144523637311\n",
      "Step :  4140 Loss SD :  0.6929528465408956 Loss G :  0.6944267089900539 Epsilon :  1.014802756419699 ROC_SCORE:  0.6286471834453469\n",
      "Step :  4150 Loss SD :  0.6930500308864219 Loss G :  0.6948026644356651 Epsilon :  1.0160827564196986 ROC_SCORE:  0.627318019496378\n",
      "Step :  4160 Loss SD :  0.6932013457820008 Loss G :  0.6948268218227877 Epsilon :  1.0173627564196979 ROC_SCORE:  0.6317342579920052\n",
      "Step :  4170 Loss SD :  0.6928587695410053 Loss G :  0.6946870241722993 Epsilon :  1.0186427564196974 ROC_SCORE:  0.6221913147474046\n",
      "Step :  4180 Loss SD :  0.693148716603463 Loss G :  0.6949006200611357 Epsilon :  1.0199227564196967 ROC_SCORE:  0.6261649919727181\n",
      "Step :  4190 Loss SD :  0.6933363829034264 Loss G :  0.6943280121263463 Epsilon :  1.0212027564196962 ROC_SCORE:  0.624562495867948\n",
      "Step :  4200 Loss SD :  0.6931998391135861 Loss G :  0.6935511598256707 Epsilon :  1.0224827564196957 ROC_SCORE:  0.6218153596883422\n",
      "Step :  4210 Loss SD :  0.6930961614779684 Loss G :  0.6935662278828106 Epsilon :  1.0237431762208071 ROC_SCORE:  0.6210106579805589\n",
      "Step :  4220 Loss SD :  0.6931243180612011 Loss G :  0.6935264525852504 Epsilon :  1.0249591762208086 ROC_SCORE:  0.6268670707772401\n",
      "Step :  4230 Loss SD :  0.6931248001871564 Loss G :  0.6935000531560889 Epsilon :  1.0261751762208098 ROC_SCORE:  0.6196731065827659\n",
      "Step :  4240 Loss SD :  0.6932176700628123 Loss G :  0.6938993220860815 Epsilon :  1.0273911762208112 ROC_SCORE:  0.6229960164551879\n",
      "Step :  4250 Loss SD :  0.693091202577458 Loss G :  0.693755591460288 Epsilon :  1.0286071762208127 ROC_SCORE:  0.6270959987922073\n",
      "Step :  4260 Loss SD :  0.6931474736449794 Loss G :  0.6939028031679407 Epsilon :  1.029823176220814 ROC_SCORE:  0.6210313799129481\n",
      "Step :  4270 Loss SD :  0.6931462879727973 Loss G :  0.6931734301483993 Epsilon :  1.0310391762208155 ROC_SCORE:  0.62645361888814\n",
      "Step :  4280 Loss SD :  0.693151917569444 Loss G :  0.6933057824554976 Epsilon :  1.032255176220817 ROC_SCORE:  0.6176196617588579\n",
      "Step :  4290 Loss SD :  0.6931463971824227 Loss G :  0.6931761360960621 Epsilon :  1.0334711762208184 ROC_SCORE:  0.6244223761346491\n",
      "Step :  4300 Loss SD :  0.6930999138940106 Loss G :  0.6935372805329985 Epsilon :  1.0346871762208198 ROC_SCORE:  0.624769221812498\n",
      "Step :  4310 Loss SD :  0.6930816232547544 Loss G :  0.693572534515296 Epsilon :  1.0359031762208213 ROC_SCORE:  0.6240824377675965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step :  4320 Loss SD :  0.6931884574511562 Loss G :  0.6938106358804601 Epsilon :  1.0371191762208225 ROC_SCORE:  0.6237869035413781\n",
      "Step :  4330 Loss SD :  0.6932129015613313 Loss G :  0.6938404461247969 Epsilon :  1.038335176220824 ROC_SCORE:  0.6205153051205867\n",
      "Step :  4340 Loss SD :  0.6930846762757801 Loss G :  0.693815206104511 Epsilon :  1.0395511762208254 ROC_SCORE:  0.6203307812464538\n",
      "Step :  4350 Loss SD :  0.6931224599677671 Loss G :  0.6935555840464618 Epsilon :  1.0407671762208268 ROC_SCORE:  0.6263801053660923\n",
      "Step :  4360 Loss SD :  0.6931715046247491 Loss G :  0.6939344348374011 Epsilon :  1.0419831762208283 ROC_SCORE:  0.6251313622499677\n",
      "Step :  4370 Loss SD :  0.6931246815254077 Loss G :  0.693875279765428 Epsilon :  1.0431991762208297 ROC_SCORE:  0.6221025064657363\n",
      "Step :  4380 Loss SD :  0.6934076201908413 Loss G :  0.6945308055959922 Epsilon :  1.0444151762208311 ROC_SCORE:  0.6214088151100383\n",
      "Step :  4390 Loss SD :  0.6932899265829714 Loss G :  0.6942772035851571 Epsilon :  1.0456311762208326 ROC_SCORE:  0.6193109661452962\n",
      "Step :  4400 Loss SD :  0.6931215629688894 Loss G :  0.6933959923467593 Epsilon :  1.046847176220834 ROC_SCORE:  0.6225978593257084\n",
      "Step :  4410 Loss SD :  0.6931637498248215 Loss G :  0.6928883621390549 Epsilon :  1.0480631762208352 ROC_SCORE:  0.6235870849076246\n",
      "Step :  4420 Loss SD :  0.693079900483076 Loss G :  0.6926920951297414 Epsilon :  1.0492791762208367 ROC_SCORE:  0.6229377976927608\n",
      "Step :  4430 Loss SD :  0.6931476828975032 Loss G :  0.6921306615791093 Epsilon :  1.050495176220838 ROC_SCORE:  0.6225243458036606\n",
      "Step :  4440 Loss SD :  0.6927719130608315 Loss G :  0.6919192524520221 Epsilon :  1.0517111762208395 ROC_SCORE:  0.6291188540968742\n",
      "Step :  4450 Loss SD :  0.6929152225831453 Loss G :  0.6918769463519012 Epsilon :  1.052927176220841 ROC_SCORE:  0.6235732702860317\n",
      "Step :  4460 Loss SD :  0.693294820275876 Loss G :  0.6915852242248788 Epsilon :  1.0541431762208424 ROC_SCORE:  0.624540293797531\n",
      "Step :  4470 Loss SD :  0.6932709481985199 Loss G :  0.6911958399089723 Epsilon :  1.0553591762208439 ROC_SCORE:  0.6300207515351497\n",
      "Step :  4480 Loss SD :  0.6929290734996875 Loss G :  0.690803509274452 Epsilon :  1.0565751762208453 ROC_SCORE:  0.6071693939032128\n",
      "Step :  4490 Loss SD :  0.6929332353553475 Loss G :  0.6908453628349623 Epsilon :  1.0577911762208467 ROC_SCORE:  0.6273915330184258\n",
      "Step :  4500 Loss SD :  0.6930241146295297 Loss G :  0.6911419090159215 Epsilon :  1.059007176220848 ROC_SCORE:  0.6265424271698082\n",
      "Step :  4510 Loss SD :  0.6933826203163314 Loss G :  0.69128968495022 Epsilon :  1.0602231762208494 ROC_SCORE:  0.6228711914815096\n",
      "Step :  4520 Loss SD :  0.6930998749075153 Loss G :  0.6916014596861366 Epsilon :  1.0614391762208508 ROC_SCORE:  0.6222135168178217\n",
      "Step :  4530 Loss SD :  0.6934619773431283 Loss G :  0.6911419725379252 Epsilon :  1.0626551762208523 ROC_SCORE:  0.6192374526232487\n",
      "Step :  4540 Loss SD :  0.6929852251720506 Loss G :  0.6914145969806463 Epsilon :  1.0638711762208537 ROC_SCORE:  0.632649970051874\n",
      "Step :  4550 Loss SD :  0.6932897722194654 Loss G :  0.6916423981443225 Epsilon :  1.0650871762208551 ROC_SCORE:  0.6186019800299777\n",
      "Step :  4560 Loss SD :  0.692459859495903 Loss G :  0.6912775712741217 Epsilon :  1.0663031762208566 ROC_SCORE:  0.6310987853987343\n",
      "Step :  4570 Loss SD :  0.6928842260353465 Loss G :  0.6914474059449872 Epsilon :  1.067519176220858 ROC_SCORE:  0.6232333319189792\n",
      "Step :  4580 Loss SD :  0.693391529581767 Loss G :  0.6912263423747623 Epsilon :  1.0687351762208595 ROC_SCORE:  0.6267047489735241\n",
      "Step :  4590 Loss SD :  0.6931924835385992 Loss G :  0.6916461110677329 Epsilon :  1.0699511762208607 ROC_SCORE:  0.6265868313106424\n",
      "Step :  4600 Loss SD :  0.6929414135803453 Loss G :  0.6914874587455503 Epsilon :  1.071167176220862 ROC_SCORE:  0.6230710101152632\n",
      "Step :  4610 Loss SD :  0.6932492826467511 Loss G :  0.6915455786569552 Epsilon :  1.0723831762208635 ROC_SCORE:  0.6275316527517246\n",
      "Step :  4620 Loss SD :  0.6931917223252717 Loss G :  0.6917372971042223 Epsilon :  1.073599176220865 ROC_SCORE:  0.6287206969673946\n",
      "Step :  4630 Loss SD :  0.6934485460058227 Loss G :  0.6915550994533576 Epsilon :  1.0748151762208664 ROC_SCORE:  0.6068891544366151\n",
      "Step :  4640 Loss SD :  0.6931479508458697 Loss G :  0.691924586004786 Epsilon :  1.0760311762208679 ROC_SCORE:  0.6284113481195833\n",
      "Step :  4650 Loss SD :  0.6932779127476374 Loss G :  0.6921087676346659 Epsilon :  1.0772471762208693 ROC_SCORE:  0.6227310717482107\n",
      "Step :  4660 Loss SD :  0.6932900842140484 Loss G :  0.6920417223521602 Epsilon :  1.0784631762208707 ROC_SCORE:  0.6276648651742271\n",
      "Step :  4670 Loss SD :  0.693126967296044 Loss G :  0.6924976832057241 Epsilon :  1.0796791762208722 ROC_SCORE:  0.6223467292403242\n",
      "Step :  4680 Loss SD :  0.6931471006164112 Loss G :  0.6931506683169765 Epsilon :  1.0808951762208734 ROC_SCORE:  0.6178194803926116\n",
      "Step :  4690 Loss SD :  0.6932476179618037 Loss G :  0.6936735205008118 Epsilon :  1.0821111762208748 ROC_SCORE:  0.6273027247367574\n",
      "Step :  4700 Loss SD :  0.6931337839408818 Loss G :  0.6935746762029391 Epsilon :  1.0833271762208763 ROC_SCORE:  0.6132769367852783\n",
      "Step :  4710 Loss SD :  0.6931422279971291 Loss G :  0.6931836633272044 Epsilon :  1.084491927763175 ROC_SCORE:  0.6268739780880366\n",
      "Step :  4720 Loss SD :  0.6931511343899688 Loss G :  0.6932890436397237 Epsilon :  1.0856439277631746 ROC_SCORE:  0.6208843528688529\n",
      "Step :  4730 Loss SD :  0.6931462047937162 Loss G :  0.6931883002146356 Epsilon :  1.0867959277631745 ROC_SCORE:  0.6249981498274653\n",
      "Step :  4740 Loss SD :  0.6931471824640062 Loss G :  0.6931941183054381 Epsilon :  1.087947927763174 ROC_SCORE:  0.6205597092614209\n",
      "Step :  4750 Loss SD :  0.6931556264729375 Loss G :  0.6928818783015798 Epsilon :  1.0890999277631739 ROC_SCORE:  0.6265271324101876\n",
      "Step :  4760 Loss SD :  0.6931373404726764 Loss G :  0.6931028038319094 Epsilon :  1.0902519277631735 ROC_SCORE:  0.6246735062200334\n",
      "Step :  4770 Loss SD :  0.6931518296945827 Loss G :  0.6931336269120238 Epsilon :  1.091403927763173 ROC_SCORE:  0.6271626050034587\n",
      "Step :  4780 Loss SD :  0.6931471856192103 Loss G :  0.6930299171436068 Epsilon :  1.092555927763173 ROC_SCORE:  0.6188684048749826\n",
      "Step :  4790 Loss SD :  0.6931471986831839 Loss G :  0.6929495282681783 Epsilon :  1.0937079277631725 ROC_SCORE:  0.6223467292403242\n",
      "Step :  4800 Loss SD :  0.6931471810114558 Loss G :  0.693146080614947 Epsilon :  1.0948599277631723 ROC_SCORE:  0.620766435205971\n",
      "Step :  4810 Loss SD :  0.6931415026165755 Loss G :  0.6933457099294554 Epsilon :  1.096011927763172 ROC_SCORE:  0.6258847525061203\n",
      "Step :  4820 Loss SD :  0.6932013082412534 Loss G :  0.6934357674066377 Epsilon :  1.0971639277631715 ROC_SCORE:  0.6239714274155113\n",
      "Step :  4830 Loss SD :  0.6930751794410799 Loss G :  0.693621170479344 Epsilon :  1.0983159277631713 ROC_SCORE:  0.623144523637311\n",
      "Step :  4840 Loss SD :  0.6931354009161481 Loss G :  0.6933395685875412 Epsilon :  1.099467927763171 ROC_SCORE:  0.6299985494647328\n",
      "Step :  4850 Loss SD :  0.6931195681428372 Loss G :  0.6933297159292022 Epsilon :  1.1006199277631707 ROC_SCORE:  0.6117716364110007\n",
      "Step :  4860 Loss SD :  0.6931022981357216 Loss G :  0.6939170836719082 Epsilon :  1.1017719277631703 ROC_SCORE:  0.6210841715026065\n",
      "Step :  4870 Loss SD :  0.6932194173186976 Loss G :  0.6942861998913139 Epsilon :  1.10292392776317 ROC_SCORE:  0.6197175107236\n",
      "Step :  4880 Loss SD :  0.6932330617738661 Loss G :  0.6938806031620434 Epsilon :  1.1040759277631698 ROC_SCORE:  0.6308032511725161\n",
      "Step :  4890 Loss SD :  0.6931877048798578 Loss G :  0.6938882936327517 Epsilon :  1.1052279277631694 ROC_SCORE:  0.6226200613961254\n",
      "Step :  4900 Loss SD :  0.6930564401089214 Loss G :  0.693880061422255 Epsilon :  1.1063799277631692 ROC_SCORE:  0.6288095052490629\n",
      "Step :  4910 Loss SD :  0.6931626775648437 Loss G :  0.6936389419618267 Epsilon :  1.1075319277631688 ROC_SCORE:  0.6238535097526295\n",
      "Step :  4920 Loss SD :  0.6930825703045334 Loss G :  0.6928009465338044 Epsilon :  1.1086839277631686 ROC_SCORE:  0.6267560604251549\n",
      "Step :  4930 Loss SD :  0.6931684887049081 Loss G :  0.6927998384527577 Epsilon :  1.1098359277631682 ROC_SCORE:  0.628033912922493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step :  4940 Loss SD :  0.6931201704817329 Loss G :  0.6928597502641927 Epsilon :  1.1109879277631678 ROC_SCORE:  0.6169703745439942\n",
      "Step :  4950 Loss SD :  0.6931459770329126 Loss G :  0.6930927064494984 Epsilon :  1.1121399277631676 ROC_SCORE:  0.6209065549392699\n",
      "Step :  4960 Loss SD :  0.6932109515409247 Loss G :  0.6927282093876526 Epsilon :  1.1132919277631672 ROC_SCORE:  0.6178041856329909\n",
      "Step :  4970 Loss SD :  0.6931279592922186 Loss G :  0.6928498697160871 Epsilon :  1.114443927763167 ROC_SCORE:  0.6260026701690021\n",
      "Step :  4980 Loss SD :  0.6931527348664386 Loss G :  0.6929648227017726 Epsilon :  1.1155959277631666 ROC_SCORE:  0.6304342034242499\n",
      "Step :  4990 Loss SD :  0.6930283684087539 Loss G :  0.693691674980105 Epsilon :  1.1167479277631662 ROC_SCORE:  0.6211201881946163\n",
      "Step :  5000 Loss SD :  0.6933097886808794 Loss G :  0.6941064164449171 Epsilon :  1.117899927763166 ROC_SCORE:  0.6215198254621237\n",
      "Step :  5010 Loss SD :  0.6930307749667031 Loss G :  0.6940867310127691 Epsilon :  1.1190519277631656 ROC_SCORE:  0.6226422634665425\n",
      "Step :  5020 Loss SD :  0.6931871996503549 Loss G :  0.6939378527374024 Epsilon :  1.1202039277631655 ROC_SCORE:  0.6257224307024044\n",
      "Step :  5030 Loss SD :  0.6931200632592269 Loss G :  0.6941327991421182 Epsilon :  1.121355927763165 ROC_SCORE:  0.6239645201047148\n",
      "Step :  5040 Loss SD :  0.6933824974110294 Loss G :  0.694396826213524 Epsilon :  1.1225079277631647 ROC_SCORE:  0.6126498516408317\n",
      "Step :  5050 Loss SD :  0.6932495735228784 Loss G :  0.6942138380198938 Epsilon :  1.1236599277631645 ROC_SCORE:  0.6230557153556426\n",
      "Step :  5060 Loss SD :  0.6933105364844657 Loss G :  0.6939854114960473 Epsilon :  1.124811927763164 ROC_SCORE:  0.6226866676073766\n",
      "Step :  5070 Loss SD :  0.6931793345480899 Loss G :  0.6941713715182347 Epsilon :  1.125963927763164 ROC_SCORE:  0.609289444938372\n",
      "Step :  5080 Loss SD :  0.6931135648287406 Loss G :  0.6942532334463344 Epsilon :  1.1271159277631635 ROC_SCORE:  0.6261067732102912\n",
      "Step :  5090 Loss SD :  0.6930416806843767 Loss G :  0.6948609206689367 Epsilon :  1.1282679277631633 ROC_SCORE:  0.6192665620044622\n",
      "Step :  5100 Loss SD :  0.693325052201571 Loss G :  0.6950240906148092 Epsilon :  1.129419927763163 ROC_SCORE:  0.6224799416628266\n",
      "Step :  5110 Loss SD :  0.6930006970334002 Loss G :  0.6947135582415067 Epsilon :  1.1305719277631625 ROC_SCORE:  0.6274137350888429\n",
      "Step :  5120 Loss SD :  0.6930432258672434 Loss G :  0.6948404812678575 Epsilon :  1.1317239277631623 ROC_SCORE:  0.6311806863696063\n",
      "Step :  5130 Loss SD :  0.693093133633788 Loss G :  0.6949268166222048 Epsilon :  1.132875927763162 ROC_SCORE:  0.6192749494532864\n",
      "Step :  5140 Loss SD :  0.6931483773003815 Loss G :  0.6946911093801765 Epsilon :  1.1340279277631617 ROC_SCORE:  0.6273555163264158\n",
      "Step :  5150 Loss SD :  0.6933347113518771 Loss G :  0.6944696798665819 Epsilon :  1.1351799277631613 ROC_SCORE:  0.6260914784506705\n",
      "Step :  5160 Loss SD :  0.6930560605419083 Loss G :  0.6946257861598364 Epsilon :  1.136331927763161 ROC_SCORE:  0.6081670069339533\n",
      "Step :  5170 Loss SD :  0.692709871495095 Loss G :  0.6949071797364312 Epsilon :  1.1374839277631608 ROC_SCORE:  0.6266090333810597\n",
      "Step :  5180 Loss SD :  0.6927992443672535 Loss G :  0.6950343935056668 Epsilon :  1.1386359277631604 ROC_SCORE:  0.6250356466575029\n",
      "Step :  5190 Loss SD :  0.6931503315817173 Loss G :  0.6956701702310983 Epsilon :  1.1397879277631602 ROC_SCORE:  0.6208690581092321\n",
      "Step :  5200 Loss SD :  0.6930010371819537 Loss G :  0.6955015573218316 Epsilon :  1.1409399277631598 ROC_SCORE:  0.6251244549391712\n",
      "Step :  5210 Loss SD :  0.6929105237364828 Loss G :  0.6950657108346423 Epsilon :  1.1420919277631594 ROC_SCORE:  0.6362920963589591\n",
      "Step :  5220 Loss SD :  0.692879936943507 Loss G :  0.6953158923991593 Epsilon :  1.1432439277631592 ROC_SCORE:  0.6240602356971796\n",
      "Step :  5230 Loss SD :  0.6933106526267434 Loss G :  0.6951148924298454 Epsilon :  1.1443959277631588 ROC_SCORE:  0.6266312354514766\n",
      "Step :  5240 Loss SD :  0.6932145543122614 Loss G :  0.6952410423353206 Epsilon :  1.1455479277631586 ROC_SCORE:  0.6226644655369595\n",
      "Step :  5250 Loss SD :  0.6925958899178566 Loss G :  0.6951293154395143 Epsilon :  1.1466999277631582 ROC_SCORE:  0.6276870672446441\n",
      "Step :  5260 Loss SD :  0.6928120774149253 Loss G :  0.6949427400447191 Epsilon :  1.147851927763158 ROC_SCORE:  0.6257293380132009\n",
      "Step :  5270 Loss SD :  0.6934031987942093 Loss G :  0.6951757486911908 Epsilon :  1.1490039277631576 ROC_SCORE:  0.6234622599339464\n",
      "Step :  5280 Loss SD :  0.6936807785092046 Loss G :  0.6946617694157152 Epsilon :  1.1501559277631572 ROC_SCORE:  0.6281671253449955\n",
      "Step :  5290 Loss SD :  0.6930147230731416 Loss G :  0.694000556550283 Epsilon :  1.1513070732482842 ROC_SCORE:  0.6229155956223438\n",
      "Step :  5300 Loss SD :  0.6930674131401356 Loss G :  0.6945259878290315 Epsilon :  1.1523950732482833 ROC_SCORE:  0.6295850975756326\n",
      "Step :  5310 Loss SD :  0.6932389959862599 Loss G :  0.6941177143770928 Epsilon :  1.1534830732482824 ROC_SCORE:  0.6266159406918559\n",
      "Step :  5320 Loss SD :  0.6932028000582846 Loss G :  0.6937349284147686 Epsilon :  1.1545710732482815 ROC_SCORE:  0.6222288115774424\n",
      "Step :  5330 Loss SD :  0.6931023220608107 Loss G :  0.6936406364507811 Epsilon :  1.1556590732482805 ROC_SCORE:  0.6150501421425886\n",
      "Step :  5340 Loss SD :  0.6930812651350491 Loss G :  0.6934578938201923 Epsilon :  1.1567470732482796 ROC_SCORE:  0.6264161220581024\n",
      "Step :  5350 Loss SD :  0.6931724334648598 Loss G :  0.6935559409123772 Epsilon :  1.1578350732482787 ROC_SCORE:  0.6173241275326395\n",
      "Step :  5360 Loss SD :  0.6931678575537352 Loss G :  0.6938043388590318 Epsilon :  1.1589230732482778 ROC_SCORE:  0.6283294471487114\n",
      "Step :  5370 Loss SD :  0.6931479990560578 Loss G :  0.6944399178635549 Epsilon :  1.160011073248277 ROC_SCORE:  0.6238604170634259\n",
      "Step :  5380 Loss SD :  0.6932083894342362 Loss G :  0.6950513416986835 Epsilon :  1.161099073248276 ROC_SCORE:  0.6197175107236\n",
      "Step :  5390 Loss SD :  0.6928884521943088 Loss G :  0.6952255947733977 Epsilon :  1.162187073248275 ROC_SCORE:  0.6277314713854782\n",
      "Step :  5400 Loss SD :  0.6929683255703334 Loss G :  0.6950891801781269 Epsilon :  1.1632750732482742 ROC_SCORE:  0.6223620239999448\n",
      "Step :  5410 Loss SD :  0.6933644677070624 Loss G :  0.6954354211206977 Epsilon :  1.1643630732482733 ROC_SCORE:  0.6297030152385144\n",
      "Step :  5420 Loss SD :  0.6935287111299183 Loss G :  0.6955723128413336 Epsilon :  1.1654510732482724 ROC_SCORE:  0.6243266605421844\n",
      "Step :  5430 Loss SD :  0.6933947776283523 Loss G :  0.6951047162639954 Epsilon :  1.1665390732482714 ROC_SCORE:  0.6208330414172224\n",
      "Step :  5440 Loss SD :  0.6934752963648436 Loss G :  0.6948283418624179 Epsilon :  1.1676270732482705 ROC_SCORE:  0.6244667802754833\n",
      "Step :  5450 Loss SD :  0.6928014899015305 Loss G :  0.695403895458843 Epsilon :  1.1687150732482696 ROC_SCORE:  0.6200712637122454\n",
      "Step :  5460 Loss SD :  0.6931492199277474 Loss G :  0.6951482547553667 Epsilon :  1.1698030732482687 ROC_SCORE:  0.6187351924524802\n",
      "Step :  5470 Loss SD :  0.693332789912119 Loss G :  0.6951127382792217 Epsilon :  1.1708910732482678 ROC_SCORE:  0.6210841715026065\n",
      "Step :  5480 Loss SD :  0.6929226263002379 Loss G :  0.695564616062796 Epsilon :  1.171979073248267 ROC_SCORE:  0.628898313530731\n",
      "Step :  5490 Loss SD :  0.6930126784725383 Loss G :  0.695345777046232 Epsilon :  1.173067073248266 ROC_SCORE:  0.6238313076822123\n",
      "Step :  5500 Loss SD :  0.6933959019621636 Loss G :  0.6957503807163389 Epsilon :  1.174155073248265 ROC_SCORE:  0.6218444690695557\n",
      "Step :  5510 Loss SD :  0.6937757795843995 Loss G :  0.6953443973888471 Epsilon :  1.1752430732482642 ROC_SCORE:  0.6254490985466031\n",
      "Step :  5520 Loss SD :  0.6930552058166399 Loss G :  0.694642958635709 Epsilon :  1.1763310732482632 ROC_SCORE:  0.6269114749180744\n",
      "Step :  5530 Loss SD :  0.6930001903937978 Loss G :  0.6947138068093387 Epsilon :  1.1774190732482623 ROC_SCORE:  0.6295781902648362\n",
      "Step :  5540 Loss SD :  0.6933010876397971 Loss G :  0.6947898868475011 Epsilon :  1.1785070732482614 ROC_SCORE:  0.6306340220580037\n",
      "Step :  5550 Loss SD :  0.6931483500859897 Loss G :  0.6946810105560144 Epsilon :  1.1795950732482605 ROC_SCORE:  0.625426896476186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step :  5560 Loss SD :  0.6932457587112215 Loss G :  0.6946886829723586 Epsilon :  1.1806830732482596 ROC_SCORE:  0.6252936840536836\n",
      "Step :  5570 Loss SD :  0.6927390037857271 Loss G :  0.6950307394995061 Epsilon :  1.1817710732482587 ROC_SCORE:  0.626395400125713\n",
      "Step :  5580 Loss SD :  0.6932471038453378 Loss G :  0.6947229724518296 Epsilon :  1.1828590732482578 ROC_SCORE:  0.6207067363055162\n",
      "Step :  5590 Loss SD :  0.6932864125018221 Loss G :  0.6946037610059227 Epsilon :  1.1839470732482569 ROC_SCORE:  0.6314540185254074\n",
      "Step :  5600 Loss SD :  0.6931012388153599 Loss G :  0.6946504000420454 Epsilon :  1.185035073248256 ROC_SCORE:  0.6219845888028543\n",
      "Step :  5610 Loss SD :  0.6930962714442837 Loss G :  0.694829104160372 Epsilon :  1.186123073248255 ROC_SCORE:  0.623188927778145\n",
      "Step :  5620 Loss SD :  0.6929833270120311 Loss G :  0.6949145399292559 Epsilon :  1.1872110732482541 ROC_SCORE:  0.6210397673617724\n",
      "Step :  5630 Loss SD :  0.6931493442640065 Loss G :  0.6952293525264658 Epsilon :  1.1882990732482532 ROC_SCORE:  0.6212311985467018\n",
      "Step :  5640 Loss SD :  0.6928127537820767 Loss G :  0.694937721561036 Epsilon :  1.1893870732482523 ROC_SCORE:  0.6233290475114438\n",
      "Step :  5650 Loss SD :  0.6927068051868449 Loss G :  0.6951781201942089 Epsilon :  1.1904750732482514 ROC_SCORE:  0.6294005737014995\n",
      "Step :  5660 Loss SD :  0.6932590471508253 Loss G :  0.6943247921758234 Epsilon :  1.1915630732482505 ROC_SCORE:  0.6061648735616758\n",
      "Step :  5670 Loss SD :  0.6929532980369721 Loss G :  0.6940559752784173 Epsilon :  1.1926510732482496 ROC_SCORE:  0.6253449955053142\n",
      "Step :  5680 Loss SD :  0.6934677192546435 Loss G :  0.6944107571554837 Epsilon :  1.1937390732482487 ROC_SCORE:  0.6250647560387165\n",
      "Step :  5690 Loss SD :  0.6933192345049932 Loss G :  0.6942424297273768 Epsilon :  1.1948270732482478 ROC_SCORE:  0.6151680598054704\n",
      "Step :  5700 Loss SD :  0.6932468723212024 Loss G :  0.6942031206367291 Epsilon :  1.1959150732482469 ROC_SCORE:  0.6273249268071746\n",
      "Step :  5710 Loss SD :  0.6931167297722991 Loss G :  0.6941314706931868 Epsilon :  1.197003073248246 ROC_SCORE:  0.6303606899022023\n",
      "Step :  5720 Loss SD :  0.6933236220470687 Loss G :  0.6942647010663421 Epsilon :  1.198091073248245 ROC_SCORE:  0.618654771619636\n",
      "Step :  5730 Loss SD :  0.693117409537658 Loss G :  0.6941320488155172 Epsilon :  1.1991790732482441 ROC_SCORE:  0.6295628955052155\n",
      "Step :  5740 Loss SD :  0.693429387740824 Loss G :  0.6944181479489355 Epsilon :  1.2002670732482432 ROC_SCORE:  0.6223023250994899\n",
      "Step :  5750 Loss SD :  0.6930303231453478 Loss G :  0.6944394942157031 Epsilon :  1.2013550732482423 ROC_SCORE:  0.6241490439788479\n",
      "Step :  5760 Loss SD :  0.6929979983893289 Loss G :  0.6947630338109868 Epsilon :  1.2024430732482414 ROC_SCORE:  0.6255295193794471\n",
      "Step :  5770 Loss SD :  0.6927569352158041 Loss G :  0.6949547801653382 Epsilon :  1.2035310732482405 ROC_SCORE:  0.623742499400544\n",
      "Step :  5780 Loss SD :  0.6933167237193532 Loss G :  0.6949337916570087 Epsilon :  1.2046190732482396 ROC_SCORE:  0.6241268419084307\n",
      "Step :  5790 Loss SD :  0.6932159710508384 Loss G :  0.6952913274949595 Epsilon :  1.2057070732482387 ROC_SCORE:  0.619290244212907\n",
      "Step :  5800 Loss SD :  0.6935360111521851 Loss G :  0.6956159608643334 Epsilon :  1.2067950732482378 ROC_SCORE:  0.6258847525061203\n",
      "Step :  5810 Loss SD :  0.6930765016778423 Loss G :  0.6954863758138172 Epsilon :  1.2078830732482368 ROC_SCORE:  0.6288317073194798\n",
      "Step :  5820 Loss SD :  0.6928042356161632 Loss G :  0.6959402496875161 Epsilon :  1.208971073248236 ROC_SCORE:  0.6240602356971796\n",
      "Step :  5830 Loss SD :  0.6927768603660923 Loss G :  0.6961528785124901 Epsilon :  1.210059073248235 ROC_SCORE:  0.623188927778145\n",
      "Step :  5840 Loss SD :  0.6929652858336569 Loss G :  0.6961315390100862 Epsilon :  1.2111470732482341 ROC_SCORE:  0.6265646292402255\n",
      "Step :  5850 Loss SD :  0.6936683553090087 Loss G :  0.6958991442385158 Epsilon :  1.2122350732482332 ROC_SCORE:  0.6275469475113452\n",
      "Step :  5860 Loss SD :  0.6936496620357834 Loss G :  0.6957926419477226 Epsilon :  1.2133230732482323 ROC_SCORE:  0.6085582567526364\n",
      "Step :  5870 Loss SD :  0.6928875553903643 Loss G :  0.6952405551770844 Epsilon :  1.2144110732482314 ROC_SCORE:  0.6207955445871846\n",
      "Step :  5880 Loss SD :  0.6931488264316257 Loss G :  0.6949551359946997 Epsilon :  1.2154990732482305 ROC_SCORE:  0.6249468383758346\n",
      "Step :  5890 Loss SD :  0.693299419736673 Loss G :  0.6947433374914358 Epsilon :  1.2165870732482296 ROC_SCORE:  0.6173325149814637\n",
      "Step :  5900 Loss SD :  0.6927586124049722 Loss G :  0.6947206018943963 Epsilon :  1.2176750732482287 ROC_SCORE:  0.6244070813750285\n",
      "Step :  5910 Loss SD :  0.6931485411823964 Loss G :  0.6947987112897264 Epsilon :  1.2187630732482277 ROC_SCORE:  0.6271626050034587\n",
      "Step :  5920 Loss SD :  0.6930327190868024 Loss G :  0.6950277110737584 Epsilon :  1.2198510732482268 ROC_SCORE:  0.6201753667535344\n",
      "Step :  5930 Loss SD :  0.6936129896178009 Loss G :  0.6952484857341794 Epsilon :  1.220939073248226 ROC_SCORE:  0.622959999763178\n",
      "Step :  5940 Loss SD :  0.6926935417630358 Loss G :  0.6952407177418545 Epsilon :  1.222027073248225 ROC_SCORE:  0.6252714819832665\n",
      "Step :  5950 Loss SD :  0.693340772277446 Loss G :  0.6952019345234076 Epsilon :  1.223115073248224 ROC_SCORE:  0.6254338037869824\n",
      "Step :  5960 Loss SD :  0.6931488429603267 Loss G :  0.6949600826256692 Epsilon :  1.2242030732482232 ROC_SCORE:  0.624702615601247\n",
      "Step :  5970 Loss SD :  0.6932962019277924 Loss G :  0.6943173247283527 Epsilon :  1.2252910732482223 ROC_SCORE:  0.6265271324101876\n",
      "Step :  5980 Loss SD :  0.6931115246380768 Loss G :  0.6943068315198375 Epsilon :  1.2263790732482214 ROC_SCORE:  0.6200352470202354\n",
      "Step :  5990 Loss SD :  0.6932344815459425 Loss G :  0.694530988218833 Epsilon :  1.2274670732482205 ROC_SCORE:  0.6251535643203848\n",
      "Step :  6000 Loss SD :  0.6934451653854636 Loss G :  0.6950596150853622 Epsilon :  1.2285250914649883 ROC_SCORE:  0.6257293380132009\n",
      "Step :  6010 Loss SD :  0.6930727369940319 Loss G :  0.6956550634080262 Epsilon :  1.2295490914649885 ROC_SCORE:  0.6192818567640828\n",
      "Step :  6020 Loss SD :  0.6933053674131675 Loss G :  0.6956268886002333 Epsilon :  1.230573091464988 ROC_SCORE:  0.6242669616417297\n",
      "Step :  6030 Loss SD :  0.6931508088127512 Loss G :  0.6958484426858206 Epsilon :  1.231597091464988 ROC_SCORE:  0.6316607444699576\n",
      "Step :  6040 Loss SD :  0.6935257498508766 Loss G :  0.6961493945012531 Epsilon :  1.2326210914649878 ROC_SCORE:  0.6173394222922601\n",
      "Step :  6050 Loss SD :  0.6926143215374496 Loss G :  0.6960124389352234 Epsilon :  1.233645091464988 ROC_SCORE:  0.6241934481196819\n",
      "Step :  6060 Loss SD :  0.6932399603700572 Loss G :  0.6959863343171404 Epsilon :  1.2346690914649874 ROC_SCORE:  0.6217418461662946\n",
      "Step :  6070 Loss SD :  0.6929069778042967 Loss G :  0.695745604049534 Epsilon :  1.2356930914649875 ROC_SCORE:  0.6256405297315325\n",
      "Step :  6080 Loss SD :  0.6933461577275029 Loss G :  0.6962613959604864 Epsilon :  1.236717091464987 ROC_SCORE:  0.6155302002429399\n",
      "Step :  6090 Loss SD :  0.6933428320982075 Loss G :  0.6962008533132016 Epsilon :  1.2377410914649871 ROC_SCORE:  0.6228711914815096\n",
      "Step :  6100 Loss SD :  0.6931511468668189 Loss G :  0.6959668551032004 Epsilon :  1.2387650914649868 ROC_SCORE:  0.6236176744268659\n",
      "Step :  6110 Loss SD :  0.6929895133233606 Loss G :  0.6957358400509268 Epsilon :  1.239789091464987 ROC_SCORE:  0.6265715365510218\n",
      "Step :  6120 Loss SD :  0.6933887543608622 Loss G :  0.6956922112121062 Epsilon :  1.2408130914649864 ROC_SCORE:  0.6281671253449955\n",
      "Step :  6130 Loss SD :  0.693325544378256 Loss G :  0.6959605697578047 Epsilon :  1.2418370914649866 ROC_SCORE:  0.6318896724849248\n",
      "Step :  6140 Loss SD :  0.6933055223239208 Loss G :  0.6956271252357973 Epsilon :  1.242861091464986 ROC_SCORE:  0.6307894365509232\n",
      "Step :  6150 Loss SD :  0.6930787547538293 Loss G :  0.6954228429013342 Epsilon :  1.2438850914649862 ROC_SCORE:  0.6257890369136556\n",
      "Step :  6160 Loss SD :  0.6935777446813658 Loss G :  0.6954289210701293 Epsilon :  1.2449090914649859 ROC_SCORE:  0.6137722896452503\n",
      "Step :  6170 Loss SD :  0.6929281405431826 Loss G :  0.6955212472728497 Epsilon :  1.245933091464986 ROC_SCORE:  0.6322740149928114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step :  6180 Loss SD :  0.6936176092298649 Loss G :  0.6952744779949652 Epsilon :  1.2469570914649855 ROC_SCORE:  0.6163057925695098\n",
      "Step :  6190 Loss SD :  0.6929559472807478 Loss G :  0.6946711357091588 Epsilon :  1.2479810914649856 ROC_SCORE:  0.6236620785677001\n",
      "Step :  6200 Loss SD :  0.6931010083461828 Loss G :  0.6946887998243613 Epsilon :  1.249005091464985 ROC_SCORE:  0.6257002286319874\n",
      "Step :  6210 Loss SD :  0.6934258226569981 Loss G :  0.6949153137254523 Epsilon :  1.2500290914649852 ROC_SCORE:  0.6231223215668937\n",
      "Step :  6220 Loss SD :  0.6932116891334558 Loss G :  0.6951531762624674 Epsilon :  1.251053091464985 ROC_SCORE:  0.620455606220132\n",
      "Step :  6230 Loss SD :  0.6933549361237694 Loss G :  0.6948003143960075 Epsilon :  1.252077091464985 ROC_SCORE:  0.6094364719824673\n",
      "Step :  6240 Loss SD :  0.6931480512334656 Loss G :  0.6944639721107976 Epsilon :  1.2531010914649845 ROC_SCORE:  0.6236536911188759\n",
      "Step :  6250 Loss SD :  0.6928278198952692 Loss G :  0.694647819391023 Epsilon :  1.2541250914649846 ROC_SCORE:  0.6155746043837741\n",
      "Step :  6260 Loss SD :  0.6928890088766284 Loss G :  0.6945332124374435 Epsilon :  1.255149091464984 ROC_SCORE:  0.6164681143732257\n",
      "Step :  6270 Loss SD :  0.6931007544976286 Loss G :  0.694668141227269 Epsilon :  1.2561730914649842 ROC_SCORE:  0.6232708287490168\n",
      "Step :  6280 Loss SD :  0.6928451025398257 Loss G :  0.6950994974856286 Epsilon :  1.257197091464984 ROC_SCORE:  0.6251244549391712\n",
      "Step :  6290 Loss SD :  0.6935533654618329 Loss G :  0.6957463825229538 Epsilon :  1.258221091464984 ROC_SCORE:  0.6165860320361075\n",
      "Step :  6300 Loss SD :  0.6934083089724243 Loss G :  0.6959025901776632 Epsilon :  1.2592450914649835 ROC_SCORE:  0.6225243458036606\n",
      "Step :  6310 Loss SD :  0.6931511596143869 Loss G :  0.695982773953208 Epsilon :  1.2602690914649837 ROC_SCORE:  0.6309739604250562\n",
      "Step :  6320 Loss SD :  0.6938911002526649 Loss G :  0.6961035094170863 Epsilon :  1.2612930914649831 ROC_SCORE:  0.6286249813749298\n",
      "Step :  6330 Loss SD :  0.6928977315263003 Loss G :  0.6958486985078506 Epsilon :  1.2623170914649833 ROC_SCORE:  0.6187573945228971\n",
      "Step :  6340 Loss SD :  0.6924800042103074 Loss G :  0.6962203802133456 Epsilon :  1.263341091464983 ROC_SCORE:  0.6277230839366541\n",
      "Step :  6350 Loss SD :  0.6933391967099212 Loss G :  0.6961365520464141 Epsilon :  1.264365091464983 ROC_SCORE:  0.6186310894111913\n",
      "Step :  6360 Loss SD :  0.6932506053533543 Loss G :  0.6962996072082529 Epsilon :  1.2653890914649826 ROC_SCORE:  0.6239645201047148\n",
      "Step :  6370 Loss SD :  0.6931516225925491 Loss G :  0.6961314753894409 Epsilon :  1.2664130914649827 ROC_SCORE:  0.6250203518978823\n",
      "Step :  6380 Loss SD :  0.6934377770856421 Loss G :  0.6962080496112737 Epsilon :  1.2674370914649822 ROC_SCORE:  0.6207151237543406\n",
      "Step :  6390 Loss SD :  0.6933176169857451 Loss G :  0.6958208081825404 Epsilon :  1.2684610914649823 ROC_SCORE:  0.6238091056117954\n",
      "Step :  6400 Loss SD :  0.693222431012604 Loss G :  0.6954768076340385 Epsilon :  1.269485091464982 ROC_SCORE:  0.6308116386213403\n",
      "Step :  6410 Loss SD :  0.6929431156169645 Loss G :  0.6953482287911232 Epsilon :  1.2705090914649821 ROC_SCORE:  0.6204709009797528\n",
      "Step :  6420 Loss SD :  0.6930835035195073 Loss G :  0.6952542072828323 Epsilon :  1.2715330914649816 ROC_SCORE:  0.6200865584718661\n",
      "Step :  6430 Loss SD :  0.693096551808049 Loss G :  0.694821184831902 Epsilon :  1.2725570914649817 ROC_SCORE:  0.6300276588459464\n",
      "Step :  6440 Loss SD :  0.6934129356246181 Loss G :  0.6948423697546492 Epsilon :  1.2735810914649812 ROC_SCORE:  0.6247845165721186\n",
      "Step :  6450 Loss SD :  0.6931904007807737 Loss G :  0.6944960949922736 Epsilon :  1.2746050914649814 ROC_SCORE:  0.6271848070738757\n",
      "Step :  6460 Loss SD :  0.6933307250762307 Loss G :  0.6946102016434292 Epsilon :  1.275629091464981 ROC_SCORE:  0.625013444587086\n",
      "Step :  6470 Loss SD :  0.6931475416741898 Loss G :  0.6940050104423982 Epsilon :  1.2766530914649812 ROC_SCORE:  0.6282184367966261\n",
      "Step :  6480 Loss SD :  0.6932193962422623 Loss G :  0.6942949398184245 Epsilon :  1.2776770914649807 ROC_SCORE:  0.6249246363054176\n",
      "Step :  6490 Loss SD :  0.6929341528839866 Loss G :  0.6948843354937841 Epsilon :  1.2787010914649808 ROC_SCORE:  0.6264758209585571\n",
      "Step :  6500 Loss SD :  0.6931486530944933 Loss G :  0.6948633954362742 Epsilon :  1.2797250914649803 ROC_SCORE:  0.6195773909903012\n",
      "Step :  6510 Loss SD :  0.6930841698922399 Loss G :  0.6952587643054613 Epsilon :  1.2807490914649804 ROC_SCORE:  0.6198576304568988\n",
      "Step :  6520 Loss SD :  0.6932366577156721 Loss G :  0.6958909793984134 Epsilon :  1.28177309146498 ROC_SCORE:  0.6261733794215424\n",
      "Step :  6530 Loss SD :  0.6929337688132112 Loss G :  0.6954698560306092 Epsilon :  1.2827970914649802 ROC_SCORE:  0.6248136259533322\n",
      "Step :  6540 Loss SD :  0.6936375904882641 Loss G :  0.6957586546617452 Epsilon :  1.2838210914649797 ROC_SCORE:  0.6211576850246541\n",
      "Step :  6550 Loss SD :  0.6934339025713525 Loss G :  0.6954214306822109 Epsilon :  1.2848450914649798 ROC_SCORE:  0.6229377976927608\n",
      "Step :  6560 Loss SD :  0.6930025007776656 Loss G :  0.6955145356490585 Epsilon :  1.2858690914649793 ROC_SCORE:  0.619326260904917\n",
      "Step :  6570 Loss SD :  0.6929462369512125 Loss G :  0.69533421870963 Epsilon :  1.2868930914649794 ROC_SCORE:  0.615079251523802\n",
      "Step :  6580 Loss SD :  0.6932363704813066 Loss G :  0.6958777997801942 Epsilon :  1.2879170914649791 ROC_SCORE:  0.6259069545765376\n",
      "Step :  6590 Loss SD :  0.6934666938837114 Loss G :  0.69566757306502 Epsilon :  1.2889410914649793 ROC_SCORE:  0.6231001194964768\n",
      "Step :  6600 Loss SD :  0.6932932896906493 Loss G :  0.6954425078731792 Epsilon :  1.2899650914649787 ROC_SCORE:  0.6178638845334457\n",
      "Step :  6610 Loss SD :  0.6932326695653767 Loss G :  0.6957879913200578 Epsilon :  1.2909890914649789 ROC_SCORE:  0.6200574490906525\n",
      "Step :  6620 Loss SD :  0.6934293704221909 Loss G :  0.6961211021821485 Epsilon :  1.2920130914649783 ROC_SCORE:  0.6197550075536377\n",
      "Step :  6630 Loss SD :  0.6935070839743132 Loss G :  0.695999026704216 Epsilon :  1.2930370914649785 ROC_SCORE:  0.6203598906276673\n",
      "Step :  6640 Loss SD :  0.6937412765827151 Loss G :  0.6954995137286898 Epsilon :  1.2940610914649782 ROC_SCORE:  0.623846602441833\n",
      "Step :  6650 Loss SD :  0.6935101260595714 Loss G :  0.695059456261866 Epsilon :  1.2950850914649783 ROC_SCORE:  0.6085360546822193\n",
      "Step :  6660 Loss SD :  0.6932549325440256 Loss G :  0.6948534132178548 Epsilon :  1.2961090914649778 ROC_SCORE:  0.6251688590800054\n",
      "Step :  6670 Loss SD :  0.6928068845255784 Loss G :  0.6943553539857993 Epsilon :  1.297133091464978 ROC_SCORE:  0.6225756572552912\n",
      "Step :  6680 Loss SD :  0.6932055890331387 Loss G :  0.6940657401521588 Epsilon :  1.2981570914649774 ROC_SCORE:  0.6176862679701092\n",
      "Step :  6690 Loss SD :  0.6933408859607229 Loss G :  0.6943773956091969 Epsilon :  1.2991810914649775 ROC_SCORE:  0.6240380336267624\n",
      "Step :  6700 Loss SD :  0.6932904602175156 Loss G :  0.6946686563264781 Epsilon :  1.3002050914649772 ROC_SCORE:  0.6193109661452962\n",
      "Step :  6710 Loss SD :  0.6931490681131773 Loss G :  0.6951092890687889 Epsilon :  1.3012290914649773 ROC_SCORE:  0.6267713551847756\n",
      "Step :  6720 Loss SD :  0.693078552178115 Loss G :  0.6954254658862887 Epsilon :  1.3022530914649768 ROC_SCORE:  0.6293561695606654\n",
      "Step :  6730 Loss SD :  0.6930078536463771 Loss G :  0.6954203909218283 Epsilon :  1.303277091464977 ROC_SCORE:  0.6277092693150612\n",
      "Step :  6740 Loss SD :  0.693149918595841 Loss G :  0.6954898979456449 Epsilon :  1.3043010914649764 ROC_SCORE:  0.6208177466576016\n",
      "Step :  6750 Loss SD :  0.6931493365705843 Loss G :  0.6952332220654703 Epsilon :  1.3053250914649766 ROC_SCORE:  0.6320006828370102\n",
      "Step :  6760 Loss SD :  0.692945795542805 Loss G :  0.6953362922934512 Epsilon :  1.3063490914649762 ROC_SCORE:  0.617848589773825\n",
      "Step :  6770 Loss SD :  0.6931506215699746 Loss G :  0.6957735323530266 Epsilon :  1.3073730914649764 ROC_SCORE:  0.6035356550449518\n",
      "Step :  6780 Loss SD :  0.692639443810445 Loss G :  0.6958888411075761 Epsilon :  1.3083970914649758 ROC_SCORE:  0.6170507953768382\n",
      "Step :  6790 Loss SD :  0.6933857526626384 Loss G :  0.6956580765778931 Epsilon :  1.309421091464976 ROC_SCORE:  0.6218153596883422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step :  6800 Loss SD :  0.693637989684524 Loss G :  0.6953782342638647 Epsilon :  1.3104450914649755 ROC_SCORE:  0.6170216859956248\n",
      "Step :  6810 Loss SD :  0.6929173445660408 Loss G :  0.6949926261746608 Epsilon :  1.3114690914649756 ROC_SCORE:  0.6190016172974849\n",
      "Step :  6820 Loss SD :  0.6931938115973342 Loss G :  0.6946228326547484 Epsilon :  1.3124930914649753 ROC_SCORE:  0.6199686408089843\n",
      "Step :  6830 Loss SD :  0.6930919396262636 Loss G :  0.694975134307239 Epsilon :  1.3135170914649754 ROC_SCORE:  0.6261067732102912\n",
      "Step :  6840 Loss SD :  0.6926938025623051 Loss G :  0.6952333255704578 Epsilon :  1.3145410914649749 ROC_SCORE:  0.6192596546936657\n",
      "Step :  6850 Loss SD :  0.6928871577752581 Loss G :  0.6948145398104102 Epsilon :  1.315565091464975 ROC_SCORE:  0.6255157047578543\n",
      "Step :  6860 Loss SD :  0.6927123868187623 Loss G :  0.69516923928687 Epsilon :  1.3165374551411577 ROC_SCORE:  0.6261358825915045\n",
      "Step :  6870 Loss SD :  0.6933498165150814 Loss G :  0.6952905395799168 Epsilon :  1.31749745514116 ROC_SCORE:  0.6255823109691055\n",
      "Step :  6880 Loss SD :  0.6934337703250816 Loss G :  0.6954339973053261 Epsilon :  1.3184574551411623 ROC_SCORE:  0.6281005191337442\n",
      "Step :  6890 Loss SD :  0.6931490850626096 Loss G :  0.695078768506881 Epsilon :  1.3194174551411646 ROC_SCORE:  0.6231598183969316\n",
      "Step :  6900 Loss SD :  0.6932016108500842 Loss G :  0.6948356470118864 Epsilon :  1.3203774551411667 ROC_SCORE:  0.6204861957393734\n",
      "Step :  6910 Loss SD :  0.6932327617466587 Loss G :  0.6944888779818047 Epsilon :  1.321337455141169 ROC_SCORE:  0.6163418092615196\n",
      "Step :  6920 Loss SD :  0.6932547378351519 Loss G :  0.6942620251192587 Epsilon :  1.3222974551411713 ROC_SCORE:  0.6241046398380137\n",
      "Step :  6930 Loss SD :  0.6930776586908424 Loss G :  0.6937057360374604 Epsilon :  1.3232574551411733 ROC_SCORE:  0.6271848070738757\n",
      "Step :  6940 Loss SD :  0.6931481999903569 Loss G :  0.6945989129545953 Epsilon :  1.3242174551411756 ROC_SCORE:  0.6239798148643354\n",
      "Step :  6950 Loss SD :  0.6932794456822708 Loss G :  0.694539194515752 Epsilon :  1.325177455141178 ROC_SCORE:  0.6188017986637313\n",
      "Step :  6960 Loss SD :  0.6930504467664782 Loss G :  0.694185242456706 Epsilon :  1.3261374551411802 ROC_SCORE:  0.6181150146188299\n",
      "Step :  6970 Loss SD :  0.6930849660893822 Loss G :  0.6941538903741035 Epsilon :  1.3270974551411823 ROC_SCORE:  0.6248580300941664\n",
      "Step :  6980 Loss SD :  0.6932124869691528 Loss G :  0.694188903453003 Epsilon :  1.3280574551411846 ROC_SCORE:  0.6248595102321943\n",
      "Step :  6990 Loss SD :  0.6933601848547912 Loss G :  0.6945326906297699 Epsilon :  1.3290174551411869 ROC_SCORE:  0.6215045307025031\n",
      "Step :  7000 Loss SD :  0.6929959056929973 Loss G :  0.6947769472120442 Epsilon :  1.329977455141189 ROC_SCORE:  0.6248580300941664\n",
      "Step :  7010 Loss SD :  0.6935233932467393 Loss G :  0.6944656673181668 Epsilon :  1.3309374551411912 ROC_SCORE:  0.6190016172974849\n",
      "Step :  7020 Loss SD :  0.6929936807717968 Loss G :  0.6943782749938218 Epsilon :  1.3318974551411935 ROC_SCORE:  0.6245333864867344\n",
      "Step :  7030 Loss SD :  0.6931729596033855 Loss G :  0.6940368680941295 Epsilon :  1.3328574551411958 ROC_SCORE:  0.6212242912359054\n",
      "Step :  7040 Loss SD :  0.6931472820764841 Loss G :  0.6935906906777819 Epsilon :  1.3338174551411979 ROC_SCORE:  0.6247248176716639\n",
      "Step :  7050 Loss SD :  0.6930903867213041 Loss G :  0.6937623562028948 Epsilon :  1.3347774551412002 ROC_SCORE:  0.6281518305853747\n",
      "Step :  7060 Loss SD :  0.6932378326534616 Loss G :  0.693855862395795 Epsilon :  1.3357374551412025 ROC_SCORE:  0.6187573945228971\n",
      "Step :  7070 Loss SD :  0.6931843405001747 Loss G :  0.6935422621882855 Epsilon :  1.3366974551412045 ROC_SCORE:  0.6217487534770909\n",
      "Step :  7080 Loss SD :  0.6931206698036236 Loss G :  0.6940144021477762 Epsilon :  1.3376574551412068 ROC_SCORE:  0.6186685862412289\n",
      "Step :  7090 Loss SD :  0.6930239555872264 Loss G :  0.6944731506391552 Epsilon :  1.3386174551412091 ROC_SCORE:  0.6286471834453469\n",
      "Step :  7100 Loss SD :  0.6931482137948699 Loss G :  0.694591795725109 Epsilon :  1.3395774551412114 ROC_SCORE:  0.6261289752807082\n",
      "Step :  7110 Loss SD :  0.6930161826791671 Loss G :  0.6945848191117389 Epsilon :  1.3405374551412135 ROC_SCORE:  0.6188462028045655\n",
      "Step :  7120 Loss SD :  0.6927294110673259 Loss G :  0.6945045328533522 Epsilon :  1.3414974551412158 ROC_SCORE:  0.6232624413001927\n",
      "Step :  7130 Loss SD :  0.692933500058335 Loss G :  0.6945197335797866 Epsilon :  1.342457455141218 ROC_SCORE:  0.6224355375219924\n",
      "Step :  7140 Loss SD :  0.6935076917325109 Loss G :  0.6942725698566837 Epsilon :  1.3434174551412201 ROC_SCORE:  0.6223398219295277\n",
      "Step :  7150 Loss SD :  0.6931161714925513 Loss G :  0.6941629196364065 Epsilon :  1.3443774551412224 ROC_SCORE:  0.61556621693495\n",
      "Step :  7160 Loss SD :  0.6930391790992658 Loss G :  0.6943074248140731 Epsilon :  1.3453374551412247 ROC_SCORE:  0.6201684594427379\n",
      "Step :  7170 Loss SD :  0.6931880309439244 Loss G :  0.6944358771729264 Epsilon :  1.346297455141227 ROC_SCORE:  0.6258334410544898\n",
      "Step :  7180 Loss SD :  0.6932628039397194 Loss G :  0.6943770143903821 Epsilon :  1.347257455141229 ROC_SCORE:  0.6225465478740778\n",
      "Step :  7190 Loss SD :  0.6933616764095951 Loss G :  0.694276108749665 Epsilon :  1.3482174551412314 ROC_SCORE:  0.6230044039040121\n",
      "Step :  7200 Loss SD :  0.6930671500559354 Loss G :  0.694459370048226 Epsilon :  1.3491774551412337 ROC_SCORE:  0.6258556431249069\n",
      "Step :  7210 Loss SD :  0.6931044758745507 Loss G :  0.6945652322349242 Epsilon :  1.3501374551412357 ROC_SCORE:  0.6224799416628266\n",
      "Step :  7220 Loss SD :  0.6930250652188539 Loss G :  0.6951335557791418 Epsilon :  1.351097455141238 ROC_SCORE:  0.6201393500615244\n",
      "Step :  7230 Loss SD :  0.6931496577169274 Loss G :  0.6953760550089859 Epsilon :  1.3520574551412403 ROC_SCORE:  0.6210994662622272\n",
      "Step :  7240 Loss SD :  0.6932060904017379 Loss G :  0.6949718540640201 Epsilon :  1.3530174551412426 ROC_SCORE:  0.62209559915494\n",
      "Step :  7250 Loss SD :  0.693111299934115 Loss G :  0.694310154415414 Epsilon :  1.3539774551412447 ROC_SCORE:  0.6242960710229433\n",
      "Step :  7260 Loss SD :  0.6932778896956303 Loss G :  0.6941774037748828 Epsilon :  1.354937455141247 ROC_SCORE:  0.6256780265615702\n",
      "Step :  7270 Loss SD :  0.6935320277343815 Loss G :  0.6946700097160249 Epsilon :  1.3558974551412493 ROC_SCORE:  0.6242891637121467\n",
      "Step :  7280 Loss SD :  0.6929244585448902 Loss G :  0.6949480462828975 Epsilon :  1.3568574551412513 ROC_SCORE:  0.6247179103608675\n",
      "Step :  7290 Loss SD :  0.6930690906958838 Loss G :  0.6943966324257446 Epsilon :  1.3578174551412536 ROC_SCORE:  0.6232846433706097\n",
      "Step :  7300 Loss SD :  0.6930088720994036 Loss G :  0.6946399923372362 Epsilon :  1.358777455141256 ROC_SCORE:  0.6342677609162647\n",
      "Step :  7310 Loss SD :  0.6931482908460542 Loss G :  0.69464225556576 Epsilon :  1.3597374551412582 ROC_SCORE:  0.6184189362938726\n",
      "Step :  7320 Loss SD :  0.6930915645249606 Loss G :  0.6949920489416789 Epsilon :  1.3606974551412603 ROC_SCORE:  0.6184327509154653\n",
      "Step :  7330 Loss SD :  0.6933731377946122 Loss G :  0.6949321355687822 Epsilon :  1.3616574551412626 ROC_SCORE:  0.6229155956223438\n",
      "Step :  7340 Loss SD :  0.6932984413848868 Loss G :  0.6955181543679821 Epsilon :  1.3626174551412649 ROC_SCORE:  0.6192818567640828\n",
      "Step :  7350 Loss SD :  0.6930726682276005 Loss G :  0.6956505285521096 Epsilon :  1.363577455141267 ROC_SCORE:  0.6307741417913025\n",
      "Step :  7360 Loss SD :  0.6935682525325358 Loss G :  0.6958129667979606 Epsilon :  1.3645374551412692 ROC_SCORE:  0.6215198254621237\n",
      "Step :  7370 Loss SD :  0.6932251946345724 Loss G :  0.6955424513974542 Epsilon :  1.3654974551412715 ROC_SCORE:  0.6303675972129988\n",
      "Step :  7380 Loss SD :  0.693390201837573 Loss G :  0.6950521353887283 Epsilon :  1.3664574551412738 ROC_SCORE:  0.6305827106063732\n",
      "Step :  7390 Loss SD :  0.6933625467645688 Loss G :  0.694859602476653 Epsilon :  1.3674174551412759 ROC_SCORE:  0.6222801230290729\n",
      "Step :  7400 Loss SD :  0.6933183747025292 Loss G :  0.694955207278389 Epsilon :  1.3683774551412782 ROC_SCORE:  0.6294962892939643\n",
      "Step :  7410 Loss SD :  0.6928202100410062 Loss G :  0.6943170487768127 Epsilon :  1.3693374551412805 ROC_SCORE:  0.620744233135554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step :  7420 Loss SD :  0.6931204851182111 Loss G :  0.6940284326822523 Epsilon :  1.3702974551412825 ROC_SCORE:  0.6147546079163703\n",
      "Step :  7430 Loss SD :  0.6931806934804721 Loss G :  0.6936865879193066 Epsilon :  1.3712574551412848 ROC_SCORE:  0.6202419729647856\n",
      "Step :  7440 Loss SD :  0.6931665548307634 Loss G :  0.6937423176741868 Epsilon :  1.3722174551412871 ROC_SCORE:  0.6262093961135523\n",
      "Step :  7450 Loss SD :  0.6932094211294716 Loss G :  0.6934323307650337 Epsilon :  1.3731774551412894 ROC_SCORE:  0.6189266236374097\n",
      "Step :  7460 Loss SD :  0.6932396340124946 Loss G :  0.6934420193568307 Epsilon :  1.3741374551412915 ROC_SCORE:  0.6259222493361581\n",
      "Step :  7470 Loss SD :  0.6931291487241503 Loss G :  0.693348716425793 Epsilon :  1.3750974551412938 ROC_SCORE:  0.6217265514066739\n",
      "Step :  7480 Loss SD :  0.6931670491780828 Loss G :  0.6932889586134408 Epsilon :  1.376057455141296 ROC_SCORE:  0.6216530378846263\n",
      "Step :  7490 Loss SD :  0.6931529514033372 Loss G :  0.693193722756656 Epsilon :  1.3770174551412981 ROC_SCORE:  0.6298584297314338\n",
      "Step :  7500 Loss SD :  0.6931528746184388 Loss G :  0.6933320905101328 Epsilon :  1.3779774551413004 ROC_SCORE:  0.6286471834453469\n",
      "Step :  7510 Loss SD :  0.6931058622097647 Loss G :  0.6938242961411801 Epsilon :  1.3789374551413027 ROC_SCORE:  0.6204042947685015\n",
      "Step :  7520 Loss SD :  0.6930880746417617 Loss G :  0.694098744809041 Epsilon :  1.379897455141305 ROC_SCORE:  0.6191708464119974\n",
      "Step :  7530 Loss SD :  0.6931478657731445 Loss G :  0.6943273602809468 Epsilon :  1.380857455141307 ROC_SCORE:  0.6283516492191286\n",
      "Step :  7540 Loss SD :  0.6930523380810838 Loss G :  0.694684932371309 Epsilon :  1.3818174551413094 ROC_SCORE:  0.628402960670759\n",
      "Step :  7550 Loss SD :  0.6931013669347268 Loss G :  0.6946383852038445 Epsilon :  1.3827774551413117 ROC_SCORE:  0.6257224307024044\n",
      "Step :  7560 Loss SD :  0.6932778964508288 Loss G :  0.6945317534934919 Epsilon :  1.3837374551413137 ROC_SCORE:  0.6250356466575029\n",
      "Step :  7570 Loss SD :  0.693147909167963 Loss G :  0.6943570526014776 Epsilon :  1.384697455141316 ROC_SCORE:  0.6250203518978823\n",
      "Step :  7580 Loss SD :  0.6931475708644272 Loss G :  0.6940318817278758 Epsilon :  1.3856574551413183 ROC_SCORE:  0.6285514678528821\n",
      "Step :  7590 Loss SD :  0.6930150036066685 Loss G :  0.6940036622547144 Epsilon :  1.3866174551413206 ROC_SCORE:  0.6270737967217903\n",
      "Step :  7600 Loss SD :  0.6931709596115726 Loss G :  0.6938900786687248 Epsilon :  1.3875774551413227 ROC_SCORE:  0.6177972783221944\n",
      "Step :  7610 Loss SD :  0.6930710101116957 Loss G :  0.6937617192312496 Epsilon :  1.388537455141325 ROC_SCORE:  0.6174420451955213\n",
      "Step :  7620 Loss SD :  0.6930779046162774 Loss G :  0.6938909216231318 Epsilon :  1.3894974551413273 ROC_SCORE:  0.6210619694321894\n",
      "Step :  7630 Loss SD :  0.6931475987716605 Loss G :  0.694077427176198 Epsilon :  1.3904574551413293 ROC_SCORE:  0.6256558244911533\n",
      "Step :  7640 Loss SD :  0.6932149746312284 Loss G :  0.6942215368829618 Epsilon :  1.3914174551413316 ROC_SCORE:  0.6230932121856805\n",
      "Step :  7650 Loss SD :  0.6931264118119627 Loss G :  0.6938154491779759 Epsilon :  1.392377455141334 ROC_SCORE:  0.6242156501900991\n",
      "Step :  7660 Loss SD :  0.6930720316403981 Loss G :  0.6935042521329492 Epsilon :  1.3933374551413362 ROC_SCORE:  0.6158104397095377\n",
      "Step :  7670 Loss SD :  0.6931753713056164 Loss G :  0.694060428583909 Epsilon :  1.3942974551413383 ROC_SCORE:  0.6234691672447428\n",
      "Step :  7680 Loss SD :  0.6931051558138934 Loss G :  0.6945240351804429 Epsilon :  1.3952574551413406 ROC_SCORE:  0.6199839355686049\n",
      "Step :  7690 Loss SD :  0.6931485866398202 Loss G :  0.6948217725663456 Epsilon :  1.3962174551413429 ROC_SCORE:  0.6278937931891941\n",
      "Step :  7700 Loss SD :  0.6930940066452514 Loss G :  0.6948909603051726 Epsilon :  1.397177455141345 ROC_SCORE:  0.6281449232745784\n",
      "Step :  7710 Loss SD :  0.6934632032872918 Loss G :  0.6948083649953065 Epsilon :  1.3981374551413472 ROC_SCORE:  0.6289871218123995\n",
      "Step :  7720 Loss SD :  0.6931488580215004 Loss G :  0.6949934808643162 Epsilon :  1.3990974551413495 ROC_SCORE:  0.6211798870950712\n",
      "Step :  7730 Loss SD :  0.6928982457408397 Loss G :  0.6951692042643046 Epsilon :  1.4000574551413518 ROC_SCORE:  0.6220664897737264\n",
      "Step :  7740 Loss SD :  0.693087092071577 Loss G :  0.6951345545979477 Epsilon :  1.401017455141354 ROC_SCORE:  0.6186907883116459\n",
      "Step :  7750 Loss SD :  0.6932351996354762 Loss G :  0.6945320495483823 Epsilon :  1.4019774551413562 ROC_SCORE:  0.6162974051206855\n",
      "Step :  7760 Loss SD :  0.6931480461445148 Loss G :  0.6944576163697759 Epsilon :  1.4029374551413585 ROC_SCORE:  0.6157369261874899\n",
      "Step :  7770 Loss SD :  0.6934222985395717 Loss G :  0.6945974158266291 Epsilon :  1.4038974551413606 ROC_SCORE:  0.6258181462948692\n",
      "Step :  7780 Loss SD :  0.6930727664233376 Loss G :  0.6943710927769468 Epsilon :  1.4048574551413628 ROC_SCORE:  0.6092228387271207\n",
      "Step :  7790 Loss SD :  0.6930464573629163 Loss G :  0.6947973713190858 Epsilon :  1.4058174551413651 ROC_SCORE:  0.6167705559102405\n",
      "Step :  7800 Loss SD :  0.693005845817583 Loss G :  0.6954482608572226 Epsilon :  1.4067774551413674 ROC_SCORE:  0.6224355375219924\n",
      "Step :  7810 Loss SD :  0.6938521008129789 Loss G :  0.6953857273343161 Epsilon :  1.4077374551413695 ROC_SCORE:  0.6242225575008955\n",
      "Step :  7820 Loss SD :  0.6929475762807374 Loss G :  0.6953217563065001 Epsilon :  1.4086974551413718 ROC_SCORE:  0.6248136259533322\n",
      "Step :  7830 Loss SD :  0.6932130406938384 Loss G :  0.6951794523266777 Epsilon :  1.409657455141374 ROC_SCORE:  0.6246138073195786\n",
      "Step :  7840 Loss SD :  0.6933815295284919 Loss G :  0.6946259287360275 Epsilon :  1.4106174551413762 ROC_SCORE:  0.6225021437332436\n",
      "Step :  7850 Loss SD :  0.6934356818487959 Loss G :  0.6944431943534164 Epsilon :  1.4115774551413784 ROC_SCORE:  0.6173616243626772\n",
      "Step :  7860 Loss SD :  0.6928936565075281 Loss G :  0.6944959452066474 Epsilon :  1.4125374551413807 ROC_SCORE:  0.6220220856328921\n",
      "Step :  7870 Loss SD :  0.693147481644717 Loss G :  0.6939146266093655 Epsilon :  1.413497455141383 ROC_SCORE:  0.6305605085359559\n",
      "Step :  7880 Loss SD :  0.6931697489070647 Loss G :  0.6938536006911913 Epsilon :  1.414457455141385 ROC_SCORE:  0.6243044584717674\n",
      "Step :  7890 Loss SD :  0.693221559247253 Loss G :  0.6939453864978259 Epsilon :  1.4154174551413874 ROC_SCORE:  0.618919716326613\n",
      "Step :  7900 Loss SD :  0.6929357163408212 Loss G :  0.6943019191294686 Epsilon :  1.4163774551413897 ROC_SCORE:  0.6209065549392699\n",
      "Step :  7910 Loss SD :  0.6931826631247509 Loss G :  0.6942618451339652 Epsilon :  1.4173133209210982 ROC_SCORE:  0.6254935026874373\n",
      "Step :  7920 Loss SD :  0.6932934737719738 Loss G :  0.6946952648345495 Epsilon :  1.4182093209210977 ROC_SCORE:  0.6286471834453469\n",
      "Step :  7930 Loss SD :  0.692985040451842 Loss G :  0.6944474735780533 Epsilon :  1.4191053209210978 ROC_SCORE:  0.6077382602852325\n",
      "Step :  7940 Loss SD :  0.6931232132218601 Loss G :  0.6939160659680764 Epsilon :  1.4200013209210973 ROC_SCORE:  0.6254338037869824\n",
      "Step :  7950 Loss SD :  0.6931737081263127 Loss G :  0.6939871670732188 Epsilon :  1.4208973209210973 ROC_SCORE:  0.6076272499331472\n",
      "Step :  7960 Loss SD :  0.6931817196185757 Loss G :  0.6942480482984953 Epsilon :  1.421793320921097 ROC_SCORE:  0.6218819658995933\n",
      "Step :  7970 Loss SD :  0.6932608513239988 Loss G :  0.6943561561046568 Epsilon :  1.422689320921097 ROC_SCORE:  0.6232333319189792\n",
      "Step :  7980 Loss SD :  0.6932280181721767 Loss G :  0.6940021074914413 Epsilon :  1.4235853209210965 ROC_SCORE:  0.6213422088987872\n",
      "Step :  7990 Loss SD :  0.6932397291912266 Loss G :  0.6946193052914771 Epsilon :  1.4244813209210965 ROC_SCORE:  0.6173172202218431\n",
      "Step :  8000 Loss SD :  0.6933687085348157 Loss G :  0.6943217725194137 Epsilon :  1.425377320921096 ROC_SCORE:  0.6227241644374144\n",
      "Step :  8010 Loss SD :  0.6930515279785903 Loss G :  0.693901962847076 Epsilon :  1.4262733209210963 ROC_SCORE:  0.616867751640733\n",
      "Step :  8020 Loss SD :  0.693185143239007 Loss G :  0.6937512653010559 Epsilon :  1.4271693209210956 ROC_SCORE:  0.6275982589629757\n",
      "Step :  8030 Loss SD :  0.6930662349387162 Loss G :  0.6938050809670964 Epsilon :  1.4280653209210958 ROC_SCORE:  0.6165194258248563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step :  8040 Loss SD :  0.6933374880364768 Loss G :  0.6937424208945348 Epsilon :  1.4289613209210954 ROC_SCORE:  0.6245111844163175\n",
      "Step :  8050 Loss SD :  0.6931763329235494 Loss G :  0.6940582893974429 Epsilon :  1.4298573209210954 ROC_SCORE:  0.6183508499445934\n",
      "Step :  8060 Loss SD :  0.6929424105622006 Loss G :  0.6940957095716395 Epsilon :  1.430753320921095 ROC_SCORE:  0.6253311808837213\n",
      "Step :  8070 Loss SD :  0.6930539759586206 Loss G :  0.6941653335950748 Epsilon :  1.431649320921095 ROC_SCORE:  0.6207511404463505\n",
      "Step :  8080 Loss SD :  0.6930655057963419 Loss G :  0.6944635980381397 Epsilon :  1.4325453209210945 ROC_SCORE:  0.6230044039040121\n",
      "Step :  8090 Loss SD :  0.6929631523684516 Loss G :  0.6946221862950462 Epsilon :  1.4334413209210946 ROC_SCORE:  0.6209800684613176\n",
      "Step :  8100 Loss SD :  0.6932194079862102 Loss G :  0.694268962058245 Epsilon :  1.4343373209210941 ROC_SCORE:  0.614318953956853\n",
      "Step :  8110 Loss SD :  0.6931082827045771 Loss G :  0.6937480170637633 Epsilon :  1.4352333209210941 ROC_SCORE:  0.6236689858784964\n",
      "Step :  8120 Loss SD :  0.6932134887690568 Loss G :  0.6935020436674318 Epsilon :  1.4361293209210937 ROC_SCORE:  0.620744233135554\n",
      "Step :  8130 Loss SD :  0.6931474541444063 Loss G :  0.6938865555468281 Epsilon :  1.437025320921094 ROC_SCORE:  0.6217778628583043\n",
      "Step :  8140 Loss SD :  0.6930449390004071 Loss G :  0.6938121364564216 Epsilon :  1.4379213209210933 ROC_SCORE:  0.6101385507869894\n",
      "Step :  8150 Loss SD :  0.6931155944087464 Loss G :  0.6934723726700487 Epsilon :  1.4388173209210935 ROC_SCORE:  0.6152124639463046\n",
      "Step :  8160 Loss SD :  0.693152567013578 Loss G :  0.6933265723539632 Epsilon :  1.439713320921093 ROC_SCORE:  0.6206332227834687\n",
      "Step :  8170 Loss SD :  0.6929807974318862 Loss G :  0.6940657845037272 Epsilon :  1.440609320921093 ROC_SCORE:  0.6228267873406754\n",
      "Step :  8180 Loss SD :  0.693299125956579 Loss G :  0.6947492225836587 Epsilon :  1.4415053209210926 ROC_SCORE:  0.6238979138934637\n",
      "Step :  8190 Loss SD :  0.6933217900798018 Loss G :  0.6945213929018165 Epsilon :  1.4424013209210926 ROC_SCORE:  0.6283072450782944\n",
      "Step :  8200 Loss SD :  0.6932425617827014 Loss G :  0.6946654819762333 Epsilon :  1.4432973209210922 ROC_SCORE:  0.623824400371416\n",
      "Step :  8210 Loss SD :  0.6927574211929568 Loss G :  0.6952543853444116 Epsilon :  1.4441933209210922 ROC_SCORE:  0.6251244549391712\n",
      "Step :  8220 Loss SD :  0.6936360919903146 Loss G :  0.6957299400404818 Epsilon :  1.4450893209210918 ROC_SCORE:  0.6169175829543359\n",
      "Step :  8230 Loss SD :  0.6929954435831329 Loss G :  0.6956256189470287 Epsilon :  1.4459853209210918 ROC_SCORE:  0.622982201833595\n",
      "Step :  8240 Loss SD :  0.6929724544684686 Loss G :  0.6950243178042947 Epsilon :  1.4468813209210913 ROC_SCORE:  0.6179526928151139\n",
      "Step :  8250 Loss SD :  0.6935661661758126 Loss G :  0.6946083560874986 Epsilon :  1.4477773209210913 ROC_SCORE:  0.628898313530731\n",
      "Step :  8260 Loss SD :  0.6932455265398743 Loss G :  0.6941760387944912 Epsilon :  1.448673320921091 ROC_SCORE:  0.6217931576179251\n",
      "Step :  8270 Loss SD :  0.6930799932071171 Loss G :  0.694239671339778 Epsilon :  1.4495693209210911 ROC_SCORE:  0.6259291566469545\n",
      "Step :  8280 Loss SD :  0.6931803098034008 Loss G :  0.6941688451401222 Epsilon :  1.4504653209210905 ROC_SCORE:  0.6249690404462517\n",
      "Step :  8290 Loss SD :  0.6931728807847345 Loss G :  0.6939690141059425 Epsilon :  1.4513613209210907 ROC_SCORE:  0.6244598729646869\n",
      "Step :  8300 Loss SD :  0.6930300433869108 Loss G :  0.6938982589517486 Epsilon :  1.4522573209210903 ROC_SCORE:  0.6219776814920581\n",
      "Step :  8310 Loss SD :  0.693082203271274 Loss G :  0.6936806563991803 Epsilon :  1.4531533209210903 ROC_SCORE:  0.6179082886742798\n",
      "Step :  8320 Loss SD :  0.6931473830217205 Loss G :  0.6937908477036765 Epsilon :  1.4540493209210898 ROC_SCORE:  0.6305230117059183\n",
      "Step :  8330 Loss SD :  0.6931763209153836 Loss G :  0.6940599787325995 Epsilon :  1.4549453209210899 ROC_SCORE:  0.620397387457705\n",
      "Step :  8340 Loss SD :  0.6930676766473238 Loss G :  0.6937777064043665 Epsilon :  1.4558413209210894 ROC_SCORE:  0.6244667802754833\n",
      "Step :  8350 Loss SD :  0.6933254637084325 Loss G :  0.6943002564386154 Epsilon :  1.4567373209210894 ROC_SCORE:  0.62784938904836\n",
      "Step :  8360 Loss SD :  0.6930765832445049 Loss G :  0.6942891856512883 Epsilon :  1.457633320921089 ROC_SCORE:  0.6228420821002962\n",
      "Step :  8370 Loss SD :  0.6932093908969308 Loss G :  0.6941322394522035 Epsilon :  1.458529320921089 ROC_SCORE:  0.6238757118230465\n",
      "Step :  8380 Loss SD :  0.6931789364361621 Loss G :  0.6936598150450805 Epsilon :  1.4594253209210886 ROC_SCORE:  0.6290093238828165\n",
      "Step :  8390 Loss SD :  0.692975133959333 Loss G :  0.6938638780012084 Epsilon :  1.4603213209210888 ROC_SCORE:  0.6217487534770909\n",
      "Step :  8400 Loss SD :  0.693420175506518 Loss G :  0.6945797270893548 Epsilon :  1.4612173209210881 ROC_SCORE:  0.621424109869659\n",
      "Step :  8410 Loss SD :  0.693238873702094 Loss G :  0.6946080826308807 Epsilon :  1.4621133209210884 ROC_SCORE:  0.6309808677358526\n",
      "Step :  8420 Loss SD :  0.6933490830787062 Loss G :  0.6952678649370091 Epsilon :  1.463009320921088 ROC_SCORE:  0.6240311263159659\n",
      "Step :  8430 Loss SD :  0.6929314194839816 Loss G :  0.6954910816394215 Epsilon :  1.463905320921088 ROC_SCORE:  0.6208108393468051\n",
      "Step :  8440 Loss SD :  0.6925775384362505 Loss G :  0.6957911791361456 Epsilon :  1.4648013209210875 ROC_SCORE:  0.6251535643203848\n",
      "Step :  8450 Loss SD :  0.6931510211095049 Loss G :  0.6959289252874735 Epsilon :  1.4656973209210875 ROC_SCORE:  0.6301164671276145\n",
      "Step :  8460 Loss SD :  0.6929767533909377 Loss G :  0.6959478996889924 Epsilon :  1.466593320921087 ROC_SCORE:  0.6258112389840726\n",
      "Step :  8470 Loss SD :  0.6933578384824902 Loss G :  0.696424667808627 Epsilon :  1.467489320921087 ROC_SCORE:  0.6230113112148085\n",
      "Step :  8480 Loss SD :  0.6925899048538262 Loss G :  0.6967683356722494 Epsilon :  1.4683853209210866 ROC_SCORE:  0.6215420275325408\n",
      "Step :  8490 Loss SD :  0.6926810834714178 Loss G :  0.6969278789202858 Epsilon :  1.4692813209210867 ROC_SCORE:  0.6204348842877428\n",
      "Step :  8500 Loss SD :  0.6930286874175904 Loss G :  0.6972100068052572 Epsilon :  1.4701773209210862 ROC_SCORE:  0.6186241821003949\n",
      "Step :  8510 Loss SD :  0.6924789797008308 Loss G :  0.6974935983260236 Epsilon :  1.4710733209210862 ROC_SCORE:  0.6286249813749298\n",
      "Step :  8520 Loss SD :  0.6922879825875687 Loss G :  0.6971305528971283 Epsilon :  1.4719693209210858 ROC_SCORE:  0.6216752399550433\n",
      "Step :  8530 Loss SD :  0.6930282786135509 Loss G :  0.6972246347100539 Epsilon :  1.472865320921086 ROC_SCORE:  0.6240173116943731\n",
      "Step :  8540 Loss SD :  0.6932726345164637 Loss G :  0.6969180536157435 Epsilon :  1.4737613209210854 ROC_SCORE:  0.6284182554303798\n",
      "Step :  8550 Loss SD :  0.6924701368810675 Loss G :  0.6967976861868388 Epsilon :  1.4746573209210856 ROC_SCORE:  0.6255157047578543\n",
      "Step :  8560 Loss SD :  0.693995363866123 Loss G :  0.6969856984165235 Epsilon :  1.4755533209210852 ROC_SCORE:  0.6226866676073766\n",
      "Step :  8570 Loss SD :  0.6931544972959829 Loss G :  0.696977914949873 Epsilon :  1.4764493209210852 ROC_SCORE:  0.6251535643203848\n",
      "Step :  8580 Loss SD :  0.6936282010361462 Loss G :  0.696954220301432 Epsilon :  1.4773453209210847 ROC_SCORE:  0.6247914238829152\n",
      "Step :  8590 Loss SD :  0.6932624824808464 Loss G :  0.6966430079910336 Epsilon :  1.4782413209210847 ROC_SCORE:  0.6231001194964768\n",
      "Step :  8600 Loss SD :  0.6932633418885529 Loss G :  0.6966619779841181 Epsilon :  1.4791373209210843 ROC_SCORE:  0.626084571139874\n",
      "Step :  8610 Loss SD :  0.693347906770633 Loss G :  0.6962767232258766 Epsilon :  1.4800333209210843 ROC_SCORE:  0.6221913147474046\n",
      "Step :  8620 Loss SD :  0.6931521629320828 Loss G :  0.6963030891467872 Epsilon :  1.4809293209210839 ROC_SCORE:  0.6277467661450989\n",
      "Step :  8630 Loss SD :  0.6923901519279887 Loss G :  0.6966560361234422 Epsilon :  1.4818253209210839 ROC_SCORE:  0.6247914238829152\n",
      "Step :  8640 Loss SD :  0.6927466074549306 Loss G :  0.6963934798940216 Epsilon :  1.4827213209210834 ROC_SCORE:  0.6109807493248104\n",
      "Step :  8650 Loss SD :  0.693151094637463 Loss G :  0.6959421917994014 Epsilon :  1.4836173209210837 ROC_SCORE:  0.6260470743098363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step :  8660 Loss SD :  0.6934998696995387 Loss G :  0.695381991127442 Epsilon :  1.484513320921083 ROC_SCORE:  0.6236467838080795\n",
      "Step :  8670 Loss SD :  0.6935505694793122 Loss G :  0.6952769486412088 Epsilon :  1.4854093209210832 ROC_SCORE:  0.6339071006168229\n",
      "Step :  8680 Loss SD :  0.6932690782147548 Loss G :  0.6950735570323543 Epsilon :  1.4863053209210828 ROC_SCORE:  0.619532986849467\n",
      "Step :  8690 Loss SD :  0.693333450931632 Loss G :  0.6946317410857299 Epsilon :  1.4872013209210828 ROC_SCORE:  0.6201531646831172\n",
      "Step :  8700 Loss SD :  0.6931179579642401 Loss G :  0.6940964727794706 Epsilon :  1.4880973209210824 ROC_SCORE:  0.6229377976927608\n",
      "Step :  8710 Loss SD :  0.6933587725041885 Loss G :  0.6939794033505512 Epsilon :  1.4889933209210824 ROC_SCORE:  0.6262538002543864\n",
      "Step :  8720 Loss SD :  0.6931614079069952 Loss G :  0.6936069756538151 Epsilon :  1.489889320921082 ROC_SCORE:  0.6261067732102912\n",
      "Step :  8730 Loss SD :  0.6931471820902423 Loss G :  0.6931815015002515 Epsilon :  1.490785320921082 ROC_SCORE:  0.6202641750352025\n",
      "Step :  8740 Loss SD :  0.6931574892363854 Loss G :  0.6929961556493177 Epsilon :  1.4916813209210815 ROC_SCORE:  0.628011710852076\n",
      "Step :  8750 Loss SD :  0.6931634478909092 Loss G :  0.6929875639261494 Epsilon :  1.4925773209210815 ROC_SCORE:  0.6189863225378645\n",
      "Step :  8760 Loss SD :  0.693156980242833 Loss G :  0.6933019216673371 Epsilon :  1.493473320921081 ROC_SCORE:  0.6197397127940171\n",
      "Step :  8770 Loss SD :  0.69314722434707 Loss G :  0.692860212876635 Epsilon :  1.494369320921081 ROC_SCORE:  0.6271404029330415\n",
      "Step :  8780 Loss SD :  0.6931283514575599 Loss G :  0.6928329551836684 Epsilon :  1.4952653209210807 ROC_SCORE:  0.6271182008626244\n",
      "Step :  8790 Loss SD :  0.6932188156871446 Loss G :  0.6925861108277951 Epsilon :  1.496161320921081 ROC_SCORE:  0.6254713006170202\n",
      "Step :  8800 Loss SD :  0.6931655016486434 Loss G :  0.6932424128246101 Epsilon :  1.4970573209210802 ROC_SCORE:  0.6211729797842749\n",
      "Step :  8810 Loss SD :  0.6931407148573174 Loss G :  0.6933658534518385 Epsilon :  1.4979533209210805 ROC_SCORE:  0.623351249581861\n",
      "Step :  8820 Loss SD :  0.6931820499153791 Loss G :  0.6935086689411606 Epsilon :  1.49884932092108 ROC_SCORE:  0.6210397673617724\n",
      "Step :  8830 Loss SD :  0.6931472700583587 Loss G :  0.6935609053137355 Epsilon :  1.49974532092108 ROC_SCORE:  0.6284695668820104\n",
      "Step :  8840 Loss SD :  0.6931947047842125 Loss G :  0.6939272092272595 Epsilon :  1.5006413209210796 ROC_SCORE:  0.6290981321644847\n",
      "Step :  8850 Loss SD :  0.6930759505206543 Loss G :  0.6943018989480837 Epsilon :  1.5015373209210796 ROC_SCORE:  0.6236467838080795\n",
      "Step :  8860 Loss SD :  0.6929060009963062 Loss G :  0.6944510475460456 Epsilon :  1.5024333209210792 ROC_SCORE:  0.6266894542139037\n",
      "Step :  8870 Loss SD :  0.6934234137289765 Loss G :  0.6945948915233133 Epsilon :  1.5033293209210792 ROC_SCORE:  0.6251826737015982\n",
      "Step :  8880 Loss SD :  0.6932808203539154 Loss G :  0.694562289229864 Epsilon :  1.5042253209210787 ROC_SCORE:  0.6284626595712138\n",
      "Step :  8890 Loss SD :  0.6930931451526817 Loss G :  0.6949206171613623 Epsilon :  1.5051213209210788 ROC_SCORE:  0.6215198254621237\n",
      "Step :  8900 Loss SD :  0.6930338772585674 Loss G :  0.694999128473226 Epsilon :  1.5060173209210783 ROC_SCORE:  0.6242447595713125\n",
      "Step :  8910 Loss SD :  0.6930633346152033 Loss G :  0.6944765004113337 Epsilon :  1.5069133209210785 ROC_SCORE:  0.620212863583572\n",
      "Step :  8920 Loss SD :  0.6930647552559489 Loss G :  0.6940346815871771 Epsilon :  1.507809320921078 ROC_SCORE:  0.6191417370307839\n",
      "Step :  8930 Loss SD :  0.6930669352928858 Loss G :  0.6940207083963523 Epsilon :  1.5087053209210781 ROC_SCORE:  0.6175239461663933\n",
      "Step :  8940 Loss SD :  0.6930572808840082 Loss G :  0.693868902596202 Epsilon :  1.5096013209210777 ROC_SCORE:  0.6249024342350006\n",
      "Step :  8950 Loss SD :  0.6931450695115271 Loss G :  0.6931743639036965 Epsilon :  1.5104973209210777 ROC_SCORE:  0.6156106210757841\n",
      "Step :  8960 Loss SD :  0.6931514464539497 Loss G :  0.6930993104542771 Epsilon :  1.5113933209210773 ROC_SCORE:  0.6237869035413781\n",
      "Step :  8970 Loss SD :  0.6931490934043842 Loss G :  0.6932053037988634 Epsilon :  1.5122893209210773 ROC_SCORE:  0.6260554617586607\n",
      "Step :  8980 Loss SD :  0.6931463215725633 Loss G :  0.6931798863955014 Epsilon :  1.5131853209210768 ROC_SCORE:  0.6249690404462517\n",
      "Step :  8990 Loss SD :  0.6930428273086351 Loss G :  0.6938299501846567 Epsilon :  1.5140813209210768 ROC_SCORE:  0.6241046398380137\n",
      "Step :  9000 Loss SD :  0.6931472658852851 Loss G :  0.6935488354828575 Epsilon :  1.5149773209210764 ROC_SCORE:  0.6294449778423337\n",
      "Step :  9010 Loss SD :  0.6931374850775418 Loss G :  0.6928246558033729 Epsilon :  1.5158733209210764 ROC_SCORE:  0.6265646292402255\n",
      "Step :  9020 Loss SD :  0.6930877477176483 Loss G :  0.6929193425938746 Epsilon :  1.516769320921076 ROC_SCORE:  0.619326260904917\n",
      "Step :  9030 Loss SD :  0.6930797156243169 Loss G :  0.6920567077796179 Epsilon :  1.517665320921076 ROC_SCORE:  0.6156481179058217\n",
      "Step :  9040 Loss SD :  0.693071390179246 Loss G :  0.6919070179235072 Epsilon :  1.5185613209210755 ROC_SCORE:  0.6181816208300811\n",
      "Step :  9050 Loss SD :  0.6934581063975792 Loss G :  0.6917205596269537 Epsilon :  1.5194573209210758 ROC_SCORE:  0.6215711369137543\n",
      "Step :  9060 Loss SD :  0.6927723372783674 Loss G :  0.6916265733953609 Epsilon :  1.5203533209210751 ROC_SCORE:  0.6196731065827659\n",
      "Step :  9070 Loss SD :  0.6927989890232312 Loss G :  0.6912642580553012 Epsilon :  1.5212493209210753 ROC_SCORE:  0.6311875936804027\n",
      "Step :  9080 Loss SD :  0.6934346548424294 Loss G :  0.6913280694228802 Epsilon :  1.522145320921075 ROC_SCORE:  0.6253380881945176\n",
      "Step :  9090 Loss SD :  0.6928859693242242 Loss G :  0.6914586989811733 Epsilon :  1.523041320921075 ROC_SCORE:  0.6284404575007968\n",
      "Step :  9100 Loss SD :  0.6930829088704777 Loss G :  0.6910050212407799 Epsilon :  1.5239373209210745 ROC_SCORE:  0.6191264422711633\n",
      "Step :  9110 Loss SD :  0.6935178711615799 Loss G :  0.6908123970412807 Epsilon :  1.5248333209210745 ROC_SCORE:  0.6179151959850763\n",
      "Step :  9120 Loss SD :  0.6933795325238131 Loss G :  0.6907104599521295 Epsilon :  1.525729320921074 ROC_SCORE:  0.6166748403177758\n",
      "Step :  9130 Loss SD :  0.6929331931192195 Loss G :  0.6908318627065094 Epsilon :  1.526625320921074 ROC_SCORE:  0.625795944224452\n",
      "Step :  9140 Loss SD :  0.6936203538049146 Loss G :  0.6906560509428333 Epsilon :  1.5275213209210736 ROC_SCORE:  0.6286027793045128\n",
      "Step :  9150 Loss SD :  0.6930670557821359 Loss G :  0.6904549292176683 Epsilon :  1.5284173209210736 ROC_SCORE:  0.6220733970845227\n",
      "Step :  9160 Loss SD :  0.6932395099288784 Loss G :  0.6903227791712425 Epsilon :  1.5293133209210732 ROC_SCORE:  0.6128856869665953\n",
      "Step :  9170 Loss SD :  0.693240279855739 Loss G :  0.6902980665884072 Epsilon :  1.5302093209210734 ROC_SCORE:  0.6293630768714619\n",
      "Step :  9180 Loss SD :  0.6929844847869534 Loss G :  0.6905151288356428 Epsilon :  1.5311053209210728 ROC_SCORE:  0.6280561149929101\n",
      "Step :  9190 Loss SD :  0.6932372133159399 Loss G :  0.6903939982308614 Epsilon :  1.532001320921073 ROC_SCORE:  0.628898313530731\n",
      "Step :  9200 Loss SD :  0.6929664740468284 Loss G :  0.6901857336583206 Epsilon :  1.5328973209210726 ROC_SCORE:  0.6253824923353519\n",
      "Step :  9210 Loss SD :  0.6936220434272703 Loss G :  0.6901478232725937 Epsilon :  1.5337933209210726 ROC_SCORE:  0.6298653370422304\n",
      "Step :  9220 Loss SD :  0.6926786141923642 Loss G :  0.6901191513299663 Epsilon :  1.5346893209210721 ROC_SCORE:  0.6191486443415803\n",
      "Step :  9230 Loss SD :  0.6931531277119494 Loss G :  0.6897086491589886 Epsilon :  1.5355475643307965 ROC_SCORE:  0.6283960533599626\n",
      "Step :  9240 Loss SD :  0.6937957634531986 Loss G :  0.6897343610882299 Epsilon :  1.5363795643307956 ROC_SCORE:  0.6242378522605162\n",
      "Step :  9250 Loss SD :  0.692946046923836 Loss G :  0.6898382369821356 Epsilon :  1.537211564330794 ROC_SCORE:  0.6262982043952205\n",
      "Step :  9260 Loss SD :  0.6938059215311398 Loss G :  0.6896964828483841 Epsilon :  1.538043564330793 ROC_SCORE:  0.6213200068283701\n",
      "Step :  9270 Loss SD :  0.6931538316690216 Loss G :  0.6895143317748689 Epsilon :  1.5388755643307916 ROC_SCORE:  0.6147990120572043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step :  9280 Loss SD :  0.6935523194285305 Loss G :  0.689958001563467 Epsilon :  1.5397075643307907 ROC_SCORE:  0.6209731611505211\n",
      "Step :  9290 Loss SD :  0.693325087328958 Loss G :  0.6903643154294001 Epsilon :  1.540539564330789 ROC_SCORE:  0.6240602356971796\n",
      "Step :  9300 Loss SD :  0.6933899152091824 Loss G :  0.6906181555099522 Epsilon :  1.5413715643307881 ROC_SCORE:  0.6175461482368102\n",
      "Step :  9310 Loss SD :  0.6935098511660076 Loss G :  0.6902845104937805 Epsilon :  1.5422035643307865 ROC_SCORE:  0.6289496249823616\n",
      "Step :  9320 Loss SD :  0.6938009925688997 Loss G :  0.6905651566900091 Epsilon :  1.5430355643307856 ROC_SCORE:  0.6249912425166688\n",
      "Step :  9330 Loss SD :  0.6936084294337215 Loss G :  0.6915260334295975 Epsilon :  1.5438675643307842 ROC_SCORE:  0.623720297330127\n",
      "Step :  9340 Loss SD :  0.6933510868048739 Loss G :  0.6915300131061185 Epsilon :  1.5446995643307833 ROC_SCORE:  0.6276648651742271\n",
      "Step :  9350 Loss SD :  0.6934169016172607 Loss G :  0.6914332441834193 Epsilon :  1.5455315643307816 ROC_SCORE:  0.61318812850361\n",
      "Step :  9360 Loss SD :  0.6932259398337701 Loss G :  0.6919216035672525 Epsilon :  1.5463635643307807 ROC_SCORE:  0.624702615601247\n",
      "Step :  9370 Loss SD :  0.6931791913567993 Loss G :  0.6921479747513967 Epsilon :  1.547195564330779 ROC_SCORE:  0.6243335678529808\n",
      "Step :  9380 Loss SD :  0.6931137580589986 Loss G :  0.6920728440410473 Epsilon :  1.5480275643307781 ROC_SCORE:  0.622288510477897\n",
      "Step :  9390 Loss SD :  0.6932158544221321 Loss G :  0.6920527838699775 Epsilon :  1.5488595643307768 ROC_SCORE:  0.6239492253450942\n",
      "Step :  9400 Loss SD :  0.6931016589898018 Loss G :  0.6916616656501329 Epsilon :  1.5496915643307758 ROC_SCORE:  0.6282337315562467\n",
      "Step :  9410 Loss SD :  0.6933185135466893 Loss G :  0.6913441974076605 Epsilon :  1.5505235643307742 ROC_SCORE:  0.6234913693151598\n",
      "Step :  9420 Loss SD :  0.693148628686854 Loss G :  0.6914488040503652 Epsilon :  1.5513555643307733 ROC_SCORE:  0.6249690404462517\n",
      "Step :  9430 Loss SD :  0.6933329246072111 Loss G :  0.6916893118875105 Epsilon :  1.5521875643307717 ROC_SCORE:  0.6225243458036606\n",
      "Step :  9440 Loss SD :  0.6932805982926202 Loss G :  0.6917414538492774 Epsilon :  1.5530195643307707 ROC_SCORE:  0.6226866676073766\n",
      "Step :  9450 Loss SD :  0.6932240711456816 Loss G :  0.6919272353716736 Epsilon :  1.5538515643307693 ROC_SCORE:  0.6125250266671534\n",
      "Step :  9460 Loss SD :  0.6930391556313418 Loss G :  0.6919813499700714 Epsilon :  1.5546835643307684 ROC_SCORE:  0.621564229602958\n",
      "Step :  9470 Loss SD :  0.6932374820583359 Loss G :  0.6921989590814 Epsilon :  1.5555155643307668 ROC_SCORE:  0.6213866130396214\n",
      "Step :  9480 Loss SD :  0.693071345241236 Loss G :  0.6923367954938643 Epsilon :  1.5563475643307658 ROC_SCORE:  0.6170882922068759\n",
      "Step :  9490 Loss SD :  0.6932661916553331 Loss G :  0.692378001584561 Epsilon :  1.5571795643307642 ROC_SCORE:  0.6250065372762895\n",
      "Step :  9500 Loss SD :  0.6930934504219737 Loss G :  0.6913648417575164 Epsilon :  1.5580115643307633 ROC_SCORE:  0.6203307812464538\n",
      "Step :  9510 Loss SD :  0.6931480774256293 Loss G :  0.6918343477456986 Epsilon :  1.5588435643307619 ROC_SCORE:  0.6295406934347985\n",
      "Step :  9520 Loss SD :  0.693193464582582 Loss G :  0.691703249730811 Epsilon :  1.559675564330761 ROC_SCORE:  0.6260179649286228\n",
      "Step :  9530 Loss SD :  0.693000813861605 Loss G :  0.691969723913833 Epsilon :  1.5605075643307593 ROC_SCORE:  0.6235066640747805\n",
      "Step :  9540 Loss SD :  0.6928529559545435 Loss G :  0.6919591420437579 Epsilon :  1.5613395643307584 ROC_SCORE:  0.6258556431249069\n",
      "Step :  9550 Loss SD :  0.6931475337226998 Loss G :  0.6923227791585175 Epsilon :  1.5621715643307568 ROC_SCORE:  0.6240311263159659\n",
      "Step :  9560 Loss SD :  0.6930594892755404 Loss G :  0.6927275380873056 Epsilon :  1.5630035643307558 ROC_SCORE:  0.6289871218123995\n",
      "Step :  9570 Loss SD :  0.6931040626152011 Loss G :  0.692465756545616 Epsilon :  1.5638355643307544 ROC_SCORE:  0.6227823831998414\n",
      "Step :  9580 Loss SD :  0.6930523354025333 Loss G :  0.6921174775991068 Epsilon :  1.5646675643307535 ROC_SCORE:  0.6168371621214916\n",
      "Step :  9590 Loss SD :  0.6932489008798928 Loss G :  0.6923487040939841 Epsilon :  1.5654995643307519 ROC_SCORE:  0.6245180917271139\n",
      "Step :  9600 Loss SD :  0.6932080120315607 Loss G :  0.6921926079912891 Epsilon :  1.566331564330751 ROC_SCORE:  0.6224424448327888\n",
      "Step :  9610 Loss SD :  0.6931640911286834 Loss G :  0.692604967630239 Epsilon :  1.5671635643307493 ROC_SCORE:  0.6208774455580565\n",
      "Step :  9620 Loss SD :  0.6931578653455783 Loss G :  0.6929859516757771 Epsilon :  1.5679955643307484 ROC_SCORE:  0.6270515946513732\n",
      "Step :  9630 Loss SD :  0.6931472358704116 Loss G :  0.6934927982006828 Epsilon :  1.568827564330747 ROC_SCORE:  0.6171701931777478\n",
      "Step :  9640 Loss SD :  0.6931512913125868 Loss G :  0.6932860853163646 Epsilon :  1.569659564330746 ROC_SCORE:  0.6248427353345457\n",
      "Step :  9650 Loss SD :  0.6931471748493102 Loss G :  0.6931553677484852 Epsilon :  1.5704915643307444 ROC_SCORE:  0.6265493344806048\n",
      "Step :  9660 Loss SD :  0.6931273696622462 Loss G :  0.6929878438603602 Epsilon :  1.5713235643307435 ROC_SCORE:  0.6310252718766867\n",
      "Step :  9670 Loss SD :  0.693147212279185 Loss G :  0.6928983386455065 Epsilon :  1.5721555643307419 ROC_SCORE:  0.6269336769884915\n",
      "Step :  9680 Loss SD :  0.6931235396957083 Loss G :  0.6928817772104068 Epsilon :  1.572987564330741 ROC_SCORE:  0.6214310171804555\n",
      "Step :  9690 Loss SD :  0.693300221114048 Loss G :  0.6925523589250169 Epsilon :  1.5738195643307396 ROC_SCORE:  0.6235066640747805\n",
      "Step :  9700 Loss SD :  0.6931170947709714 Loss G :  0.6929076495768856 Epsilon :  1.5746515643307386 ROC_SCORE:  0.6158326417799548\n",
      "Step :  9710 Loss SD :  0.6931638320800789 Loss G :  0.6936873202736924 Epsilon :  1.575483564330737 ROC_SCORE:  0.6232999381302305\n",
      "Step :  9720 Loss SD :  0.6931310986829544 Loss G :  0.6936627054261425 Epsilon :  1.576315564330736 ROC_SCORE:  0.6194219764973816\n",
      "Step :  9730 Loss SD :  0.6931961533558253 Loss G :  0.6939313228356105 Epsilon :  1.5771475643307344 ROC_SCORE:  0.6267782624955719\n",
      "Step :  9740 Loss SD :  0.6931486802130293 Loss G :  0.6949123661092647 Epsilon :  1.5779795643307335 ROC_SCORE:  0.6196731065827659\n",
      "Step :  9750 Loss SD :  0.6930846543151308 Loss G :  0.6952077767444206 Epsilon :  1.578811564330732 ROC_SCORE:  0.6224133354515753\n",
      "Step :  9760 Loss SD :  0.693282683160846 Loss G :  0.6945652905888938 Epsilon :  1.5796435643307312 ROC_SCORE:  0.6226200613961254\n",
      "Step :  9770 Loss SD :  0.6931971311821706 Loss G :  0.693950212023234 Epsilon :  1.5804755643307296 ROC_SCORE:  0.6298293203502204\n",
      "Step :  9780 Loss SD :  0.69318974034111 Loss G :  0.6935725508926458 Epsilon :  1.5813075643307286 ROC_SCORE:  0.6227310717482107\n",
      "Step :  9790 Loss SD :  0.6931653022371227 Loss G :  0.6937212617555434 Epsilon :  1.582139564330727 ROC_SCORE:  0.6232624413001927\n",
      "Step :  9800 Loss SD :  0.6930854205405548 Loss G :  0.694165577362745 Epsilon :  1.582971564330726 ROC_SCORE:  0.6194954900194293\n",
      "Step :  9810 Loss SD :  0.6931476250088306 Loss G :  0.6940793169123768 Epsilon :  1.5838035643307247 ROC_SCORE:  0.6256780265615702\n",
      "Step :  9820 Loss SD :  0.6931261494861334 Loss G :  0.6938325224098824 Epsilon :  1.5846355643307237 ROC_SCORE:  0.6264092147473059\n",
      "Step :  9830 Loss SD :  0.6931660085968271 Loss G :  0.6937434805747617 Epsilon :  1.5854675643307221 ROC_SCORE:  0.6238979138934637\n",
      "Step :  9840 Loss SD :  0.6930822937060779 Loss G :  0.6942063715934098 Epsilon :  1.5862995643307212 ROC_SCORE:  0.6290537280236506\n",
      "Step :  9850 Loss SD :  0.6933443689452972 Loss G :  0.694713080994167 Epsilon :  1.5871315643307196 ROC_SCORE:  0.6180928125484129\n",
      "Step :  9860 Loss SD :  0.6931486064367256 Loss G :  0.6948365550590002 Epsilon :  1.5879635643307186 ROC_SCORE:  0.6178569772226492\n",
      "Step :  9870 Loss SD :  0.693095752073572 Loss G :  0.6948369527110503 Epsilon :  1.5887955643307172 ROC_SCORE:  0.6244001740642321\n",
      "Step :  9880 Loss SD :  0.6930443001875044 Loss G :  0.6947960518528812 Epsilon :  1.5896275643307163 ROC_SCORE:  0.6212756026875359\n",
      "Step :  9890 Loss SD :  0.6933515925091893 Loss G :  0.6953070794598513 Epsilon :  1.5904595643307147 ROC_SCORE:  0.625013444587086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step :  9900 Loss SD :  0.6934407662205431 Loss G :  0.6950006927373857 Epsilon :  1.5912915643307137 ROC_SCORE:  0.6161281760061732\n",
      "Step :  9910 Loss SD :  0.6933083890985869 Loss G :  0.6948647250809823 Epsilon :  1.5921235643307121 ROC_SCORE:  0.6213644109692043\n",
      "Step :  9920 Loss SD :  0.6935413837348603 Loss G :  0.6949289157388536 Epsilon :  1.5929555643307112 ROC_SCORE:  0.6223023250994899\n",
      "Step :  9930 Loss SD :  0.6930464865662753 Loss G :  0.6947791044582523 Epsilon :  1.5937875643307098 ROC_SCORE:  0.6153096596767971\n",
      "Step :  9940 Loss SD :  0.6929094393283215 Loss G :  0.6950556236798693 Epsilon :  1.5946195643307088 ROC_SCORE:  0.6130188993890977\n",
      "Step :  9950 Loss SD :  0.6930360737614245 Loss G :  0.6949631034036086 Epsilon :  1.5954515643307072 ROC_SCORE:  0.6174060285035115\n",
      "Step :  9960 Loss SD :  0.6928621386531475 Loss G :  0.6949963619956899 Epsilon :  1.5962835643307063 ROC_SCORE:  0.6244736875862797\n",
      "Step :  9970 Loss SD :  0.6933954090295869 Loss G :  0.6947228824533861 Epsilon :  1.5971155643307047 ROC_SCORE:  0.6201018532314867\n",
      "Step :  9980 Loss SD :  0.6935127727142953 Loss G :  0.6950802733612544 Epsilon :  1.5979475643307037 ROC_SCORE:  0.6246957082904504\n",
      "Step :  9990 Loss SD :  0.6929927726407621 Loss G :  0.6947929654323775 Epsilon :  1.5987795643307023 ROC_SCORE:  0.6211798870950712\n",
      "Step :  10000 Loss SD :  0.6931161524204494 Loss G :  0.69416429105692 Epsilon :  1.5996115643307014 ROC_SCORE:  0.6259735607877887\n",
      "Step :  10010 Loss SD :  0.6932516019644186 Loss G :  0.6942620743203357 Epsilon :  1.6004435643306998 ROC_SCORE:  0.6186616789304326\n",
      "Step :  10020 Loss SD :  0.6931139439106 Loss G :  0.6942372729249267 Epsilon :  1.6012755643306988 ROC_SCORE:  0.6232624413001927\n",
      "Step :  10030 Loss SD :  0.6931487182934124 Loss G :  0.6949173233768238 Epsilon :  1.6021075643306972 ROC_SCORE:  0.6255961255906984\n",
      "Step :  10040 Loss SD :  0.693626406983948 Loss G :  0.695702420815735 Epsilon :  1.6029395643306963 ROC_SCORE:  0.6211729797842749\n",
      "Step :  10050 Loss SD :  0.6931509275485932 Loss G :  0.695886326115814 Epsilon :  1.603771564330695 ROC_SCORE:  0.6202932844164162\n",
      "Step :  10060 Loss SD :  0.6925339017967507 Loss G :  0.6959942076388398 Epsilon :  1.604603564330694 ROC_SCORE:  0.6123459299657892\n",
      "Step :  10070 Loss SD :  0.6931527539396628 Loss G :  0.6964779946392367 Epsilon :  1.6054355643306923 ROC_SCORE:  0.622162205366191\n",
      "Step :  10080 Loss SD :  0.6936966535123381 Loss G :  0.6960400361324267 Epsilon :  1.6062675643306914 ROC_SCORE:  0.6284182554303798\n",
      "Step :  10090 Loss SD :  0.6929668149522901 Loss G :  0.6961191881961303 Epsilon :  1.6070995643306898 ROC_SCORE:  0.626984988440122\n",
      "Step :  10100 Loss SD :  0.6927694471593691 Loss G :  0.6962152998232773 Epsilon :  1.6079315643306888 ROC_SCORE:  0.6149391317905032\n",
      "Step :  10110 Loss SD :  0.6934154471572107 Loss G :  0.6959685876159046 Epsilon :  1.6087635643306875 ROC_SCORE:  0.6242669616417297\n",
      "Step :  10120 Loss SD :  0.6931511132903098 Loss G :  0.6959534117018301 Epsilon :  1.6095955643306865 ROC_SCORE:  0.6243848793046114\n",
      "Step :  10130 Loss SD :  0.6933561301880095 Loss G :  0.6964159389565924 Epsilon :  1.610427564330685 ROC_SCORE:  0.6265715365510218\n",
      "Step :  10140 Loss SD :  0.6928729656469521 Loss G :  0.6961411916752439 Epsilon :  1.611259564330684 ROC_SCORE:  0.6238313076822123\n",
      "Step :  10150 Loss SD :  0.6929688751672081 Loss G :  0.6960666042922145 Epsilon :  1.6120915643306823 ROC_SCORE:  0.6275469475113452\n",
      "Step :  10160 Loss SD :  0.6927983062163622 Loss G :  0.6959746772023461 Epsilon :  1.6129235643306814 ROC_SCORE:  0.6175974596884408\n",
      "Step :  10170 Loss SD :  0.6931499844663842 Loss G :  0.6955104088144234 Epsilon :  1.61375556433068 ROC_SCORE:  0.6231958350889416\n",
      "Step :  10180 Loss SD :  0.6929731444064633 Loss G :  0.6960073525876131 Epsilon :  1.614587564330679 ROC_SCORE:  0.6187573945228971\n",
      "Step :  10190 Loss SD :  0.6933440428615126 Loss G :  0.6962367455834435 Epsilon :  1.6154195643306775 ROC_SCORE:  0.6240824377675965\n",
      "Step :  10200 Loss SD :  0.6929581017993962 Loss G :  0.696244428318105 Epsilon :  1.6162515643306765 ROC_SCORE:  0.625138269560764\n",
      "Step :  10210 Loss SD :  0.693232949212081 Loss G :  0.6957733294196095 Epsilon :  1.617083564330675 ROC_SCORE:  0.6224355375219924\n",
      "Step :  10220 Loss SD :  0.6928154722923352 Loss G :  0.6958258845306636 Epsilon :  1.617915564330674 ROC_SCORE:  0.6222357188882386\n",
      "Step :  10230 Loss SD :  0.6938734763933534 Loss G :  0.6960323716178943 Epsilon :  1.6187475643306726 ROC_SCORE:  0.6205528019506246\n",
      "Step :  10240 Loss SD :  0.6931515231255535 Loss G :  0.6961154672433183 Epsilon :  1.6195795643306716 ROC_SCORE:  0.6246360093899956\n",
      "Step :  10250 Loss SD :  0.6926608545508202 Loss G :  0.6957659373955428 Epsilon :  1.62041156433067 ROC_SCORE:  0.6239714274155113\n",
      "Step :  10260 Loss SD :  0.6933106511172815 Loss G :  0.6957130010094477 Epsilon :  1.621243564330669 ROC_SCORE:  0.6194594733274192\n",
      "Step :  10270 Loss SD :  0.6931504608288563 Loss G :  0.6957139573675618 Epsilon :  1.6220755643306675 ROC_SCORE:  0.6193568504241582\n",
      "Step :  10280 Loss SD :  0.693443268140724 Loss G :  0.696271760306251 Epsilon :  1.6229075643306665 ROC_SCORE:  0.6237647014709613\n",
      "Step :  10290 Loss SD :  0.6929693356891067 Loss G :  0.6960612938523483 Epsilon :  1.6237395643306651 ROC_SCORE:  0.624769221812498\n",
      "Step :  10300 Loss SD :  0.6928620683052988 Loss G :  0.6962353094306871 Epsilon :  1.6245715643306642 ROC_SCORE:  0.6194885827086329\n",
      "Step :  10310 Loss SD :  0.6935810113290752 Loss G :  0.6958889742079677 Epsilon :  1.6254035643306626 ROC_SCORE:  0.6315275320474552\n",
      "Step :  10320 Loss SD :  0.6930701412107947 Loss G :  0.6957325426463977 Epsilon :  1.6262355643306616 ROC_SCORE:  0.6222357188882386\n",
      "Step :  10330 Loss SD :  0.6928864834857104 Loss G :  0.6952541041616725 Epsilon :  1.62706756433066 ROC_SCORE:  0.6308476553133502\n",
      "Step :  10340 Loss SD :  0.6928428059431956 Loss G :  0.6950996431932962 Epsilon :  1.627899564330659 ROC_SCORE:  0.6273846257076294\n",
      "Step :  10350 Loss SD :  0.6933293156253812 Loss G :  0.6950471611442918 Epsilon :  1.6287315643306577 ROC_SCORE:  0.6236245817376622\n",
      "Step :  10360 Loss SD :  0.6929055515542297 Loss G :  0.695110066430819 Epsilon :  1.6295635643306567 ROC_SCORE:  0.6206485175430893\n",
      "Step :  10370 Loss SD :  0.6932921299705389 Loss G :  0.695426581383354 Epsilon :  1.6303955643306551 ROC_SCORE:  0.6222357188882386\n",
      "Step :  10380 Loss SD :  0.6927620450584552 Loss G :  0.6956597471812569 Epsilon :  1.6312275643306542 ROC_SCORE:  0.6271848070738757\n",
      "Step :  10390 Loss SD :  0.6926904683560993 Loss G :  0.6961063966268899 Epsilon :  1.6320595643306526 ROC_SCORE:  0.6252354652912565\n",
      "Step :  10400 Loss SD :  0.6928650303046857 Loss G :  0.6962108948087126 Epsilon :  1.6328915643306516 ROC_SCORE:  0.6303009910017475\n",
      "Step :  10410 Loss SD :  0.6938226667557252 Loss G :  0.696218539159321 Epsilon :  1.6337235643306502 ROC_SCORE:  0.627827186977943\n",
      "Step :  10420 Loss SD :  0.693692008897872 Loss G :  0.6956102172203991 Epsilon :  1.6345555643306493 ROC_SCORE:  0.6240977325272172\n",
      "Step :  10430 Loss SD :  0.6931500051289037 Loss G :  0.6955315636125091 Epsilon :  1.6353875643306477 ROC_SCORE:  0.6220733970845227\n",
      "Step :  10440 Loss SD :  0.692864589085862 Loss G :  0.6954347823767951 Epsilon :  1.6362195643306467 ROC_SCORE:  0.6244445782050662\n",
      "Step :  10450 Loss SD :  0.693331038983598 Loss G :  0.6960316933666421 Epsilon :  1.6370515643306451 ROC_SCORE:  0.6167552611506198\n",
      "Step :  10460 Loss SD :  0.6934455189760758 Loss G :  0.6962739971190236 Epsilon :  1.6378835643306442 ROC_SCORE:  0.6294518851531302\n",
      "Step :  10470 Loss SD :  0.6929617018746561 Loss G :  0.6962030712062464 Epsilon :  1.6387155643306428 ROC_SCORE:  0.6300804504356047\n",
      "Step :  10480 Loss SD :  0.6934494752788183 Loss G :  0.696321929848197 Epsilon :  1.6395475643306419 ROC_SCORE:  0.6221552980553946\n",
      "Step :  10490 Loss SD :  0.6933965022820252 Loss G :  0.6970443404360673 Epsilon :  1.6403795643306402 ROC_SCORE:  0.622982201833595\n",
      "Step :  10500 Loss SD :  0.6931555647722168 Loss G :  0.6972550608659538 Epsilon :  1.6412115643306393 ROC_SCORE:  0.6182773364225458\n",
      "Step :  10510 Loss SD :  0.6930204709680383 Loss G :  0.697498639459306 Epsilon :  1.6420435643306377 ROC_SCORE:  0.6215198254621237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step :  10520 Loss SD :  0.6932883888390853 Loss G :  0.6973936635754069 Epsilon :  1.6428755643306368 ROC_SCORE:  0.6233221402006475\n",
      "Step :  10530 Loss SD :  0.6933029789018507 Loss G :  0.6977961785391 Epsilon :  1.6437075643306354 ROC_SCORE:  0.6227088696777937\n",
      "Step :  10540 Loss SD :  0.6929946219672928 Loss G :  0.6984923575043229 Epsilon :  1.6445395643306344 ROC_SCORE:  0.6229155956223438\n",
      "Step :  10550 Loss SD :  0.693160038946137 Loss G :  0.6982405681061005 Epsilon :  1.6453715643306328 ROC_SCORE:  0.6256642119399775\n",
      "Step :  10560 Loss SD :  0.6928393848638821 Loss G :  0.6983178188483872 Epsilon :  1.6462035643306319 ROC_SCORE:  0.6226422634665425\n",
      "Step :  10570 Loss SD :  0.6933170409840098 Loss G :  0.6981869880523198 Epsilon :  1.6470355643306303 ROC_SCORE:  0.6222066095070252\n",
      "Step :  10580 Loss SD :  0.6927026890262458 Loss G :  0.6980243413991792 Epsilon :  1.6478675643306293 ROC_SCORE:  0.6323919326556932\n",
      "Step :  10590 Loss SD :  0.6932936839643834 Loss G :  0.6975220165686674 Epsilon :  1.648699564330628 ROC_SCORE:  0.6238535097526295\n",
      "Step :  10600 Loss SD :  0.6930159279951341 Loss G :  0.6976991203933787 Epsilon :  1.649531564330627 ROC_SCORE:  0.6207220310651369\n",
      "Step :  10610 Loss SD :  0.6937878509670377 Loss G :  0.6981760898785837 Epsilon :  1.6503635643306254 ROC_SCORE:  0.6243557699233979\n",
      "Step :  10620 Loss SD :  0.6934733362330192 Loss G :  0.6981833124659034 Epsilon :  1.6511955643306244 ROC_SCORE:  0.6290162311936129\n",
      "Step :  10630 Loss SD :  0.6936843073297737 Loss G :  0.6973793708145596 Epsilon :  1.6520275643306228 ROC_SCORE:  0.6267491531143584\n",
      "Step :  10640 Loss SD :  0.6935692797972852 Loss G :  0.6975438220702634 Epsilon :  1.6528595643306219 ROC_SCORE:  0.6279159952596113\n",
      "Step :  10650 Loss SD :  0.6936985163540347 Loss G :  0.6974737303932588 Epsilon :  1.6536915643306205 ROC_SCORE:  0.6214754213212896\n",
      "Step :  10660 Loss SD :  0.69233950738938 Loss G :  0.697531040600154 Epsilon :  1.6545235643306195 ROC_SCORE:  0.6144590736901518\n",
      "Step :  10670 Loss SD :  0.6934535814267359 Loss G :  0.6978760887499811 Epsilon :  1.655355564330618 ROC_SCORE:  0.6251091601795506\n",
      "Step :  10680 Loss SD :  0.6926449756849664 Loss G :  0.6972284435771954 Epsilon :  1.656187564330617 ROC_SCORE:  0.6222288115774424\n",
      "Step :  10690 Loss SD :  0.6930433006978634 Loss G :  0.6966771234912292 Epsilon :  1.6570195643306154 ROC_SCORE:  0.6110473555360616\n",
      "Step :  10700 Loss SD :  0.6936069967340692 Loss G :  0.6967795465651928 Epsilon :  1.6578515643306144 ROC_SCORE:  0.6232042225377658\n",
      "Step :  10710 Loss SD :  0.6922793942996519 Loss G :  0.6971661278666376 Epsilon :  1.658683564330613 ROC_SCORE:  0.6207511404463505\n",
      "Step :  10720 Loss SD :  0.6935269903382214 Loss G :  0.6971149658845177 Epsilon :  1.659515564330612 ROC_SCORE:  0.6210466746725688\n",
      "Step :  10730 Loss SD :  0.6934858710705172 Loss G :  0.6966974904428612 Epsilon :  1.6603475643306105 ROC_SCORE:  0.6240533283863832\n",
      "Step :  10740 Loss SD :  0.6931550743915723 Loss G :  0.6971467498004502 Epsilon :  1.6611795643306095 ROC_SCORE:  0.6186172747895985\n",
      "Step :  10750 Loss SD :  0.6927355566532417 Loss G :  0.6976456113125937 Epsilon :  1.662011564330608 ROC_SCORE:  0.6251313622499677\n",
      "Step :  10760 Loss SD :  0.692898458863133 Loss G :  0.6972673384444094 Epsilon :  1.662843564330607 ROC_SCORE:  0.6237647014709613\n",
      "Step :  10770 Loss SD :  0.6936378193993049 Loss G :  0.6970019214008467 Epsilon :  1.6636755643306056 ROC_SCORE:  0.623108506945301\n",
      "Step :  10780 Loss SD :  0.6931544987714839 Loss G :  0.696986214002028 Epsilon :  1.6645075643306046 ROC_SCORE:  0.622982201833595\n",
      "Step :  10790 Loss SD :  0.693800819469844 Loss G :  0.6972568248255244 Epsilon :  1.665339564330603 ROC_SCORE:  0.6184771550562995\n",
      "Step :  10800 Loss SD :  0.6932591140779545 Loss G :  0.6965321810659272 Epsilon :  1.666171564330602 ROC_SCORE:  0.6259957628582057\n",
      "Step :  10810 Loss SD :  0.6927713869460802 Loss G :  0.6962026470552487 Epsilon :  1.6670035643306005 ROC_SCORE:  0.6276648651742271\n",
      "Step :  10820 Loss SD :  0.6931538091348403 Loss G :  0.6967966848885491 Epsilon :  1.6678355643305995 ROC_SCORE:  0.6184174561558446\n",
      "Step :  10830 Loss SD :  0.6934620099963549 Loss G :  0.6964381583169551 Epsilon :  1.6686675643305982 ROC_SCORE:  0.6236092869780416\n",
      "Step :  10840 Loss SD :  0.693614505609508 Loss G :  0.6960871502717566 Epsilon :  1.6694995643305972 ROC_SCORE:  0.6269336769884915\n",
      "Step :  10850 Loss SD :  0.6933615145482179 Loss G :  0.6965220679518712 Epsilon :  1.6703315643305956 ROC_SCORE:  0.6220886918441435\n",
      "Step :  10860 Loss SD :  0.692755045500229 Loss G :  0.6963349903280363 Epsilon :  1.6711635643305947 ROC_SCORE:  0.6194954900194293\n",
      "Step :  10870 Loss SD :  0.6936230688782784 Loss G :  0.6961485503606808 Epsilon :  1.671995564330593 ROC_SCORE:  0.622959999763178\n",
      "Step :  10880 Loss SD :  0.6928280131302174 Loss G :  0.6957136783379414 Epsilon :  1.672827564330592 ROC_SCORE:  0.6249468383758346\n",
      "Step :  10890 Loss SD :  0.6928921320799997 Loss G :  0.6959234997275354 Epsilon :  1.6736595643305907 ROC_SCORE:  0.6255226120686508\n",
      "Step :  10900 Loss SD :  0.6935955434242137 Loss G :  0.6955032741443787 Epsilon :  1.6744915643305898 ROC_SCORE:  0.6300429536055668\n",
      "Step :  10910 Loss SD :  0.6932294734152609 Loss G :  0.6956766640636464 Epsilon :  1.6752684701792608 ROC_SCORE:  0.6238757118230465\n",
      "Step :  10920 Loss SD :  0.693074728644273 Loss G :  0.6955717678384261 Epsilon :  1.6760364701792603 ROC_SCORE:  0.6286984948969774\n",
      "Step :  10930 Loss SD :  0.6938541626605362 Loss G :  0.6959417851095215 Epsilon :  1.6768044701792597 ROC_SCORE:  0.6164237102323915\n",
      "Step :  10940 Loss SD :  0.6937436122416749 Loss G :  0.6955134272418396 Epsilon :  1.6775724701792591 ROC_SCORE:  0.6267116562843208\n",
      "Step :  10950 Loss SD :  0.6929807017425169 Loss G :  0.6958746254263728 Epsilon :  1.6783404701792586 ROC_SCORE:  0.6204042947685015\n",
      "Step :  10960 Loss SD :  0.6930550814321347 Loss G :  0.6962645200273538 Epsilon :  1.6791084701792582 ROC_SCORE:  0.623351249581861\n",
      "Step :  10970 Loss SD :  0.6928376242831029 Loss G :  0.6965224628709924 Epsilon :  1.6798764701792577 ROC_SCORE:  0.6230488080448462\n",
      "Step :  10980 Loss SD :  0.6928378844121719 Loss G :  0.696519329178055 Epsilon :  1.680644470179257 ROC_SCORE:  0.6284626595712138\n",
      "Step :  10990 Loss SD :  0.6929089862391079 Loss G :  0.6970916997016088 Epsilon :  1.6814124701792565 ROC_SCORE:  0.6283960533599626\n",
      "Step :  11000 Loss SD :  0.6928865926761554 Loss G :  0.6974950604422862 Epsilon :  1.682180470179256 ROC_SCORE:  0.623846602441833\n",
      "Step :  11010 Loss SD :  0.6938555687318448 Loss G :  0.6976242272152948 Epsilon :  1.6829484701792554 ROC_SCORE:  0.6276648651742271\n",
      "Step :  11020 Loss SD :  0.6940126910659377 Loss G :  0.6977186796065117 Epsilon :  1.683716470179255 ROC_SCORE:  0.6249024342350006\n",
      "Step :  11030 Loss SD :  0.6933896806042998 Loss G :  0.6968989489129418 Epsilon :  1.6844844701792545 ROC_SCORE:  0.623351249581861\n",
      "Step :  11040 Loss SD :  0.6927522817027277 Loss G :  0.6963481362526946 Epsilon :  1.685252470179254 ROC_SCORE:  0.6229377976927608\n",
      "Step :  11050 Loss SD :  0.6928482273878809 Loss G :  0.6963959664029753 Epsilon :  1.6860204701792534 ROC_SCORE:  0.6248067186425359\n",
      "Step :  11060 Loss SD :  0.6929604380818235 Loss G :  0.6962214198561957 Epsilon :  1.6867884701792528 ROC_SCORE:  0.6276426631038099\n",
      "Step :  11070 Loss SD :  0.6934599176511982 Loss G :  0.6964308532566093 Epsilon :  1.6875564701792525 ROC_SCORE:  0.6250800507983371\n",
      "Step :  11080 Loss SD :  0.6938642438349008 Loss G :  0.6963882312205908 Epsilon :  1.688324470179252 ROC_SCORE:  0.6234691672447428\n",
      "Step :  11090 Loss SD :  0.693150945760689 Loss G :  0.6958857702391381 Epsilon :  1.6890924701792513 ROC_SCORE:  0.6238535097526295\n",
      "Step :  11100 Loss SD :  0.6930731600592168 Loss G :  0.6956044678415758 Epsilon :  1.6898604701792508 ROC_SCORE:  0.625013444587086\n",
      "Step :  11110 Loss SD :  0.6930802178293874 Loss G :  0.6953683671790724 Epsilon :  1.6906284701792502 ROC_SCORE:  0.6212311985467018\n",
      "Step :  11120 Loss SD :  0.6931489678152669 Loss G :  0.6950505080080642 Epsilon :  1.6913964701792497 ROC_SCORE:  0.6245486812463552\n",
      "Step :  11130 Loss SD :  0.6933262396732052 Loss G :  0.6950431343769264 Epsilon :  1.6921644701792493 ROC_SCORE:  0.6236023796672453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step :  11140 Loss SD :  0.6930322540593941 Loss G :  0.6950213064196671 Epsilon :  1.6929324701792487 ROC_SCORE:  0.6223911333811583\n",
      "Step :  11150 Loss SD :  0.6934966171272967 Loss G :  0.6953664402835693 Epsilon :  1.6937004701792482 ROC_SCORE:  0.6195260795386706\n",
      "Step :  11160 Loss SD :  0.6926932336949556 Loss G :  0.6952371759995659 Epsilon :  1.6944684701792476 ROC_SCORE:  0.6188753121857791\n",
      "Step :  11170 Loss SD :  0.6935266657188879 Loss G :  0.6955510564736032 Epsilon :  1.695236470179247 ROC_SCORE:  0.6141635394639335\n",
      "Step :  11180 Loss SD :  0.6935597640028175 Loss G :  0.6953120404089133 Epsilon :  1.6960044701792467 ROC_SCORE:  0.619326260904917\n",
      "Step :  11190 Loss SD :  0.6932209293416083 Loss G :  0.6954271212775158 Epsilon :  1.6967724701792462 ROC_SCORE:  0.6185131717483094\n",
      "Step :  11200 Loss SD :  0.6928827925227774 Loss G :  0.6952955118312482 Epsilon :  1.6975404701792456 ROC_SCORE:  0.6253380881945176\n",
      "Step :  11210 Loss SD :  0.6930363287724608 Loss G :  0.6949396624024351 Epsilon :  1.698308470179245 ROC_SCORE:  0.6225756572552912\n",
      "Step :  11220 Loss SD :  0.69367992258918 Loss G :  0.6952675757007926 Epsilon :  1.6990764701792445 ROC_SCORE:  0.6233956537226952\n",
      "Step :  11230 Loss SD :  0.6929228512537958 Loss G :  0.6949477774609699 Epsilon :  1.699844470179244 ROC_SCORE:  0.6268892728476574\n",
      "Step :  11240 Loss SD :  0.6931958149716226 Loss G :  0.6946646151465005 Epsilon :  1.7006124701792436 ROC_SCORE:  0.6226866676073766\n",
      "Step :  11250 Loss SD :  0.693008921574185 Loss G :  0.6942449108463167 Epsilon :  1.701380470179243 ROC_SCORE:  0.6259138618873339\n",
      "Step :  11260 Loss SD :  0.6931475785766459 Loss G :  0.6940381541977757 Epsilon :  1.7021484701792424 ROC_SCORE:  0.6266381427622731\n",
      "Step :  11270 Loss SD :  0.6932540385325003 Loss G :  0.6942999556147599 Epsilon :  1.7029164701792419 ROC_SCORE:  0.623144523637311\n",
      "Step :  11280 Loss SD :  0.6931477637142849 Loss G :  0.6942269260173516 Epsilon :  1.7036844701792413 ROC_SCORE:  0.6243848793046114\n",
      "Step :  11290 Loss SD :  0.6932368450635862 Loss G :  0.6938435299285196 Epsilon :  1.704452470179241 ROC_SCORE:  0.6210841715026065\n",
      "Step :  11300 Loss SD :  0.6931708812235552 Loss G :  0.693398090589173 Epsilon :  1.7052204701792404 ROC_SCORE:  0.6162613884286756\n",
      "Step :  11310 Loss SD :  0.6930417189557878 Loss G :  0.6935884722864567 Epsilon :  1.7059884701792398 ROC_SCORE:  0.6266825469031072\n",
      "Step :  11320 Loss SD :  0.6931040019050188 Loss G :  0.6938490503203177 Epsilon :  1.7067564701792393 ROC_SCORE:  0.62624689294359\n",
      "Step :  11330 Loss SD :  0.6932908104625246 Loss G :  0.6942940397941101 Epsilon :  1.7075244701792387 ROC_SCORE:  0.619348462975334\n",
      "Step :  11340 Loss SD :  0.6930465999518001 Loss G :  0.6947910513682127 Epsilon :  1.7082924701792381 ROC_SCORE:  0.630109559816818\n",
      "Step :  11350 Loss SD :  0.6933951947336991 Loss G :  0.6951177588151005 Epsilon :  1.7090604701792378 ROC_SCORE:  0.6284695668820104\n",
      "Step :  11360 Loss SD :  0.6931498901520574 Loss G :  0.6954976504130723 Epsilon :  1.7098284701792372 ROC_SCORE:  0.6190238193679022\n",
      "Step :  11370 Loss SD :  0.6933390854700109 Loss G :  0.6951572900460269 Epsilon :  1.7105964701792367 ROC_SCORE:  0.6239201159638806\n",
      "Step :  11380 Loss SD :  0.6932703321141536 Loss G :  0.6950767819973175 Epsilon :  1.711364470179236 ROC_SCORE:  0.6280561149929101\n",
      "Step :  11390 Loss SD :  0.6934078564091382 Loss G :  0.69521522450799 Epsilon :  1.7121324701792355 ROC_SCORE:  0.6263357012252582\n",
      "Step :  11400 Loss SD :  0.6930853905600709 Loss G :  0.6951891812535026 Epsilon :  1.7129004701792352 ROC_SCORE:  0.6164972237544392\n",
      "Step :  11410 Loss SD :  0.6933443250912443 Loss G :  0.695227729855134 Epsilon :  1.7136684701792346 ROC_SCORE:  0.6254713006170202\n",
      "Step :  11420 Loss SD :  0.6932070153618612 Loss G :  0.6949977489325767 Epsilon :  1.714436470179234 ROC_SCORE:  0.6194150691865853\n",
      "Step :  11430 Loss SD :  0.6930607779499617 Loss G :  0.6945425127641641 Epsilon :  1.7152044701792335 ROC_SCORE:  0.6158035323987413\n",
      "Step :  11440 Loss SD :  0.6930936840505334 Loss G :  0.6949082115603761 Epsilon :  1.715972470179233 ROC_SCORE:  0.6250356466575029\n",
      "Step :  11450 Loss SD :  0.6932557192079991 Loss G :  0.6948660599395925 Epsilon :  1.7167404701792324 ROC_SCORE:  0.623824400371416\n",
      "Step :  11460 Loss SD :  0.6933617741606062 Loss G :  0.6948629537983099 Epsilon :  1.717508470179232 ROC_SCORE:  0.6221552980553946\n",
      "Step :  11470 Loss SD :  0.6930436888812148 Loss G :  0.6948119885067289 Epsilon :  1.7182764701792315 ROC_SCORE:  0.6237647014709613\n",
      "Step :  11480 Loss SD :  0.6932591121486821 Loss G :  0.6943113815294009 Epsilon :  1.719044470179231 ROC_SCORE:  0.6253089788133044\n",
      "Step :  11490 Loss SD :  0.6933107558606091 Loss G :  0.6939975132910169 Epsilon :  1.7198124701792303 ROC_SCORE:  0.6211354829542372\n",
      "Step :  11500 Loss SD :  0.6932456124731647 Loss G :  0.693657241192801 Epsilon :  1.7205804701792298 ROC_SCORE:  0.6237799962305818\n",
      "Step :  11510 Loss SD :  0.6931471807525369 Loss G :  0.6931648734564522 Epsilon :  1.7213484701792294 ROC_SCORE:  0.6169772818547906\n",
      "Step :  11520 Loss SD :  0.6932899934733661 Loss G :  0.6925829454566246 Epsilon :  1.7221164701792289 ROC_SCORE:  0.6258028515352485\n",
      "Step :  11530 Loss SD :  0.6931881510395401 Loss G :  0.6924967964855488 Epsilon :  1.7228844701792283 ROC_SCORE:  0.6194525660166229\n",
      "Step :  11540 Loss SD :  0.6930534341329814 Loss G :  0.6927165141692684 Epsilon :  1.7236524701792277 ROC_SCORE:  0.621955479421641\n",
      "Step :  11550 Loss SD :  0.6931302077469654 Loss G :  0.6926222276340359 Epsilon :  1.7244204701792272 ROC_SCORE:  0.6194510858785951\n",
      "Step :  11560 Loss SD :  0.6930513299176395 Loss G :  0.6927529440604702 Epsilon :  1.7251884701792266 ROC_SCORE:  0.6221844074366082\n",
      "Step :  11570 Loss SD :  0.6931661242978612 Loss G :  0.6928396830791993 Epsilon :  1.7259564701792263 ROC_SCORE:  0.6216752399550433\n",
      "Step :  11580 Loss SD :  0.6931438647762118 Loss G :  0.6930533726426579 Epsilon :  1.7267244701792257 ROC_SCORE:  0.6264980230289742\n",
      "Step :  11590 Loss SD :  0.6931245080294944 Loss G :  0.6927878536858526 Epsilon :  1.7274924701792251 ROC_SCORE:  0.6200352470202354\n",
      "Step :  11600 Loss SD :  0.6931509540988539 Loss G :  0.6930922317315814 Epsilon :  1.7282604701792246 ROC_SCORE:  0.6196439972015524\n",
      "Step :  11610 Loss SD :  0.6931480158118548 Loss G :  0.6931494363154129 Epsilon :  1.729028470179224 ROC_SCORE:  0.6275316527517246\n",
      "Step :  11620 Loss SD :  0.6931572772835151 Loss G :  0.6930407536414048 Epsilon :  1.7297964701792237 ROC_SCORE:  0.6263357012252582\n",
      "Step :  11630 Loss SD :  0.6931573538663238 Loss G :  0.6934858501386308 Epsilon :  1.730564470179223 ROC_SCORE:  0.624747019742081\n",
      "Step :  11640 Loss SD :  0.6931473920286002 Loss G :  0.6938084746363818 Epsilon :  1.7313324701792225 ROC_SCORE:  0.6322809223036079\n",
      "Step :  11650 Loss SD :  0.6932737282460902 Loss G :  0.6941640675556392 Epsilon :  1.732100470179222 ROC_SCORE:  0.6228489894110926\n",
      "Step :  11660 Loss SD :  0.6931335004223669 Loss G :  0.6935900533709783 Epsilon :  1.7328684701792214 ROC_SCORE:  0.6233581568926575\n",
      "Step :  11670 Loss SD :  0.6932223890273482 Loss G :  0.6935530349999568 Epsilon :  1.7336364701792208 ROC_SCORE:  0.6201684594427379\n",
      "Step :  11680 Loss SD :  0.69297273223934 Loss G :  0.6940944864303628 Epsilon :  1.7344044701792205 ROC_SCORE:  0.6222135168178217\n",
      "Step :  11690 Loss SD :  0.6931153729956929 Loss G :  0.6941767644659776 Epsilon :  1.73517247017922 ROC_SCORE:  0.629938850564278\n",
      "Step :  11700 Loss SD :  0.6930157214200415 Loss G :  0.6938654652920282 Epsilon :  1.7359404701792194 ROC_SCORE:  0.6186172747895985\n",
      "Step :  11710 Loss SD :  0.6928854997722066 Loss G :  0.6943656855715751 Epsilon :  1.7367084701792188 ROC_SCORE:  0.6103452767315395\n",
      "Step :  11720 Loss SD :  0.6931724700862777 Loss G :  0.693938121606696 Epsilon :  1.7374764701792182 ROC_SCORE:  0.6305674158467525\n",
      "Step :  11730 Loss SD :  0.6931257334771569 Loss G :  0.6938445202104361 Epsilon :  1.738244470179218 ROC_SCORE:  0.6198285210756853\n",
      "Step :  11740 Loss SD :  0.6933289403065256 Loss G :  0.6938616584508994 Epsilon :  1.7390124701792173 ROC_SCORE:  0.6318605631037113\n",
      "Step :  11750 Loss SD :  0.6933108148678677 Loss G :  0.694178124148821 Epsilon :  1.7397804701792168 ROC_SCORE:  0.6207289383759333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step :  11760 Loss SD :  0.6930653010982258 Loss G :  0.6944782164514186 Epsilon :  1.7405484701792162 ROC_SCORE:  0.616105973935756\n",
      "Step :  11770 Loss SD :  0.6933835362849927 Loss G :  0.6943990903792949 Epsilon :  1.7413164701792156 ROC_SCORE:  0.6237716087817576\n",
      "Step :  11780 Loss SD :  0.6934822607981586 Loss G :  0.6941085515032489 Epsilon :  1.742084470179215 ROC_SCORE:  0.6268157593256096\n",
      "Step :  11790 Loss SD :  0.6930561320073532 Loss G :  0.6941323256248727 Epsilon :  1.7428524701792147 ROC_SCORE:  0.612287711203362\n",
      "Step :  11800 Loss SD :  0.6929984569525689 Loss G :  0.6939542208905872 Epsilon :  1.7436204701792142 ROC_SCORE:  0.625013444587086\n",
      "Step :  11810 Loss SD :  0.6927296547643924 Loss G :  0.694847541460011 Epsilon :  1.7443884701792136 ROC_SCORE:  0.6192665620044622\n",
      "Step :  11820 Loss SD :  0.6931963099807833 Loss G :  0.6946848577802344 Epsilon :  1.745156470179213 ROC_SCORE:  0.6157369261874899\n",
      "Step :  11830 Loss SD :  0.6931479655237467 Loss G :  0.6943939453790332 Epsilon :  1.7459244701792125 ROC_SCORE:  0.6263648106064718\n",
      "Step :  11840 Loss SD :  0.6932793197617607 Loss G :  0.6945458151336867 Epsilon :  1.7466924701792121 ROC_SCORE:  0.6233068454410269\n",
      "Step :  11850 Loss SD :  0.6932621353723569 Loss G :  0.6943627711018276 Epsilon :  1.7474604701792116 ROC_SCORE:  0.6242378522605162\n",
      "Step :  11860 Loss SD :  0.6933879667179013 Loss G :  0.6942370973762791 Epsilon :  1.748228470179211 ROC_SCORE:  0.6233137527518233\n",
      "Step :  11870 Loss SD :  0.6935796663679049 Loss G :  0.6945243927918683 Epsilon :  1.7489964701792104 ROC_SCORE:  0.6247914238829152\n",
      "Step :  11880 Loss SD :  0.6930745338066111 Loss G :  0.694315189523446 Epsilon :  1.7497644701792099 ROC_SCORE:  0.6263648106064718\n",
      "Step :  11890 Loss SD :  0.6933828934111228 Loss G :  0.6943807695860728 Epsilon :  1.7505324701792093 ROC_SCORE:  0.6250425539682994\n",
      "Step :  11900 Loss SD :  0.6930621578623283 Loss G :  0.6945183706969612 Epsilon :  1.751300470179209 ROC_SCORE:  0.6272139164550892\n",
      "Step :  11910 Loss SD :  0.6931235738960546 Loss G :  0.6938884922807812 Epsilon :  1.7520684701792084 ROC_SCORE:  0.6302940836909511\n",
      "Step :  11920 Loss SD :  0.6931601448443483 Loss G :  0.6932324617611572 Epsilon :  1.7528364701792079 ROC_SCORE:  0.6218444690695557\n",
      "Step :  11930 Loss SD :  0.6931428659470208 Loss G :  0.6931891015163286 Epsilon :  1.7536044701792073 ROC_SCORE:  0.6248580300941664\n",
      "Step :  11940 Loss SD :  0.693163294096662 Loss G :  0.6936573387449262 Epsilon :  1.7543724701792067 ROC_SCORE:  0.6243557699233979\n",
      "Step :  11950 Loss SD :  0.6932336467301177 Loss G :  0.693688287258365 Epsilon :  1.7551404701792064 ROC_SCORE:  0.6265493344806048\n",
      "Step :  11960 Loss SD :  0.6931961984170152 Loss G :  0.6934502270894752 Epsilon :  1.7559084701792058 ROC_SCORE:  0.628196234726209\n",
      "Step :  11970 Loss SD :  0.6930807207153592 Loss G :  0.6936025123269102 Epsilon :  1.7566764701792053 ROC_SCORE:  0.630538306465539\n",
      "Step :  11980 Loss SD :  0.6931078976401219 Loss G :  0.6935716723919366 Epsilon :  1.7574444701792047 ROC_SCORE:  0.6248580300941664\n",
      "Step :  11990 Loss SD :  0.6931667056176909 Loss G :  0.6937469735983566 Epsilon :  1.7582124701792041 ROC_SCORE:  0.6123918142446511\n",
      "Step :  12000 Loss SD :  0.6930640539421801 Loss G :  0.6940472235774571 Epsilon :  1.7589804701792036 ROC_SCORE:  0.6204195895281222\n",
      "Step :  12010 Loss SD :  0.6931139017736625 Loss G :  0.694229950862604 Epsilon :  1.7597484701792032 ROC_SCORE:  0.6302274774797\n",
      "Step :  12020 Loss SD :  0.6930920564577117 Loss G :  0.6935727005959194 Epsilon :  1.7605164701792027 ROC_SCORE:  0.6265937386214389\n"
     ]
    }
   ],
   "source": [
    "# Initialise hyperparams and do TRAINING\n",
    "Hyperparams = collections.namedtuple(\n",
    "        'Hyperarams',\n",
    "        'batch_size num_teacher_iters num_student_iters num_moments lap_scale class_ratios lr')\n",
    "Hyperparams.__new__.__defaults__ = (None, None, None, None, None, None, None)\n",
    "\n",
    "model = pate_gan.PATE_GAN(LEAKY,logfile, input_dim, z_dim, NUM_TEACHERS, TARGET_EPSILON, TARGET_DELTA, conditional)\n",
    "model.train(train_x, train_y, test_x, test_y, data_columns, scaler, Hyperparams(batch_size=BATCH_SIZE, num_teacher_iters=TEACHER_ITER,\n",
    "                                              num_student_iters=STUDENT_ITER, num_moments=NUM_MOMENTS,\n",
    "                                              lap_scale=LAP_SCALE, class_ratios=class_ratios, lr=LEARNING_RATE))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 342,
     "status": "ok",
     "timestamp": 1623409778557,
     "user": {
      "displayName": "Tee Yee Yang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgKFrQtw-OyvubwOe5xvtv9JOTRkaAVybEHvmq9ag=s64",
      "userId": "07106232567566268752"
     },
     "user_tz": -480
    },
    "id": "src6RqhrGOge",
    "outputId": "c77277ee-36ed-44af-c7dc-911652753b33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=14, out_features=6, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=6, out_features=1, bias=True)\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=14, out_features=6, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=6, out_features=1, bias=True)\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=6, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=6, out_features=13, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Optional: Look at model architectures\n",
    "print(model.student_disc)\n",
    "print(model.teacher_disc[0])\n",
    "print(model.generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEdrKNFmOf4R"
   },
   "source": [
    "## Generate synthetic data using trained model, then save in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 433,
     "status": "ok",
     "timestamp": 1623410052478,
     "user": {
      "displayName": "Tee Yee Yang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgKFrQtw-OyvubwOe5xvtv9JOTRkaAVybEHvmq9ag=s64",
      "userId": "07106232567566268752"
     },
     "user_tz": -480
    },
    "id": "nXRyRloMOf4S"
   },
   "outputs": [],
   "source": [
    "# Helper functions for saving the synthetic data...\n",
    "def update_array(indexes, cols = None):\n",
    "    if cols: colsize = cols\n",
    "    else: colsize = indexes.max() +1\n",
    "    b = np.zeros((indexes.size, colsize))\n",
    "    b[np.arange(indexes.size), indexes] = 1\n",
    "    return b\n",
    "\n",
    "def save_marketing():\n",
    "    # Some fancy indexing to get the actual synthetic data..\n",
    "    accepted = np.argmax(syn_save[:,16:21], axis=1)\n",
    "    education = np.argmax(syn_save[:, 22:27], axis=1)\n",
    "    marital = np.argmax(syn_save[:, 27:34], axis=1)\n",
    "    country = np.argmax(syn_save[:, 34:], axis=1)\n",
    "\n",
    "    syn_save[:,16:21] = update_array(accepted, cols=5)\n",
    "    syn_save[:, 22:27] = update_array(education, cols=5)\n",
    "    syn_save[:, 27:34] = update_array(marital, cols=7)\n",
    "    syn_save[:, 34:] = update_array(country, cols=8)\n",
    "\n",
    "    df1 = pd.DataFrame(syn_save, columns = df.columns.drop(TARGET_VARIABLE))\n",
    "    df2 = pd.DataFrame(syn_y, columns = [TARGET_VARIABLE])\n",
    "    df_save = pd.concat([df1,df2], axis =1)\n",
    "    df_save.to_csv(f'synthetic_{MODEL_NAME}_{DATASET_NAME}_{TARGET_EPSILON}.csv')\n",
    "\n",
    "def save_churn():\n",
    "    geography = np.argmax(syn_save[:,8:11], axis=1)\n",
    "    gender = np.argmax(syn_save[:,11:], axis=1)\n",
    "    \n",
    "    syn_save[:,8:11] = update_array(geography, cols=3)\n",
    "    syn_save[:, 11:] = update_array(gender, cols=2)\n",
    "    syn_save[:,4] = np.round(syn_save[:,4]) # num products\n",
    "    syn_save[:,5] = np.round(np.clip(syn_save[:,5],0,1)) # Has card\n",
    "    syn_save[:,6] = np.round(np.clip(syn_save[:,6],0,1)) # Is active\n",
    "\n",
    "\n",
    "    df1 = pd.DataFrame(syn_save, columns = df.columns.drop(TARGET_VARIABLE))\n",
    "    df2 = pd.DataFrame(syn_y, columns = [TARGET_VARIABLE])\n",
    "    df_save = pd.concat([df1,df2], axis =1)\n",
    "    df_save.to_csv(f'synthetic_{MODEL_NAME}_{DATASET_NAME}_{TARGET_EPSILON}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 288,
     "status": "ok",
     "timestamp": 1623410007008,
     "user": {
      "displayName": "Tee Yee Yang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgKFrQtw-OyvubwOe5xvtv9JOTRkaAVybEHvmq9ag=s64",
      "userId": "07106232567566268752"
     },
     "user_tz": -480
    },
    "id": "odo2I7tExEKk",
    "outputId": "cd93e659-fa10-46ad-ed6b-963093d214cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.clip(syn_save[:,5],0,1)).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1623410055300,
     "user": {
      "displayName": "Tee Yee Yang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgKFrQtw-OyvubwOe5xvtv9JOTRkaAVybEHvmq9ag=s64",
      "userId": "07106232567566268752"
     },
     "user_tz": -480
    },
    "id": "tj7RmPumf7Jq"
   },
   "outputs": [],
   "source": [
    "df_save = save_churn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "executionInfo": {
     "elapsed": 320,
     "status": "ok",
     "timestamp": 1623410229662,
     "user": {
      "displayName": "Tee Yee Yang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgKFrQtw-OyvubwOe5xvtv9JOTRkaAVybEHvmq9ag=s64",
      "userId": "07106232567566268752"
     },
     "user_tz": -480
    },
    "id": "XaJ7XstKxIJ_",
    "outputId": "22501de3-3fdb-4d68-f37e-1c0030805a69"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>569.189810</td>\n",
       "      <td>40.029415</td>\n",
       "      <td>6.717890</td>\n",
       "      <td>89681.936477</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130466.340459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570.501744</td>\n",
       "      <td>33.474992</td>\n",
       "      <td>8.674211</td>\n",
       "      <td>110469.707352</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71928.116744</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>419.490332</td>\n",
       "      <td>51.890009</td>\n",
       "      <td>18.356562</td>\n",
       "      <td>200372.129774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>264136.140441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>542.538826</td>\n",
       "      <td>42.563155</td>\n",
       "      <td>8.338049</td>\n",
       "      <td>117159.416072</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>155246.459858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>577.241597</td>\n",
       "      <td>42.062559</td>\n",
       "      <td>10.930599</td>\n",
       "      <td>89837.667759</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>137180.080401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7495</th>\n",
       "      <td>594.765712</td>\n",
       "      <td>36.708907</td>\n",
       "      <td>6.737492</td>\n",
       "      <td>84549.090124</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88441.888815</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7496</th>\n",
       "      <td>533.535706</td>\n",
       "      <td>43.156655</td>\n",
       "      <td>10.432683</td>\n",
       "      <td>119125.835245</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>163115.984498</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7497</th>\n",
       "      <td>563.589866</td>\n",
       "      <td>39.947245</td>\n",
       "      <td>6.797705</td>\n",
       "      <td>91301.876516</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>132893.947639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7498</th>\n",
       "      <td>586.354935</td>\n",
       "      <td>38.140655</td>\n",
       "      <td>8.512222</td>\n",
       "      <td>92579.078628</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102529.715082</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499</th>\n",
       "      <td>588.454970</td>\n",
       "      <td>35.886111</td>\n",
       "      <td>6.749212</td>\n",
       "      <td>81964.722904</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87343.176253</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7500 rows  14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore        Age     Tenure  ...  Gender_Female  Gender_Male  Exited\n",
       "0      569.189810  40.029415   6.717890  ...            0.0          1.0     0.0\n",
       "1      570.501744  33.474992   8.674211  ...            0.0          1.0     0.0\n",
       "2      419.490332  51.890009  18.356562  ...            0.0          1.0     1.0\n",
       "3      542.538826  42.563155   8.338049  ...            0.0          1.0     0.0\n",
       "4      577.241597  42.062559  10.930599  ...            0.0          1.0     0.0\n",
       "...           ...        ...        ...  ...            ...          ...     ...\n",
       "7495   594.765712  36.708907   6.737492  ...            0.0          1.0     0.0\n",
       "7496   533.535706  43.156655  10.432683  ...            0.0          1.0     0.0\n",
       "7497   563.589866  39.947245   6.797705  ...            0.0          1.0     0.0\n",
       "7498   586.354935  38.140655   8.512222  ...            0.0          1.0     0.0\n",
       "7499   588.454970  35.886111   6.749212  ...            0.0          1.0     0.0\n",
       "\n",
       "[7500 rows x 14 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 301,
     "status": "ok",
     "timestamp": 1623409809129,
     "user": {
      "displayName": "Tee Yee Yang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgKFrQtw-OyvubwOe5xvtv9JOTRkaAVybEHvmq9ag=s64",
      "userId": "07106232567566268752"
     },
     "user_tz": -480
    },
    "id": "RH3-0pxZhlDt",
    "outputId": "70684264-8972-4f90-eb9d-c08154ef4934"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
       "       'IsActiveMember', 'EstimatedSalary', 'Exited', 'Geography_France',\n",
       "       'Geography_Germany', 'Geography_Spain', 'Gender_Female', 'Gender_Male'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 340,
     "status": "ok",
     "timestamp": 1623410367144,
     "user": {
      "displayName": "Tee Yee Yang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgKFrQtw-OyvubwOe5xvtv9JOTRkaAVybEHvmq9ag=s64",
      "userId": "07106232567566268752"
     },
     "user_tz": -480
    },
    "id": "ZnbEtOPNhGB-",
    "outputId": "7731c588-d48b-4b06-aaef-77e965738c5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    5304\n",
      "0    2196\n",
      "Name: HasCrCard, dtype: int64\n",
      "0.0    5547\n",
      "1.0    1953\n",
      "Name: HasCrCard, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "COL = 5\n",
    "print(df_train.iloc[:,COL].value_counts())\n",
    "print(df_save.iloc[:,COL].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 757,
     "status": "ok",
     "timestamp": 1623410372520,
     "user": {
      "displayName": "Tee Yee Yang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgKFrQtw-OyvubwOe5xvtv9JOTRkaAVybEHvmq9ag=s64",
      "userId": "07106232567566268752"
     },
     "user_tz": -480
    },
    "id": "C9sUEiE6gUTQ",
    "outputId": "cc808a24-d7b5-4264-f70e-763297cd38d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe18045f450>"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.histplot(syn_x[:,COL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1623410372521,
     "user": {
      "displayName": "Tee Yee Yang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgKFrQtw-OyvubwOe5xvtv9JOTRkaAVybEHvmq9ag=s64",
      "userId": "07106232567566268752"
     },
     "user_tz": -480
    },
    "id": "7lw2lCpHyNYx",
    "outputId": "1b5be044-6569-4c93-9250-875c9bcbe36a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe18022b750>"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAD4CAYAAAAdIcpQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARWUlEQVR4nO3dfYxldX3H8fdHVtColUXWLS67LoZtLbYpmhUU/aNCy1NbF60ixujWYNek2GhsbLH+QaqSatNUa2PRDRBXYwW0EtBScQXUGMvD4gMISBlRwq7ArixirRWz+u0f8xu87s7M7y6de2dm5/1Kbu453/M7537nzCwfzsOcSVUhSdJsHjffDUiSFj7DQpLUZVhIkroMC0lSl2EhSepaNt8NjMLhhx9ea9eune82JGlRufnmm39QVSumW3ZAhsXatWvZtm3bfLchSYtKkntmWuZpKElSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnzYNXqNSSZ89eq1WtG0u8B+bgPSVrovr/9Xl714a/O+XYvfeMJc75N8MhCkjQEw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV0jDYsk30tya5JvJNnWaocl2Zrkrva+vNWT5ANJJpLckuR5A9vZ2MbflWTjKHuWJO1rHEcWL6mqY6tqfZs/F7imqtYB17R5gNOAde21CbgAJsMFOA84HjgOOG8qYCRJ4zEfp6E2AFva9BbgjIH6R2vS9cChSY4ATgG2VtXuqnoI2AqcOu6mJWkpG3VYFPD5JDcn2dRqK6vqvjZ9P7CyTa8C7h1Yd3urzVSXJI3JqB/38eKq2pHk6cDWJN8eXFhVlaTm4oNaGG0CWLNmNM9GkaSlaqRHFlW1o73vBC5n8prDA+30Eu19Zxu+A1g9sPqRrTZTfe/P2lxV66tq/YoVK+b6S5GkJW1kYZHkSUmeMjUNnAx8C7gSmLqjaSNwRZu+EnhduyvqBcDD7XTV1cDJSZa3C9snt5okaUxGeRpqJXB5kqnP+deq+lySm4DLkpwN3AOc2cZfBZwOTAA/AV4PUFW7k7wLuKmNe2dV7R5h35KkvYwsLKrqbuB3p6k/CJw0Tb2Ac2bY1sXAxXPdoyRpOP4GtySpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVLXyMMiyUFJvp7ks23+qCQ3JJlIcmmSg1v9kDY/0ZavHdjG21v9ziSnjLpnSdKvGseRxZuBOwbm3wu8r6qOBh4Czm71s4GHWv19bRxJjgHOAp4DnAr8S5KDxtC3JKkZaVgkORL4Q+DCNh/gROBTbcgW4Iw2vaHN05af1MZvAC6pqkeq6rvABHDcKPuWJP2qUR9ZvB/4K+AXbf5pwA+rak+b3w6satOrgHsB2vKH2/hH69OsI0kag5GFRZI/AnZW1c2j+oy9Pm9Tkm1Jtu3atWscHylJS8YojyxeBLw0yfeAS5g8/fRPwKFJlrUxRwI72vQOYDVAW/5U4MHB+jTrPKqqNlfV+qpav2LFirn/aiRpCRtZWFTV26vqyKpay+QF6mur6jXAdcAr2rCNwBVt+so2T1t+bVVVq5/V7pY6ClgH3DiqviVJ+1rWHzLn/hq4JMm7ga8DF7X6RcDHkkwAu5kMGKrqtiSXAbcDe4Bzqurn429bkpausYRFVX0R+GKbvptp7maqqp8Cr5xh/fOB80fXoSRpNv4GtySpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVLXUGGR5EXD1CRJB6Zhjyz+ecjao5I8IcmNSb6Z5LYkf9vqRyW5IclEkkuTHNzqh7T5ibZ87cC23t7qdyY5ZcieJUlzZNlsC5O8EDgBWJHkrQOLfg04qLPtR4ATq+rHSR4PfCXJfwBvBd5XVZck+RBwNnBBe3+oqo5OchbwXuBVSY4BzgKeAzwD+EKS36iqn+/3VytJekx6RxYHA09mMlSeMvD6EfCK2VasST9us49vrwJOBD7V6luAM9r0hjZPW35SkrT6JVX1SFV9F5gAjhvqq5MkzYlZjyyq6kvAl5J8pKru2d+NJzkIuBk4Gvgg8B3gh1W1pw3ZDqxq06uAe9vn7knyMPC0Vr9+YLOD6wx+1iZgE8CaNWv2t1VJ0ixmDYsBhyTZDKwdXKeqTpxtpXaq6NgkhwKXA89+jH12VdVmYDPA+vXra1SfI0lL0bBh8UngQ8CFwH5fK6iqHya5DnghcGiSZe3o4khgRxu2A1gNbE+yDHgq8OBAfcrgOpKkMRj2bqg9VXVBVd1YVTdPvWZbIcmKdkRBkicCfwDcAVzHL693bASuaNNXtnna8murqlr9rHa31FHAOuDGIfuWJM2BYY8sPpPkz5k8lfTIVLGqds+yzhHAlnbd4nHAZVX12SS3A5ckeTfwdeCiNv4i4GNJJoDdTN4BRVXdluQy4HZgD3COd0JJ0ngNGxZT/8f/toFaAc+aaYWqugV47jT1u5nmbqaq+inwyhm2dT5w/pC9SpLm2FBhUVVHjboRSdLCNVRYJHnddPWq+ujctiNJWoiGPQ31/IHpJwAnAV8DDAtJWgKGPQ31F4Pz7S6nS0bSkSRpwXmsjyj/H8DrGJK0RAx7zeIzTN79BJMPEPwt4LJRNSVJWliGvWbxDwPTe4B7qmr7CPqRJC1AQ52Gag8U/DaTT5xdDvxslE1JkhaWYf9S3plMPmLjlcCZwA1JZn1EuSTpwDHsaah3AM+vqp0w+dwn4Av88u9SSJIOYMPeDfW4qaBoHtyPdSVJi9ywRxafS3I18Ik2/yrgqtG0JElaaHp/g/toYGVVvS3Jy4EXt0X/CXx81M1JkhaG3pHF+4G3A1TVp4FPAyT5nbbsj0fanSRpQehdd1hZVbfuXWy1tSPpSJK04PTC4tBZlj1xLhuRJC1cvbDYluTP9i4meQMw659VlSQdOHrXLN4CXJ7kNfwyHNYDBwMvG2VjkqSFY9awqKoHgBOSvAT47Vb+96q6duSdSZIWjGH/nsV1wHUj7kWStED5W9iSpC7DQpLUZVhIkroMC0lSl2EhSeoyLKaxavUakszpa9XqNfP9ZUnSYzbsI8qXlO9vv5dXffirc7rNS994wpxuT5LGySMLSVKXYSFJ6jIsJEldIwuLJKuTXJfk9iS3JXlzqx+WZGuSu9r78lZPkg8kmUhyS5LnDWxrYxt/V5KNo+pZkjS9UR5Z7AH+sqqOAV4AnJPkGOBc4JqqWgdc0+YBTgPWtdcm4AKYDBfgPOB44DjgvKmAkSSNx8jCoqruq6qvten/Bu4AVgEbgC1t2BbgjDa9AfhoTboeODTJEcApwNaq2l1VDwFbgVNH1bckaV9juWaRZC3wXOAGJv9U631t0f3Ayja9Crh3YLXtrTZTfe/P2JRkW5Jtu3btmtP+JWmpG3lYJHky8G/AW6rqR4PLqqqAmovPqarNVbW+qtavWLFiLjYpSWpGGhZJHs9kUHy8qj7dyg+000u0952tvgNYPbD6ka02U12SNCajvBsqwEXAHVX1jwOLrgSm7mjaCFwxUH9duyvqBcDD7XTV1cDJSZa3C9snt5okaUxG+biPFwGvBW5N8o1W+xvgPcBlSc4G7gHObMuuAk4HJoCfAK8HqKrdSd4F3NTGvbOqdo+wb0nSXkYWFlX1FSAzLD5pmvEFnDPDti4GLp677iRJ+8Pf4JYkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqGllYJLk4yc4k3xqoHZZka5K72vvyVk+SDySZSHJLkucNrLOxjb8rycZR9StJmtkojyw+Apy6V+1c4JqqWgdc0+YBTgPWtdcm4AKYDBfgPOB44DjgvKmAkSSNz8jCoqq+DOzeq7wB2NKmtwBnDNQ/WpOuBw5NcgRwCrC1qnZX1UPAVvYNIEnSiI37msXKqrqvTd8PrGzTq4B7B8Ztb7WZ6vtIsinJtiTbdu3aNbddS9ISN28XuKuqgJrD7W2uqvVVtX7FihVztVlJEuMPiwfa6SXa+85W3wGsHhh3ZKvNVJckjdG4w+JKYOqOpo3AFQP117W7ol4APNxOV10NnJxkebuwfXKrSZLGaNmoNpzkE8DvAYcn2c7kXU3vAS5LcjZwD3BmG34VcDowAfwEeD1AVe1O8i7gpjbunVW190VzSdKIjSwsqurVMyw6aZqxBZwzw3YuBi6ew9YkSfvJ3+CWJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6lo0YZHk1CR3JplIcu589yNJS8miCIskBwEfBE4DjgFeneSY+e1KkpaORREWwHHARFXdXVU/Ay4BNsxzT5K0ZKSq5ruHriSvAE6tqje0+dcCx1fVmwbGbAI2tdnfBO4cUTuHAz8Y0bYXK/fJ9Nwv+3Kf7Gsh7ZNnVtWK6RYsG3cno1JVm4HNo/6cJNuqav2oP2cxcZ9Mz/2yL/fJvhbLPlksp6F2AKsH5o9sNUnSGCyWsLgJWJfkqCQHA2cBV85zT5K0ZCyK01BVtSfJm4CrgYOAi6vqtnlqZ+SnuhYh98n03C/7cp/sa1Hsk0VxgVuSNL8Wy2koSdI8MiwkSV2GRUeSVya5Lckvksx4e1uS7yW5Nck3kmwbZ4/jth/7ZEk9oiXJYUm2JrmrvS+fYdzP28/JN5IckDdq9L73SQ5JcmlbfkOStePvcryG2Cd/mmTXwM/GG+ajz5kYFn3fAl4OfHmIsS+pqmMXwz3T/0/dfbJEH9FyLnBNVa0Drmnz0/nf9nNybFW9dHztjceQ3/uzgYeq6mjgfcB7x9vleO3Hv4dLB342Lhxrkx2GRUdV3VFVo/pt8EVpyH2yFB/RsgHY0qa3AGfMYy/zaZjv/eC++hRwUpKMscdxW/T/HgyLuVPA55Pc3B49stStAu4dmN/eageylVV1X5u+H1g5w7gnJNmW5PokB2KgDPO9f3RMVe0BHgaeNpbu5sew/x7+JMktST6VZPU0y+fNovg9i1FL8gXg16dZ9I6qumLIzby4qnYkeTqwNcm3q2qYU1cL0hztkwPObPtlcKaqKslM96U/s/2sPAu4NsmtVfWdue5Vi85ngE9U1SNJ3sjkkdeJ89zTowwLoKp+fw62saO970xyOZOHnYs2LOZgnxyQj2iZbb8keSDJEVV1X5IjgJ0zbGPqZ+XuJF8EngscSGExzPd+asz2JMuApwIPjqe9edHdJ1U1+PVfCPz9GPoamqeh5kCSJyV5ytQ0cDKTF4GXsqX4iJYrgY1teiOwzxFYkuVJDmnThwMvAm4fW4fjMcz3fnBfvQK4tg7s3xDu7pP2PxhTXgrcMcb++qrK1ywv4GVMnl98BHgAuLrVnwFc1aafBXyzvW5j8lTNvPc+n/ukzZ8O/BeT/9d8QO+T9vU+jcm7oO4CvgAc1urrgQvb9AnAre1n5Vbg7Pnue0T7Yp/vPfBO4KVt+gnAJ4EJ4EbgWfPd8wLYJ3/X/vvxTeA64Nnz3fPgy8d9SJK6PA0lSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6/g+Pys0oW1tSpAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(train_x[:,COL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1623409813504,
     "user": {
      "displayName": "Tee Yee Yang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgKFrQtw-OyvubwOe5xvtv9JOTRkaAVybEHvmq9ag=s64",
      "userId": "07106232567566268752"
     },
     "user_tz": -480
    },
    "id": "uR6iWcoPglg8",
    "outputId": "c828ea86-4942-4fcd-8dfa-1251a55edc04"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe1d0609590>"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAY/UlEQVR4nO3dfZAc1X3u8e9jCSEbFLQSQlmk3QiHtRyHGAFrvBiuS0ZxLnAdi+RiAuUyCqVEqQrOBZJyjG/qJpVKcgtXUsHYFURUlm3hOGCMeVG4BFsRshNSGWIJ1rzJWDJGXqn0ZlmIGO5GFv7ljz7bjFYj7ezu9HRL83yqpqb7dM/sT7Mvj/qc7tOKCMzMzADeVHYBZmZWHQ4FMzPLORTMzCznUDAzs5xDwczMclPLLmAyTj/99FiwYEHZZZiZHVc2bdr0w4iY02jbcR0KCxYsYOPGjWWXYWZ2XJG07Wjb3H1kZmY5h4KZmeUcCmZmlnMomJlZzqFgZma5wkJB0kJJg3WPVyTdJGmWpHWStqTnrrS/JH1a0lZJT0s6v6jazMysscJCISJeiIhFEbEIuAB4DXgAuAVYHxF9wPq0DnA50JceK4CVRdVmZmaNtav7aAnwvYjYBiwF1qT2NcCVaXkpcFdkasBMSd1tqs/MzGjfxWvXAHen5bkRsTMt7wLmpuV5wFDda7antp11bUhaQXYkQW9vb1H1dqTh4WFqtdoR7QMDA0yfPr2Eisys3QoPBUnTgA8Cnxi9LSJC0rju8hMRq4BVAP39/b5DUAvVajVuvuNBunr68rb9Q1u4DVi8eHFpdZlZ+7TjSOFy4MmI2J3Wd0vqjoidqXtoT2rfAfTUvW5+arM26urp44yFHuM361TtGFO4lje6jgDWAsvS8jLgobr269JZSAPAgbpuJjMza4NCjxQknQK8H/iduuZbgXslLQe2AVen9keAK4CtZGcqXV9kbWZmdqRCQyEiXgVmj2rbR3Y20uh9A7ihyHrMzOzYfEWzmZnlHApmZpZzKJiZWc6hYGZmOYeCmZnlHApmZpZzKJiZWc6hYGZmOYeCmZnlHApmZpZzKJiZWc6hYGZmOYeCmZnlHApmZpZzKJiZWc6hYGZmOYeCmZnlCr3zmnW24eFharXaEe0DAwNMnz69hIrMbCwOBStMrVbj5jsepKunL2/bP7SF24DFixeXVpeZHZ1DwQrV1dPHGQvPL7sMM2uSxxTMzCxXaChIminpPknfkbRZ0kWSZklaJ2lLeu5K+0rSpyVtlfS0JP/30syszYo+UrgdeDQi3g6cC2wGbgHWR0QfsD6tA1wO9KXHCmBlwbWZmdkohYWCpNOA9wKrASLiYES8DCwF1qTd1gBXpuWlwF2RqQEzJXUXVZ+ZmR2pyCOFs4C9wOclPSXps5JOAeZGxM60zy5gblqeBwzVvX57ajuMpBWSNkrauHfv3gLLNzPrPEWGwlTgfGBlRJwHvMobXUUAREQAMZ43jYhVEdEfEf1z5sxpWbFmZlZsKGwHtkfEE2n9PrKQ2D3SLZSe96TtO4CeutfPT21mZtYmhYVCROwChiQtTE1LgOeBtcCy1LYMeCgtrwWuS2chDQAH6rqZzMysDYq+eO33gC9Jmga8CFxPFkT3SloObAOuTvs+AlwBbAVeS/uamVkbFRoKETEI9DfYtKTBvgHcUGQ9ZmZ2bL6i2czMcg4FMzPLORTMzCznUDAzs5xDwczMcg4FMzPLORTMzCznUDAzs5xDwczMcg4FMzPLORTMzCznUDAzs5xDwczMcg4FMzPLORTMzCznUDAzs5xDwczMcg4FMzPLORTMzCznUDAzs1yhoSDpJUnPSBqUtDG1zZK0TtKW9NyV2iXp05K2Snpa0vlF1mZmZkdqx5HC+yJiUUT0p/VbgPUR0QesT+sAlwN96bECWNmG2szMrE4Z3UdLgTVpeQ1wZV37XZGpATMldZdQn5lZx5pa8PsH8HVJAfxtRKwC5kbEzrR9FzA3Lc8Dhupeuz217axrQ9IKsiMJent7Cyy9WoaHh6nVake0DwwMMH369BIqMrMTUdGhcElE7JB0BrBO0nfqN0ZEpMBoWgqWVQD9/f3jeu3xrFarcfMdD9LV05e37R/awm3A4sWLS6vLzE4shYZCROxIz3skPQBcCOyW1B0RO1P30J60+w6gp+7l81ObJV09fZyx0OPvZlacwsYUJJ0iacbIMvArwLPAWmBZ2m0Z8FBaXgtcl85CGgAO1HUzmZlZGxR5pDAXeEDSyNf5+4h4VNK3gHslLQe2AVen/R8BrgC2Aq8B1xdYm5mZNVBYKETEi8C5Ddr3AUsatAdwQ1H1mJnZ2HxFs5mZ5RwKZmaWcyiYmVnOoWBmZjmHgpmZ5RwKZmaWcyiYmVnOoWBmZjmHgpmZ5RwKZmaWcyiYmVnOoWBmZjmHgpmZ5RwKZmaWcyiYmVnOoWBmZjmHgpmZ5RwKZmaWcyiYmVnOoWBmZjmHgpmZ5QoPBUlTJD0l6eG0fpakJyRtlfRlSdNS+8lpfWvavqDo2szM7HBNhYKki5tpO4obgc11658EbouIs4H9wPLUvhzYn9pvS/uZmVkbNXuk8Jkm2w4jaT7wP4DPpnUBlwL3pV3WAFem5aVpnbR9SdrfzMzaZOqxNkq6CHgPMEfS79dt+hlgShPv/yngD4EZaX028HJEHErr24F5aXkeMAQQEYckHUj7/3BUTSuAFQC9vb1NlGBmZs0a60hhGnAqWXjMqHu8Alx1rBdK+gCwJyI2taDOXESsioj+iOifM2dOK9/azKzjHfNIISK+CXxT0hciYts43/ti4IOSrgCmkx1d3A7MlDQ1HS3MB3ak/XcAPcB2SVOB04B94/yaZmY2Cc2OKZwsaZWkr0t6bORxrBdExCciYn5ELACuAR6LiA8DG3jjKGMZ8FBaXpvWSdsfi4gYzz/GzMwm55hHCnW+AtxJNmD8+iS/5seBeyT9OfAUsDq1rwa+KGkr8COyIDEzszZqNhQORcTKiX6RiPgG8I20/CJwYYN9hoEPTfRrmJnZ5DXbffQPkn5XUrekWSOPQiszM7O2a/ZIYaSv/2N1bQG8tbXlmJlZmZoKhYg4q+hCzMysfE2FgqTrGrVHxF2tLcfMzMrUbPfRu+qWpwNLgCcBh8IJ7vVDP2FwcPCI9oGBAaZPn15CRWZWpGa7j36vfl3STOCeQiqySnll5/e588Vhzhw6KW/bP7SF24DFixeXVpeZFaPZI4XRXgU8ztAhfubMt3LGwvPLLsPM2qDZMYV/IDvbCLKJ8H4BuLeooszMrBzNHin8Vd3yIWBbRGwvoB4zMytRs2MK35Q0lzcGnLcUV5JVnQefzU5czXYfXQ38JdlUFQI+I+ljEXHfMV9oJyQPPpuduJrtPvoj4F0RsQdA0hzgn3jjDmrWYTz4bHZianbuozeNBEKybxyvNTOz40SzRwqPSvoacHda/w3gkWJKslYbHh6mVqsd1nbw4EEApk2blrcNDg7y02jmLqtHajTOMJn3M7NyjHWP5rOBuRHxMUm/DlySNv0b8KWii7PWqNVq3HzHg3T19OVtP9i0gakzZnPm295Z1/Y4sxa+q9FbjKnROMNk3s/MyjHWkcKngE8ARMT9wP0Akn4pbfvVQquzlunq6TtsDGD/0Hc5qevMI9omY/Q4w2Tfz8zab6xxgbkR8czoxtS2oJCKzMysNGOFwsxjbHtzKwsxM7PyjRUKGyX99uhGSb8FbCqmJDMzK8tYYwo3AQ9I+jBvhEA/MA34tSILMzOz9jtmKETEbuA9kt4HnJOa/19EPFZ4ZTYmTzdhZq3W7NxHG4AN43ljSdOBfwZOTl/nvoj4E0lnkd2LYTbZ0cdHIuKgpJPJbtpzAdnFcb8RES+N52t2mkange57aTPXDw6yaNGivM3XC5hZsyZ6P4Vm/CdwaUT8WNJJwOOS/hH4feC2iLhH0p3AcmBlet4fEWdLugb4JNlFcnYMjU4DvXP9Zl8vYGYTUthUFZH5cVo9KT0CuJQ35kxaA1yZlpemddL2JZJUVH0nspGgGHnMOGNe2SWZ2XGi0PmLJE2RNAjsAdYB3wNejohDaZftwMhfrHnAEEDafoCsi2n0e66QtFHSxr179xZZvplZxymy+4iIeB1YlO7p/ADw9ha85ypgFUB/f3+Msbud4BrN6wQebDebqEJDYUREvCxpA3ARMFPS1HQ0MB/YkXbbAfQA2yVNBU4jG3A2O6pG8zr53g5mE1dYKKR7LvwkBcKbgfeTDR5vAK4iOwNpGfBQesnatP5vaftjEeEjARvT6HmdzGziijxS6AbWSJpCNnZxb0Q8LOl54B5Jfw48BaxO+68GvihpK/Aj4JoCazMzswYKC4WIeBo4r0H7i8CFDdqHgQ8VVY+ZmY3Nd08zM7OcQ8HMzHIOBTMzyzkUzMws51AwM7OcQ8HMzHIOBTMzyzkUzMws51AwM7NcWybEMxvhW4iaVZtDwdqq0S1EPaupWXU4FKztRt9C1Myqw2MKZmaWcyiYmVnOoWBmZjmHgpmZ5TzQbKXzaapm1eFQsNL5NFWz6nAoWCX4NFWzavCYgpmZ5QoLBUk9kjZIel7Sc5JuTO2zJK2TtCU9d6V2Sfq0pK2Snpbk/zaambVZkd1Hh4A/iIgnJc0ANklaB/wmsD4ibpV0C3AL8HHgcqAvPd4NrEzPHWd4eJharXZY2+DgID+NKSVVZGadorBQiIidwM60/B+SNgPzgKXA4rTbGuAbZKGwFLgrIgKoSZopqTu9T0ep1WrcfMeDdPX05W0/2PQ4sxa+q8SqzKwTtGWgWdIC4DzgCWBu3R/6XcDctDwPGKp72fbUdlgoSFoBrADo7e0trOaydfX0HTbwun/ouyVWY2adovCBZkmnAl8FboqIV+q3paOCGM/7RcSqiOiPiP45c+a0sFIzMys0FCSdRBYIX4qI+1PzbkndaXs3sCe17wB66l4+P7WZmVmbFNZ9JEnAamBzRPx13aa1wDLg1vT8UF37RyXdQzbAfKATxxMs46uczcpR5JjCxcBHgGckjfx2/2+yMLhX0nJgG3B12vYIcAWwFXgNuL7A2qzifJWzWTmKPPvocUBH2bykwf4B3FBUPXb88VXOZu3nK5rNzCznUDAzs5wnxGuBRlcggwdFzez441BogUZXIHtQ1MyORw6FFhl9BbKZ2fHIYwpmZpbzkYIdNxpd0ObZY81ay6FQMk+T3bxGF7R59liz1nIolMzTZI/P6AvaPHusWWs5FNroaEcFp83/ef+hM7NKcCi0kY8KzKzqHApt5pvnmFmV+ZRUMzPLORTMzCznUDAzs5xDwczMch5othNOq2/l6VlwrZM4FOyE0+pbeXoWXOskDoWCeJ6ecrX6Vp6eBdc6hUOhIJ6nx47G3VFWZQ6FAnmeHmvE3VFWZYWFgqTPAR8A9kTEOaltFvBlYAHwEnB1ROyXJOB24ArgNeA3I+LJomozK5u7o6yqijwl9QvAZaPabgHWR0QfsD6tA1wO9KXHCmBlgXWZmdlRFHakEBH/LGnBqOalwOK0vAb4BvDx1H5XRARQkzRTUndE7CyqPussjQb+Dx48CMC0adMOa3ffvnWydo8pzK37Q78LmJuW5wFDdfttT21HhIKkFWRHE/T29hZXqZ1QGg/8b2DqjNmc+bZ35m3u27dOV9pAc0SEpJjA61YBqwD6+/vH/XrrXI0G/k/qOvOwNp9KbJ2u3aGwe6RbSFI3sCe17wB66vabn9rM2sqnEluna/fcR2uBZWl5GfBQXft1ygwABzyeYGUZOaIYecw4Y17ZJZm1TZGnpN5NNqh8uqTtwJ8AtwL3SloObAOuTrs/QnY66layU1KvL6ouMzM7uiLPPrr2KJuWNNg3gBuKqsXMzJrjqbPNzCznaS7MJqDV03ObVYVDwWwCWj09t1lVOBTMJqjV03ObVYHHFMzMLOcjhXFqNBe+r3g1qNY4g+/ZYBPlUBinRnPh+4pXg2qNM/ieDTZRDoUJGD0Xvm+eYyOqNM7gezbYRDgUzCrKXUBWBoeCWYEmM+uqu4CsDA4FswI1O+vq0cLjtPk/7y4gayuHwjH4TCNrhUb3cRjNU3ZbVXRkKDTbV+szjaydmgmPZm8r6v+82ER1ZCiMp6/WZxpZlTR7W9F2/OfFA+Enpo4MBTjyj71vw2jHi2ZuKzqZ/7xM5kjaA+HHv44NhdHcp2ud6GjjZl/41+8zq/dteVuzR9J2/HMo1GmmT9fsRHKscbOJ/LGv0lQfNjEOBbMO18pxs8lM9eEximpwKJh1iMmMm43ntaOPuJs9evAYRTU4FMw6xGTGzVr9Wo9RVJdDwayDTGbcrJWvbfbIw2MU7VepUJB0GXA7MAX4bETcWnJJZlaAZo88Gu2376XNXD84yKJFiw7bt5mg8LjF2CoTCpKmAH8DvB/YDnxL0tqIeL7cysysCM0eeTTa7871m8cMiqNd6d3s6bZV0e4gq0woABcCWyPiRQBJ9wBLgUJCYf/QlsPW/2PPDqb+/2H2nHqq29zmtqq3zZhNvVf37eIv/+4FutY/k7f98MXnmPLmGXR19x7WNvOt5zJaoy6qqhgcHOT2e9dxyuyfzdte3beLz//fjxUSZIqIlr/pREi6CrgsIn4rrX8EeHdEfHTUfiuAFWl1IfBCgWWdDvywwPdvBdfYGq6xNVxjaxRd489FxJxGG6p0pNCUiFgFrGrH15K0MSL62/G1Jso1toZrbA3X2Bpl1vimMr7oUewAeurW56c2MzNrkyqFwreAPklnSZoGXAOsLbkmM7OOUpnuo4g4JOmjwNfITkn9XEQ8V3JZbemmmiTX2BqusTVcY2uUVmNlBprNzKx8Veo+MjOzkjkUzMws51AAJPVI2iDpeUnPSboxtc+StE7SlvTcVWKN0yX9u6Rvpxr/NLWfJekJSVslfTkN0pdK0hRJT0l6uIo1SnpJ0jOSBiVtTG2V+V6nemZKuk/SdyRtlnRRBWtcmD7Dkccrkm6qYJ03p9+ZZyXdnX6XqvYzeWOq7zlJN6W2Uj5Hh0LmEPAHEfEOYAC4QdI7gFuA9RHRB6xP62X5T+DSiDgXWARcJmkA+CRwW0ScDewHlpdY44gbgc1161Ws8X0RsajuXPAqfa8hmwPs0Yh4O3Au2edZqRoj4oX0GS4CLgBeAx6gQnVKmgf8L6A/Is4hO4nlGir0MynpHOC3yWZ1OBf4gKSzKetzjAg/Rj2Ah8jmYHoB6E5t3cALZdeWankL8CTwbrKrHqem9ouAr5Vc2/z0A3wp8DCgCtb4EnD6qLbKfK+B04Dvk04EqWKNDWr+FeBfq1YnMA8YAmaRnW35MPDfq/QzCXwIWF23/n+APyzrc/SRwiiSFgDnAU8AcyNiZ9q0C5hbUllA3i0zCOwB1gHfA16OiENpl+1kvwRl+hTZD/RP0/psqldjAF+XtClNmwLV+l6fBewFPp+64T4r6RSqVeNo1wB3p+XK1BkRO4C/An4A7AQOAJuo1s/ks8B/kzRb0luAK8gu5C3lc3Qo1JF0KvBV4KaIeKV+W2RxXer5uxHxemSH6vPJDjXfXmY9o0n6ALAnIjaVXcsYLomI84HLyboK31u/sQLf66nA+cDKiDgPeJVRXQcVqDGX+uM/CHxl9Lay60z98EvJgvZM4BTgsrLqaSQiNpN1Z30deBQYBF4ftU/bPkeHQiLpJLJA+FJE3J+ad0vqTtu7yf6HXrqIeBnYQHbYO1PSyEWIZU8NcjHwQUkvAfeQdSHdTrVqHPnfIxGxh6wP/EKq9b3eDmyPiCfS+n1kIVGlGutdDjwZEbvTepXq/GXg+xGxNyJ+AtxP9nNatZ/J1RFxQUS8l2yM47uU9Dk6FABJAlYDmyPir+s2rQWWpeVlZGMNpZA0R9LMtPxmsjGPzWThcFXardQaI+ITETE/IhaQdSc8FhEfpkI1SjpF0oyRZbK+8Gep0Pc6InYBQ5IWpqYlZFPIV6bGUa7lja4jqFadPwAGJL0l/Z6PfJaV+ZkEkHRGeu4Ffh34e8r6HMsaXKnSA7iE7NDsabJDt0Gyfr3ZZIOmW4B/AmaVWOM7gadSjc8Cf5za3wr8O7CV7PD95LI/z1TXYuDhqtWYavl2ejwH/FFqr8z3OtWzCNiYvt8PAl1VqzHVeQqwDzitrq1SdQJ/Cnwn/d58ETi5Sj+TqcZ/IQurbwNLyvwcPc2FmZnl3H1kZmY5h4KZmeUcCmZmlnMomJlZzqFgZmY5h4LZBEm6UlJIqtSV5WaT4VAwm7hrgcfTs9kJwaFgNgFpnqxLyKZcvia1vUnSHekeCOskPSLpqrTtAknfTJPwfW1k+gKzqnEomE3MUrL7HXwX2CfpArLpCRYA7wA+QjY31ci8Wp8BroqIC4DPAX9RRtFmY5k69i5m1sC1ZJP9QTb537Vkv09fiYifArskbUjbFwLnAOuy6XeYQjaNs1nlOBTMxknSLLIZYH9JUpD9kQ+yGVcbvgR4LiIualOJZhPm7iOz8bsK+GJE/FxELIiIHrI7pf0I+J9pbGEu2aSAkN1Ba46kvDtJ0i+WUbjZWBwKZuN3LUceFXwV+FmyeyE8D/wd2S1TD0TEQbIg+aSkb5PNwvue9pVr1jzPkmrWQpJOjYgfS5pNNjXzxZHdH8HsuOAxBbPWejjdDGka8GcOBDve+EjBzMxyHlMwM7OcQ8HMzHIOBTMzyzkUzMws51AwM7PcfwGTzSmHMfFrQgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(df_train['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1623409803123,
     "user": {
      "displayName": "Tee Yee Yang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgKFrQtw-OyvubwOe5xvtv9JOTRkaAVybEHvmq9ag=s64",
      "userId": "07106232567566268752"
     },
     "user_tz": -480
    },
    "id": "a62lAY90Of4S"
   },
   "outputs": [],
   "source": [
    "# Run this cell to generate data and save them.\n",
    "syn_data = model.generate(train_x.shape[0], class_ratios)\n",
    "syn_x, syn_y = syn_data[:, :-1], syn_data[:, -1]\n",
    "\n",
    "# Make a copy for saving\n",
    "syn_save = scaler.inverse_transform(syn_x)\n",
    "\n",
    "# Save data to csv using functions\n",
    "if DATASET_NAME == 'churn': save_churn()\n",
    "else: save_marketing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NzwFmG7wOf4T"
   },
   "source": [
    "## Do classification using Neural Networks and look at ROC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5320,
     "status": "ok",
     "timestamp": 1623405368046,
     "user": {
      "displayName": "Tee Yee Yang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgKFrQtw-OyvubwOe5xvtv9JOTRkaAVybEHvmq9ag=s64",
      "userId": "07106232567566268752"
     },
     "user_tz": -480
    },
    "id": "QRtEB0Orm7ah",
    "outputId": "e7c3fe2d-31f3-424f-b357-99ce98d6d3e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Score 0.523977249291754\n",
      "Accuracy 0.4852\n"
     ]
    }
   ],
   "source": [
    "# Train using Synthetic data, using simple neural network.\n",
    "mlp = MLPClassifier((32,8), max_iter=1000, random_state=42)\n",
    "mlp.fit(syn_x, syn_y)\n",
    "pred_y = mlp.predict(test_x)\n",
    "\n",
    "print('ROC Score', roc_auc_score(test_y, pred_y))\n",
    "print('Accuracy', mlp.score(test_x,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10074,
     "status": "ok",
     "timestamp": 1623405378118,
     "user": {
      "displayName": "Tee Yee Yang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgKFrQtw-OyvubwOe5xvtv9JOTRkaAVybEHvmq9ag=s64",
      "userId": "07106232567566268752"
     },
     "user_tz": -480
    },
    "id": "nB_uyefotvDF",
    "outputId": "540b4e18-8e11-4501-ddd2-bbbec1eea282"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Score 0.7328967583990432\n",
      "Accuracy 0.8564\n"
     ]
    }
   ],
   "source": [
    "# Train using REAL data, using simple neural network.\n",
    "mlp = MLPClassifier((32,8), max_iter=1000, random_state=42)\n",
    "mlp.fit(train_x, train_y)\n",
    "pred_y = mlp.predict(test_x)\n",
    "\n",
    "print('ROC Score', roc_auc_score(test_y, pred_y))\n",
    "print('Accuracy', mlp.score(test_x,test_y))\n",
    "# Uitvoer van uitgevoerde code vanaf 7 jun. 2021 03:50\n",
    "# \tStream\n",
    "# \t\tROC Score 0.7530632082470008\n",
    "# \t\tAccuracy 0.8754512635379061"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z26Et5H0Of4U"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB,BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y8X5idt6zWrI"
   },
   "outputs": [],
   "source": [
    "# Initialise all models\n",
    "classifier_names = ['MLP', 'RF', 'ADABOOST', 'DT', 'GauNB', 'BernNB', 'SVM', 'LogReg']\n",
    "classifiers = [MLPClassifier((32,8), max_iter=1000, random_state=42), #MLP\n",
    "               RandomForestClassifier(max_depth=2, random_state=42), #RF\n",
    "               AdaBoostClassifier(n_estimators=50, random_state=42),\n",
    "               DecisionTreeClassifier(random_state=42),\n",
    "               GaussianNB(),\n",
    "               BernoulliNB(),\n",
    "               SVC(random_state=42),\n",
    "               LogisticRegression(random_state=42)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O4xxVDIEzZuo"
   },
   "outputs": [],
   "source": [
    "syn_clf_accuracy = []\n",
    "syn_clf_roc_score = []\n",
    "real_clf_accuracy = []\n",
    "real_clf_roc_score = []\n",
    "\n",
    "# Loop thru all classifiers.\n",
    "for clf in classifiers:\n",
    "\n",
    "    # Do synthetic\n",
    "    clf.fit(syn_x, syn_y)\n",
    "    pred_y = clf.predict(test_x)\n",
    "\n",
    "    # compute score and append\n",
    "    syn_clf_roc_score.append(roc_auc_score(test_y, pred_y))\n",
    "    syn_clf_accuracy.append(clf.score(test_x,test_y))\n",
    "\n",
    "    # Do real training data\n",
    "    clf.fit(train_x, train_y)\n",
    "    pred_y = clf.predict(test_x)\n",
    "\n",
    "    # compute score and append\n",
    "    real_clf_roc_score.append(roc_auc_score(test_y, pred_y))\n",
    "    real_clf_accuracy.append(clf.score(test_x,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x9kWsQABzbji"
   },
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame({'Classifier Name':classifier_names,\n",
    "                         'Accuracy on Synthetic':syn_clf_accuracy,\n",
    "                         'ROC on Synthetic': syn_clf_roc_score,\n",
    "                         'Accuracy on Real': real_clf_accuracy,\n",
    "                         'ROC on Real': real_clf_roc_score,\n",
    "                         })\n",
    "score_df.to_csv('scores.csv') # Make into a csv that you can download and do computations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "executionInfo": {
     "elapsed": 196,
     "status": "ok",
     "timestamp": 1623329147411,
     "user": {
      "displayName": "Rishi Yildiz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgKrDEkVNAvDdk6mSPj9mqfa7nsf70pBZmUc1aP8D4=s64",
      "userId": "04327726311178638571"
     },
     "user_tz": -120
    },
    "id": "R8rC27ri0M4s",
    "outputId": "257850a3-b0d4-41a2-cd4d-cfa0f5a2a3ce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier Name</th>\n",
       "      <th>Accuracy on Synthetic</th>\n",
       "      <th>ROC on Synthetic</th>\n",
       "      <th>Accuracy on Real</th>\n",
       "      <th>ROC on Real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.518051</td>\n",
       "      <td>0.612347</td>\n",
       "      <td>0.875451</td>\n",
       "      <td>0.753063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.850181</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.851986</td>\n",
       "      <td>0.506024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADABOOST</td>\n",
       "      <td>0.750903</td>\n",
       "      <td>0.545827</td>\n",
       "      <td>0.897112</td>\n",
       "      <td>0.750914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.514440</td>\n",
       "      <td>0.550674</td>\n",
       "      <td>0.803249</td>\n",
       "      <td>0.656013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GauNB</td>\n",
       "      <td>0.738267</td>\n",
       "      <td>0.622759</td>\n",
       "      <td>0.871841</td>\n",
       "      <td>0.636802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BernNB</td>\n",
       "      <td>0.790614</td>\n",
       "      <td>0.519556</td>\n",
       "      <td>0.781588</td>\n",
       "      <td>0.702824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.850181</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.879061</td>\n",
       "      <td>0.626161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.723827</td>\n",
       "      <td>0.658929</td>\n",
       "      <td>0.895307</td>\n",
       "      <td>0.715115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier Name  Accuracy on Synthetic  ...  Accuracy on Real  ROC on Real\n",
       "0             MLP               0.518051  ...          0.875451     0.753063\n",
       "1              RF               0.850181  ...          0.851986     0.506024\n",
       "2        ADABOOST               0.750903  ...          0.897112     0.750914\n",
       "3              DT               0.514440  ...          0.803249     0.656013\n",
       "4           GauNB               0.738267  ...          0.871841     0.636802\n",
       "5          BernNB               0.790614  ...          0.781588     0.702824\n",
       "6             SVM               0.850181  ...          0.879061     0.626161\n",
       "7          LogReg               0.723827  ...          0.895307     0.715115\n",
       "\n",
       "[8 rows x 5 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "pategan-fullscript.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
