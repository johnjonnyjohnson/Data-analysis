{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"dpwgan-fullscript.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python [conda env:pategan]","language":"python","name":"conda-env-pategan-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jQrT1TFLOBiF","executionInfo":{"status":"ok","timestamp":1623406500900,"user_tz":-120,"elapsed":792,"user":{"displayName":"Rishi Yildiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKrDEkVNAvDdk6mSPj9mqfa7nsf70pBZmUc1aP8D4=s64","userId":"04327726311178638571"}},"outputId":"c752d4be-f1b6-44bc-f2d0-be9e7743c304"},"source":["!git clone https://github.com/yeeyangtee/private-data-generation.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'private-data-generation'...\n","remote: Enumerating objects: 103, done.\u001b[K\n","remote: Counting objects: 100% (103/103), done.\u001b[K\n","remote: Compressing objects: 100% (80/80), done.\u001b[K\n","remote: Total 103 (delta 35), reused 84 (delta 20), pack-reused 0\u001b[K\n","Receiving objects: 100% (103/103), 1.21 MiB | 9.04 MiB/s, done.\n","Resolving deltas: 100% (35/35), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lT5bQZ0BOORB","executionInfo":{"status":"ok","timestamp":1623406506239,"user_tz":-120,"elapsed":273,"user":{"displayName":"Rishi Yildiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKrDEkVNAvDdk6mSPj9mqfa7nsf70pBZmUc1aP8D4=s64","userId":"04327726311178638571"}},"outputId":"ca95926e-7904-4401-a255-f0ee0f415a01"},"source":["cd /content/private-data-generation"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/private-data-generation\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jMBw5oPfOPVG","executionInfo":{"status":"ok","timestamp":1623406513385,"user_tz":-120,"elapsed":3888,"user":{"displayName":"Rishi Yildiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKrDEkVNAvDdk6mSPj9mqfa7nsf70pBZmUc1aP8D4=s64","userId":"04327726311178638571"}},"outputId":"c9adb9ac-43df-4366-b02d-36c20019c356"},"source":["# Download datasets\n","!gdown --id 1PaXMlTVHoB-vv-CaY1SgZDhf3evZjWf9 # churn processed\n","!gdown --id 1sJRwaeYcNaX_hqRJdhqAtMWnX7h-XKJE # marketing processed"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1PaXMlTVHoB-vv-CaY1SgZDhf3evZjWf9\n","To: /content/private-data-generation/churn_processed.csv\n","100% 443k/443k [00:00<00:00, 58.7MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1sJRwaeYcNaX_hqRJdhqAtMWnX7h-XKJE\n","To: /content/private-data-generation/marketing_processed.csv\n","100% 224k/224k [00:00<00:00, 94.8MB/s]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5ijsbqc7Ipl2"},"source":["## Full DPWGAN rewrite"]},{"cell_type":"code","metadata":{"id":"QifCHxjTI5Ql"},"source":["from sklearn.metrics import roc_auc_score\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","\n","from models import dp_wgan, pate_gan\n","import numpy as np\n","import pandas as pd\n","import collections, time"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KcDKmo_aisiA"},"source":["# HYPERPARAMETERS\n","MODEL_NAME = 'DPWGAN' # Don't change this\n","DATASET_NAME = 'churn' # Choose either 'churn' or 'marketing' exactly!\n","TARGET_VARIABLE = 'Exited' # either 'Exited' or 'Response'\n","TRAIN_TEST_RATIO = 0.25\n","LEAKY = False # Put False for normal relu. The number indicates the amount of negative slope. Default is 0.01\n","\n","# These seem to be good/important to tune from what I can tell from the github.\n","TARGET_EPSILON = 5\n","TARGET_DELTA = 1e-4\n","SIGMA = 3\n","NUM_EPOCHS = 100\n","LEARNING_RATE = 5e-5\n","\n","# Following defaults in the toolbox. Might not be crucial to tune these\n","MICRO_BATCH_SIZE = 8\n","BATCH_SIZE = 64\n","ENABLE_PRIVACY = True\n","CLIP_COEFF = 0.1\n","CLAMP_LOWER = -0.01\n","CLAMP_UPPER = 0.01"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6LXKHydGhhEF"},"source":["# Read in data and do train test split\n","df = pd.read_csv(f'{DATASET_NAME}_processed.csv')\n","df_train, df_test = train_test_split(df, test_size=TRAIN_TEST_RATIO, random_state=42, stratify = df[TARGET_VARIABLE])\n","\n","# Initialise logfile path\n","timestamp = int(time.time())\n","logfile = f'log_{DATASET_NAME}_{MODEL_NAME}_{timestamp}_{TARGET_EPSILON}.csv'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0rmYtc28ZXk4"},"source":["# Grab x and y from the respective dataframes and convert to numpy arrays.\n","train_x = df_train.drop(columns=TARGET_VARIABLE).values\n","train_y = df_train[TARGET_VARIABLE].values\n","test_x = df_test.drop(columns=TARGET_VARIABLE).values\n","test_y = df_test[TARGET_VARIABLE].values\n","\n","# Initialise scaler and use this to normalize the inputs.\n","scaler = StandardScaler()\n","train_x = scaler.fit_transform(train_x)\n","test_x = scaler.transform(test_x)\n","\n","# Some misc variables for pategan \n","data_columns = [col for col in df_train.columns if col != TARGET_VARIABLE]\n","class_ratios = df_train[TARGET_VARIABLE].sort_values().groupby(df_train[TARGET_VARIABLE]).size().values/train_x.shape[0]\n","input_dim = train_x.shape[1]\n","z_dim = int(input_dim / 4 + 1) if input_dim % 4 == 0 else int(input_dim / 4)\n","conditional = True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vMGXxmhnmEpz"},"source":["# Initialise hyperparams and do TRAINING\n","Hyperparams = collections.namedtuple(\n","        'Hyperarams',\n","        'batch_size micro_batch_size clamp_lower clamp_upper clip_coeff sigma class_ratios lr num_epochs')\n","Hyperparams.__new__.__defaults__ = (None, None, None, None, None, None, None, None, None)\n","\n","model = dp_wgan.DP_WGAN(LEAKY, logfile, input_dim, z_dim, TARGET_EPSILON, TARGET_DELTA, conditional)\n","model.train(train_x, train_y, Hyperparams(batch_size=BATCH_SIZE, micro_batch_size=MICRO_BATCH_SIZE,\n","                                              clamp_lower=CLAMP_LOWER, clamp_upper=CLAMP_UPPER,\n","                                              clip_coeff=CLIP_COEFF, sigma=SIGMA, class_ratios=class_ratios, lr=LEARNING_RATE, \n","                                              num_epochs=NUM_EPOCHS), private=ENABLE_PRIVACY)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2z8_6rRhoiKE","executionInfo":{"status":"ok","timestamp":1623319868751,"user_tz":-480,"elapsed":389,"user":{"displayName":"Tee Yee Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKFrQtw-OyvubwOe5xvtv9JOTRkaAVybEHvmq9ag=s64","userId":"07106232567566268752"}},"outputId":"89dd1e52-bb1c-40e8-94a6-93b46712af27"},"source":["# Optional: Look at model architectures\n","print(model.discriminator)\n","print(model.generator)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Discriminator(\n","  (main): Sequential(\n","    (0): Linear(in_features=43, out_features=21, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=21, out_features=1, bias=True)\n","  )\n",")\n","Generator(\n","  (main): Sequential(\n","    (0): Linear(in_features=11, out_features=20, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=20, out_features=42, bias=True)\n","  )\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iaRBd2RkOAyl"},"source":["## Generate synthetic data using trained model, then save in CSV"]},{"cell_type":"code","metadata":{"id":"FoR8Lqbmhace"},"source":["# Helper functions for saving the synthetic data...\n","def update_array(indexes, cols = None):\n","    if cols: colsize = cols\n","    else: colsize = indexes.max() +1\n","    b = np.zeros((indexes.size, colsize))\n","    b[np.arange(indexes.size), indexes] = 1\n","    return b\n","\n","def save_marketing():\n","    # Some fancy indexing to get the actual synthetic data..\n","    accepted = np.argmax(syn_save[:,16:21], axis=1)\n","    education = np.argmax(syn_save[:, 22:27], axis=1)\n","    marital = np.argmax(syn_save[:, 27:34], axis=1)\n","    country = np.argmax(syn_save[:, 34:], axis=1)\n","\n","    syn_save[:,16:21] = update_array(accepted, cols=5)\n","    syn_save[:, 22:27] = update_array(education, cols=5)\n","    syn_save[:, 27:34] = update_array(marital, cols=7)\n","    syn_save[:, 34:] = update_array(country, cols=8)\n","\n","    df1 = pd.DataFrame(syn_save, columns = df.columns.drop(TARGET_VARIABLE))\n","    df2 = pd.DataFrame(syn_y, columns = [TARGET_VARIABLE])\n","    df_save = pd.concat([df1,df2], axis =1)\n","    df_save.to_csv(f'synthetic_{MODEL_NAME}_{DATASET_NAME}_{TARGET_EPSILON}.csv')\n","\n","def save_churn():\n","    geography = np.argmax(syn_save[:,8:11], axis=1)\n","    gender = np.argmax(syn_save[:,11:], axis=1)\n","    \n","    syn_save[:,8:11] = update_array(geography, cols=3)\n","    syn_save[:, 11:] = update_array(gender, cols=2)\n","    syn_save[:,4] = np.round(syn_save[:,4]) # num products\n","    syn_save[:,5] = np.round(np.clip(syn_save[:,5],0,1)) # Has card\n","    syn_save[:,6] = np.round(np.clip(syn_save[:,6],0,1)) # Is active\n","    \n","    df1 = pd.DataFrame(syn_save, columns = df.columns.drop(TARGET_VARIABLE))\n","    df2 = pd.DataFrame(syn_y, columns = [TARGET_VARIABLE])\n","    df_save = pd.concat([df1,df2], axis =1)\n","    df_save.to_csv(f'synthetic_{MODEL_NAME}_{DATASET_NAME}_{TARGET_EPSILON}.csv')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QNo3jt20OAym"},"source":["# Run this cell to generate data and save them.\n","syn_data = model.generate(train_x.shape[0], class_ratios)\n","syn_x, syn_y = syn_data[:, :-1], syn_data[:, -1]\n","\n","# Make a copy for saving\n","syn_save = scaler.inverse_transform(syn_x)\n","\n","# Save data to csv using functions\n","if DATASET_NAME == 'churn': save_churn()\n","else: save_marketing()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dkFp8fy3OAyn"},"source":["## Do classification with various classifiers.\n","- MLP\n","- RandomForest\n","- AdaBoost\n","- Decision Trees\n","- Gaussian Naive Bayes\n","- Bernouilli Naive Bayes\n","- SVM\n","- Logistic Regression"]},{"cell_type":"code","metadata":{"id":"tp6RMgVKWuoh"},"source":["from sklearn.neural_network import MLPClassifier\n","from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.naive_bayes import GaussianNB,BernoulliNB\n","from sklearn.svm import SVC\n","from sklearn.linear_model import LogisticRegression"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5AWz2tkQX-e6"},"source":["# Initialise all models\n","classifier_names = ['MLP', 'RF', 'ADABOOST', 'DT', 'GauNB', 'BernNB', 'SVM', 'LogReg']\n","classifiers = [MLPClassifier((32,8), max_iter=1000, random_state=42), #MLP\n","               RandomForestClassifier(max_depth=2, random_state=42), #RF\n","               AdaBoostClassifier(n_estimators=50, random_state=42),\n","               DecisionTreeClassifier(random_state=42),\n","               GaussianNB(),\n","               BernoulliNB(),\n","               SVC(random_state=42),\n","               LogisticRegression(random_state=42)\n","]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SEcSLnyVZ7Qz"},"source":["syn_clf_accuracy = []\n","syn_clf_roc_score = []\n","real_clf_accuracy = []\n","real_clf_roc_score = []\n","\n","# Loop thru all classifiers.\n","for clf in classifiers:\n","\n","    # Do synthetic\n","    clf.fit(syn_x, syn_y)\n","    pred_y = clf.predict(test_x)\n","\n","    # compute score and append\n","    syn_clf_roc_score.append(roc_auc_score(test_y, pred_y))\n","    syn_clf_accuracy.append(clf.score(test_x,test_y))\n","\n","    # Do real training data\n","    clf.fit(train_x, train_y)\n","    pred_y = clf.predict(test_x)\n","\n","    # compute score and append\n","    real_clf_roc_score.append(roc_auc_score(test_y, pred_y))\n","    real_clf_accuracy.append(clf.score(test_x,test_y))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zYoIDID9MqCu"},"source":["score_df = pd.DataFrame({'Classifier Name':classifier_names,\n","                         'Accuracy on Synthetic':syn_clf_accuracy,\n","                         'ROC on Synthetic': syn_clf_roc_score,\n","                         'Accuracy on Real': real_clf_accuracy,\n","                         'ROC on Real': real_clf_roc_score,\n","                         })\n","score_df.to_csv( 'scores.csv') # Make into a csv that you can download and do computations!"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"id":"-OG3AhWIa8xS","executionInfo":{"status":"ok","timestamp":1623408109356,"user_tz":-120,"elapsed":529,"user":{"displayName":"Rishi Yildiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKrDEkVNAvDdk6mSPj9mqfa7nsf70pBZmUc1aP8D4=s64","userId":"04327726311178638571"}},"outputId":"0291b7b6-4327-4063-9181-e842e9aec8a5"},"source":["score_df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Classifier Name</th>\n","      <th>Accuracy on Synthetic</th>\n","      <th>ROC on Synthetic</th>\n","      <th>Accuracy on Real</th>\n","      <th>ROC on Real</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>MLP</td>\n","      <td>0.4648</td>\n","      <td>0.466567</td>\n","      <td>0.8564</td>\n","      <td>0.732897</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>RF</td>\n","      <td>0.6808</td>\n","      <td>0.532715</td>\n","      <td>0.8080</td>\n","      <td>0.529218</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ADABOOST</td>\n","      <td>0.2712</td>\n","      <td>0.481752</td>\n","      <td>0.8604</td>\n","      <td>0.724440</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>DT</td>\n","      <td>0.4464</td>\n","      <td>0.443316</td>\n","      <td>0.7948</td>\n","      <td>0.686180</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>GauNB</td>\n","      <td>0.5304</td>\n","      <td>0.570635</td>\n","      <td>0.8100</td>\n","      <td>0.654776</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>BernNB</td>\n","      <td>0.7824</td>\n","      <td>0.502909</td>\n","      <td>0.8028</td>\n","      <td>0.622471</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>SVM</td>\n","      <td>0.7792</td>\n","      <td>0.493589</td>\n","      <td>0.8612</td>\n","      <td>0.685458</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>LogReg</td>\n","      <td>0.5488</td>\n","      <td>0.508337</td>\n","      <td>0.8092</td>\n","      <td>0.578961</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Classifier Name  Accuracy on Synthetic  ...  Accuracy on Real  ROC on Real\n","0             MLP                 0.4648  ...            0.8564     0.732897\n","1              RF                 0.6808  ...            0.8080     0.529218\n","2        ADABOOST                 0.2712  ...            0.8604     0.724440\n","3              DT                 0.4464  ...            0.7948     0.686180\n","4           GauNB                 0.5304  ...            0.8100     0.654776\n","5          BernNB                 0.7824  ...            0.8028     0.622471\n","6             SVM                 0.7792  ...            0.8612     0.685458\n","7          LogReg                 0.5488  ...            0.8092     0.578961\n","\n","[8 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"52vU_o-Ta_-E"},"source":[""],"execution_count":null,"outputs":[]}]}