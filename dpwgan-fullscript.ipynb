{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 792,
     "status": "ok",
     "timestamp": 1623406500900,
     "user": {
      "displayName": "Rishi Yildiz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgKrDEkVNAvDdk6mSPj9mqfa7nsf70pBZmUc1aP8D4=s64",
      "userId": "04327726311178638571"
     },
     "user_tz": -120
    },
    "id": "jQrT1TFLOBiF",
    "outputId": "c752d4be-f1b6-44bc-f2d0-be9e7743c304"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'private-data-generation'...\n",
      "remote: Enumerating objects: 103, done.\u001b[K\n",
      "remote: Counting objects: 100% (103/103), done.\u001b[K\n",
      "remote: Compressing objects: 100% (80/80), done.\u001b[K\n",
      "remote: Total 103 (delta 35), reused 84 (delta 20), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (103/103), 1.21 MiB | 9.04 MiB/s, done.\n",
      "Resolving deltas: 100% (35/35), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/yeeyangtee/private-data-generation.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 273,
     "status": "ok",
     "timestamp": 1623406506239,
     "user": {
      "displayName": "Rishi Yildiz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgKrDEkVNAvDdk6mSPj9mqfa7nsf70pBZmUc1aP8D4=s64",
      "userId": "04327726311178638571"
     },
     "user_tz": -120
    },
    "id": "lT5bQZ0BOORB",
    "outputId": "ca95926e-7904-4401-a255-f0ee0f415a01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/private-data-generation\n"
     ]
    }
   ],
   "source": [
    "cd /content/private-data-generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3888,
     "status": "ok",
     "timestamp": 1623406513385,
     "user": {
      "displayName": "Rishi Yildiz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgKrDEkVNAvDdk6mSPj9mqfa7nsf70pBZmUc1aP8D4=s64",
      "userId": "04327726311178638571"
     },
     "user_tz": -120
    },
    "id": "jMBw5oPfOPVG",
    "outputId": "c9adb9ac-43df-4366-b02d-36c20019c356"
   },
   "outputs": [],
   "source": [
    "# Download datasets\n",
    "!gdown --id 1PaXMlTVHoB-vv-CaY1SgZDhf3evZjWf9 # churn processed\n",
    "!gdown --id 1sJRwaeYcNaX_hqRJdhqAtMWnX7h-XKJE # marketing processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ijsbqc7Ipl2"
   },
   "source": [
    "## Full DPWGAN rewrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QifCHxjTI5Ql"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from models import dp_wgan, pate_gan\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KcDKmo_aisiA"
   },
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "MODEL_NAME = 'DPWGAN' # Don't change this\n",
    "DATASET_NAME = 'marketing' # Choose either 'churn' or 'marketing' exactly!\n",
    "TARGET_VARIABLE = 'Response' # either 'Exited' or 'Response'\n",
    "TRAIN_TEST_RATIO = 0.25\n",
    "LEAKY = False # Put False for normal relu. The number indicates the amount of negative slope. Default is 0.01\n",
    "\n",
    "# These seem to be good/important to tune from what I can tell from the github.\n",
    "TARGET_EPSILON = 10\n",
    "TARGET_DELTA = 1e-4\n",
    "SIGMA = 1.2\n",
    "NUM_EPOCHS = 100\n",
    "LEARNING_RATE = 5e-5\n",
    "\n",
    "# Following defaults in the toolbox. Might not be crucial to tune these\n",
    "MICRO_BATCH_SIZE = 8\n",
    "BATCH_SIZE = 64\n",
    "ENABLE_PRIVACY = True\n",
    "CLIP_COEFF = 0.1\n",
    "CLAMP_LOWER = -0.01\n",
    "CLAMP_UPPER = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6LXKHydGhhEF"
   },
   "outputs": [],
   "source": [
    "# Read in data and do train test split\n",
    "df = pd.read_csv(f'{DATASET_NAME}_processed.csv')\n",
    "df_train, df_test = train_test_split(df, test_size=TRAIN_TEST_RATIO, random_state=42, stratify = df[TARGET_VARIABLE])\n",
    "\n",
    "# Initialise logfile path\n",
    "timestamp = int(time.time())\n",
    "logfile = f'logs/log_{DATASET_NAME}_{MODEL_NAME}_{timestamp}_{TARGET_EPSILON}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0rmYtc28ZXk4"
   },
   "outputs": [],
   "source": [
    "# Grab x and y from the respective dataframes and convert to numpy arrays.\n",
    "train_x = df_train.drop(columns=TARGET_VARIABLE).values\n",
    "train_y = df_train[TARGET_VARIABLE].values\n",
    "test_x = df_test.drop(columns=TARGET_VARIABLE).values\n",
    "test_y = df_test[TARGET_VARIABLE].values\n",
    "\n",
    "# Initialise scaler and use this to normalize the inputs.\n",
    "scaler = StandardScaler()\n",
    "train_x = scaler.fit_transform(train_x)\n",
    "test_x = scaler.transform(test_x)\n",
    "\n",
    "# Some misc variables for pategan \n",
    "data_columns = [col for col in df_train.columns if col != TARGET_VARIABLE]\n",
    "class_ratios = df_train[TARGET_VARIABLE].sort_values().groupby(df_train[TARGET_VARIABLE]).size().values/train_x.shape[0]\n",
    "input_dim = train_x.shape[1]\n",
    "z_dim = int(input_dim / 4 + 1) if input_dim % 4 == 0 else int(input_dim / 4)\n",
    "conditional = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vMGXxmhnmEpz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Roc of 0.5153480162688973 found, saving....\n",
      "saving nice!\n",
      "Epoch : 1 Loss D real :  0.011415510552723997 Loss D fake :  0.012078700414173518 Loss G :  0.012225620332291652 Epsilon spent :  1.8460928363141051 ROC attained:  0.5153480162688973\n",
      "Epoch : 2 Loss D real :  0.011933347067052595 Loss D fake :  0.012503993027578722 Loss G :  0.012535728964354249 Epsilon spent :  2.1496228187495907 ROC attained:  0.4781930268846085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yeeyang/anaconda3/envs/pategan/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:619: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 3 Loss D real :  0.012136609245305163 Loss D fake :  0.012807176579899276 Loss G :  0.012921056324201477 Epsilon spent :  2.4020824091979414 ROC attained:  0.4186427237612872\n"
     ]
    }
   ],
   "source": [
    "# Initialise hyperparams and do TRAINING\n",
    "Hyperparams = collections.namedtuple(\n",
    "        'Hyperarams',\n",
    "        'batch_size micro_batch_size clamp_lower clamp_upper clip_coeff sigma class_ratios lr num_epochs')\n",
    "Hyperparams.__new__.__defaults__ = (None, None, None, None, None, None, None, None, None)\n",
    "\n",
    "model = dp_wgan.DP_WGAN(LEAKY, logfile, input_dim, z_dim, TARGET_EPSILON, TARGET_DELTA, conditional)\n",
    "model.train(train_x, train_y, test_x, test_y, data_columns, scaler, DATASET_NAME, Hyperparams(batch_size=BATCH_SIZE, micro_batch_size=MICRO_BATCH_SIZE,\n",
    "                                              clamp_lower=CLAMP_LOWER, clamp_upper=CLAMP_UPPER,\n",
    "                                              clip_coeff=CLIP_COEFF, sigma=SIGMA, class_ratios=class_ratios, lr=LEARNING_RATE, \n",
    "                                              num_epochs=NUM_EPOCHS), private=ENABLE_PRIVACY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 389,
     "status": "ok",
     "timestamp": 1623319868751,
     "user": {
      "displayName": "Tee Yee Yang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgKFrQtw-OyvubwOe5xvtv9JOTRkaAVybEHvmq9ag=s64",
      "userId": "07106232567566268752"
     },
     "user_tz": -480
    },
    "id": "2z8_6rRhoiKE",
    "outputId": "89dd1e52-bb1c-40e8-94a6-93b46712af27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=43, out_features=21, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=21, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=11, out_features=20, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=20, out_features=42, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Optional: Look at model architectures\n",
    "print(model.discriminator)\n",
    "print(model.generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iaRBd2RkOAyl"
   },
   "source": [
    "## Generate synthetic data using trained model, then save in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FoR8Lqbmhace"
   },
   "outputs": [],
   "source": [
    "# Helper functions for saving the synthetic data...\n",
    "def update_array(indexes, cols = None):\n",
    "    if cols: colsize = cols\n",
    "    else: colsize = indexes.max() +1\n",
    "    b = np.zeros((indexes.size, colsize))\n",
    "    b[np.arange(indexes.size), indexes] = 1\n",
    "    return b\n",
    "\n",
    "def save_marketing():\n",
    "    # Some fancy indexing to get the actual synthetic data..\n",
    "    accepted = np.argmax(syn_save[:,16:21], axis=1)\n",
    "    education = np.argmax(syn_save[:, 22:27], axis=1)\n",
    "    marital = np.argmax(syn_save[:, 27:34], axis=1)\n",
    "    country = np.argmax(syn_save[:, 34:], axis=1)\n",
    "\n",
    "    syn_save[:,16:21] = update_array(accepted, cols=5)\n",
    "    syn_save[:, 22:27] = update_array(education, cols=5)\n",
    "    syn_save[:, 27:34] = update_array(marital, cols=7)\n",
    "    syn_save[:, 34:] = update_array(country, cols=8)\n",
    "\n",
    "    df1 = pd.DataFrame(syn_save, columns = df.columns.drop(TARGET_VARIABLE))\n",
    "    df2 = pd.DataFrame(syn_y, columns = [TARGET_VARIABLE])\n",
    "    df_save = pd.concat([df1,df2], axis =1)\n",
    "    df_save.to_csv(f'synthetic_{MODEL_NAME}_{DATASET_NAME}_{TARGET_EPSILON}.csv')\n",
    "\n",
    "def save_churn():\n",
    "    geography = np.argmax(syn_save[:,8:11], axis=1)\n",
    "    gender = np.argmax(syn_save[:,11:], axis=1)\n",
    "    \n",
    "    syn_save[:,8:11] = update_array(geography, cols=3)\n",
    "    syn_save[:, 11:] = update_array(gender, cols=2)\n",
    "    syn_save[:,4] = np.round(syn_save[:,4]) # num products\n",
    "    syn_save[:,5] = np.round(np.clip(syn_save[:,5],0,1)) # Has card\n",
    "    syn_save[:,6] = np.round(np.clip(syn_save[:,6],0,1)) # Is active\n",
    "    \n",
    "    df1 = pd.DataFrame(syn_save, columns = df.columns.drop(TARGET_VARIABLE))\n",
    "    df2 = pd.DataFrame(syn_y, columns = [TARGET_VARIABLE])\n",
    "    df_save = pd.concat([df1,df2], axis =1)\n",
    "    df_save.to_csv(f'synthetic_{MODEL_NAME}_{DATASET_NAME}_{TARGET_EPSILON}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNo3jt20OAym"
   },
   "outputs": [],
   "source": [
    "# Run this cell to generate data and save them.\n",
    "syn_data = model.generate(train_x.shape[0], class_ratios)\n",
    "syn_x, syn_y = syn_data[:, :-1], syn_data[:, -1]\n",
    "\n",
    "# Make a copy for saving\n",
    "syn_save = scaler.inverse_transform(syn_x)\n",
    "\n",
    "# Save data to csv using functions\n",
    "if DATASET_NAME == 'churn': save_churn()\n",
    "else: save_marketing()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dkFp8fy3OAyn"
   },
   "source": [
    "## Do classification with various classifiers.\n",
    "- MLP\n",
    "- RandomForest\n",
    "- AdaBoost\n",
    "- Decision Trees\n",
    "- Gaussian Naive Bayes\n",
    "- Bernouilli Naive Bayes\n",
    "- SVM\n",
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tp6RMgVKWuoh"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB,BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5AWz2tkQX-e6"
   },
   "outputs": [],
   "source": [
    "# Initialise all models\n",
    "classifier_names = ['MLP', 'RF', 'ADABOOST', 'DT', 'GauNB', 'BernNB', 'SVM', 'LogReg']\n",
    "classifiers = [MLPClassifier((32,8), max_iter=1000, random_state=42), #MLP\n",
    "               RandomForestClassifier(max_depth=2, random_state=42), #RF\n",
    "               AdaBoostClassifier(n_estimators=50, random_state=42),\n",
    "               DecisionTreeClassifier(random_state=42),\n",
    "               GaussianNB(),\n",
    "               BernoulliNB(),\n",
    "               SVC(random_state=42),\n",
    "               LogisticRegression(random_state=42)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SEcSLnyVZ7Qz"
   },
   "outputs": [],
   "source": [
    "syn_clf_accuracy = []\n",
    "syn_clf_roc_score = []\n",
    "real_clf_accuracy = []\n",
    "real_clf_roc_score = []\n",
    "\n",
    "# Loop thru all classifiers.\n",
    "for clf in classifiers:\n",
    "\n",
    "    # Do synthetic\n",
    "    clf.fit(syn_x, syn_y)\n",
    "    pred_y = clf.predict(test_x)\n",
    "\n",
    "    # compute score and append\n",
    "    syn_clf_roc_score.append(roc_auc_score(test_y, pred_y))\n",
    "    syn_clf_accuracy.append(clf.score(test_x,test_y))\n",
    "\n",
    "    # Do real training data\n",
    "    clf.fit(train_x, train_y)\n",
    "    pred_y = clf.predict(test_x)\n",
    "\n",
    "    # compute score and append\n",
    "    real_clf_roc_score.append(roc_auc_score(test_y, pred_y))\n",
    "    real_clf_accuracy.append(clf.score(test_x,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zYoIDID9MqCu"
   },
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame({'Classifier Name':classifier_names,\n",
    "                         'Accuracy on Synthetic':syn_clf_accuracy,\n",
    "                         'ROC on Synthetic': syn_clf_roc_score,\n",
    "                         'Accuracy on Real': real_clf_accuracy,\n",
    "                         'ROC on Real': real_clf_roc_score,\n",
    "                         })\n",
    "score_df.to_csv( 'scores.csv') # Make into a csv that you can download and do computations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "executionInfo": {
     "elapsed": 529,
     "status": "ok",
     "timestamp": 1623408109356,
     "user": {
      "displayName": "Rishi Yildiz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgKrDEkVNAvDdk6mSPj9mqfa7nsf70pBZmUc1aP8D4=s64",
      "userId": "04327726311178638571"
     },
     "user_tz": -120
    },
    "id": "-OG3AhWIa8xS",
    "outputId": "0291b7b6-4327-4063-9181-e842e9aec8a5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier Name</th>\n",
       "      <th>Accuracy on Synthetic</th>\n",
       "      <th>ROC on Synthetic</th>\n",
       "      <th>Accuracy on Real</th>\n",
       "      <th>ROC on Real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.4648</td>\n",
       "      <td>0.466567</td>\n",
       "      <td>0.8564</td>\n",
       "      <td>0.732897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.6808</td>\n",
       "      <td>0.532715</td>\n",
       "      <td>0.8080</td>\n",
       "      <td>0.529218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADABOOST</td>\n",
       "      <td>0.2712</td>\n",
       "      <td>0.481752</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>0.724440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.4464</td>\n",
       "      <td>0.443316</td>\n",
       "      <td>0.7948</td>\n",
       "      <td>0.686180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GauNB</td>\n",
       "      <td>0.5304</td>\n",
       "      <td>0.570635</td>\n",
       "      <td>0.8100</td>\n",
       "      <td>0.654776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BernNB</td>\n",
       "      <td>0.7824</td>\n",
       "      <td>0.502909</td>\n",
       "      <td>0.8028</td>\n",
       "      <td>0.622471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.7792</td>\n",
       "      <td>0.493589</td>\n",
       "      <td>0.8612</td>\n",
       "      <td>0.685458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.5488</td>\n",
       "      <td>0.508337</td>\n",
       "      <td>0.8092</td>\n",
       "      <td>0.578961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier Name  Accuracy on Synthetic  ...  Accuracy on Real  ROC on Real\n",
       "0             MLP                 0.4648  ...            0.8564     0.732897\n",
       "1              RF                 0.6808  ...            0.8080     0.529218\n",
       "2        ADABOOST                 0.2712  ...            0.8604     0.724440\n",
       "3              DT                 0.4464  ...            0.7948     0.686180\n",
       "4           GauNB                 0.5304  ...            0.8100     0.654776\n",
       "5          BernNB                 0.7824  ...            0.8028     0.622471\n",
       "6             SVM                 0.7792  ...            0.8612     0.685458\n",
       "7          LogReg                 0.5488  ...            0.8092     0.578961\n",
       "\n",
       "[8 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "52vU_o-Ta_-E"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dpwgan-fullscript.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:pategan]",
   "language": "python",
   "name": "conda-env-pategan-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
